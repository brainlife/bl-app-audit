_id,name,desc,files,admins,__v,_datatype_tags,create_date,datatype_tags,samples,uis,groupAnalysis,readme,validator,meta,validator_branch,bids,ObjectId
5d62f38749e403160c93f96a,behavior/eyetracking/peekbank,TBD.. https://github.com/langcog/peekbank/blob/master/static/peekbank-schema.json,"[{'_id': '643852d4b32aa6e00a16834e', 'id': 'aoi_data', 'filename': 'aoi_data.csv', 'required': True}, {'_id': '643852d4b32aa6e00a16834f', 'id': 'aoi_regions', 'filename': 'aoi_regions.csv', 'required': False}, {'_id': '643852d4b32aa6e00a168350', 'id': 'datasets', 'filename': 'datasets.csv', 'required': True}, {'_id': '643852d4b32aa6e00a168351', 'id': 'subjects', 'filename': 'subjects.csv', 'required': True}, {'_id': '643852d4b32aa6e00a168352', 'id': 'trials', 'filename': 'trials.csv', 'required': True}, {'_id': '643852d4b32aa6e00a168353', 'id': 'xy_data', 'filename': 'xy_data.csv', 'required': False}]",['1'],1,[],2020-09-08T15:43:02.964Z,[],[],[],False,,,,,,
5f6bf981cfa36596f6ca7dd4,dsistudio/tractmeasure,DSIStudio tractmeasure in .tsv format,"[{'_id': '5f6bf981cfa36558d0ca7dd5', 'id': 'tractmeasure', 'desc': '', 'required': True, 'filename': 'tractmeasure.tsv'}]","['1179', '1']",4,['qc'],2020-09-24T01:42:25.767Z,[],['5f6caed06bbee30e2f9a0891'],"[{'docker': False, '_id': '5be75b31e15a02914a4be8f0', 'ui': 'raw', 'name': 'File Viewer', 'desc': ""Browse / download files via Brain-Life's File Browser"", 'avatar': 'https://brainlife.io/images/ui-logos/raw.png'}]",False,"```
FileName	Image dimension	Resolution	DWI count	Max b-value	Neighboring DWI correlation	# Bad Slices
dwi	96 96 63 	2.2917 2.2917 2.3 	50	1001.005981	0.900497	0

```",brainlife/validator-dsistudio-tractmeasure,,,,
5db8b3a18aeeee1cbbf30a20,eyetrack/asc,The eye-tracking data files naturally contain gaze position (x/y coordinates) and pupil size data. ,"[{'_id': '5db8b3a18aeeee1b2cf30a21', 'id': 'eyetrack', 'desc': 'converted from .edf', 'required': True, 'filename': 'eyetrack.asc'}]",['1'],2,[],2019-10-29T21:48:17.531Z,[],[],"[{'docker': False, '_id': '5be75b31e15a02914a4be8f0', 'ui': 'raw', 'name': 'File Viewer', 'desc': ""Browse / download files via Brain-Life's File Browser"", 'avatar': 'https://brainlife.io/images/ui-logos/raw.png'}]",False,https://docs.google.com/document/d/1eggzTCzSHG3AEKhtnEDbcdk-2avXN6I94X8aUPEBVsw/edit#,,,,,
59666a40b09297d8d8271dfc,generic/image/png,PNG Image (deprecated by images datatype),"[{'_id': '643852d4b32aa6e00a168356', 'id': 'image', 'filename': 'image.png', 'required': True}]",['1'],4,"['avg', 'epochs', 'equal', 'grad', 'mag', 'maxfilt', 'maxwell', 'movecomp', 'psd', 'response_function', 'rest', 'retest', 'split', 'test']",2020-09-08T15:43:02.941Z,[],[],"[{'docker': False, '_id': '5be75b31e15a02914a4be8f0', 'ui': 'raw', 'name': 'File Viewer', 'desc': ""Browse / download files via Brain-Life's File Browser"", 'avatar': 'https://brainlife.io/images/ui-logos/raw.png'}]",False,,,[],,,
5cb7711c44947d8aea8cb4f4,generic/image/svg,SVG Image,"[{'_id': '643852d4b32aa6e00a168357', 'id': 'image', 'filename': 'image.svg', 'required': True}]",['1'],6,"['afq', 'categories', 'cleaned', 'customSeg', 'roi_mrtrix3_ifod2', 'roi_trekker', 'wmaSeg']",2020-09-08T15:43:02.962Z,[],[],"[{'docker': False, '_id': '5be75b31e15a02914a4be8f0', 'ui': 'raw', 'name': 'File Viewer', 'desc': ""Browse / download files via Brain-Life's File Browser"", 'avatar': 'https://brainlife.io/images/ui-logos/raw.png'}]",False,,,[],,,
5967b799b09297d8d831709e,generic/images,Collection of various images with metadata,"[{'_id': '5dcf0d0bc4ae286e7d2991de', 'id': 'images_json', 'filename': 'images.json', 'required': True, 'desc': 'It should look like\n\n{\n    ""images"": [\n        {\n            ""filename"": ""images/brainmask.svg"",\n            ""name"": ""brainmask"",\n            ""desc"": ""TODO""\n        },\n        {\n            ""filename"": ""images/carpetplot.svg"",\n            ""name"": ""carpetplot"",\n            ""desc"": ""TODO""\n        },\n        {\n            ""filename"": ""images/sampling_scheme.gif"",\n            ""name"": ""sampling_scheme"",\n            ""desc"": ""TODO""\n        }\n    ]\n}'}, {'_id': '5dcf0d0bc4ae28790b2991dd', 'id': 'images', 'dirname': 'images', 'required': True}]",['1'],8,"['3Dsurfaces', 'aLIC', 'cleaned', 'cortex_mapping', 'customSeg', 'dwi-t1', 'odf', 'qa_image', 'reconstructed', 'tissue_types', 'tract_profiles', 'wb_tractogram', 'white_matter_tract_overlays', 'wmc_figures']",2019-11-15T20:39:39.536Z,[],['5dcf0470c4ae2841a929906b'],"[{'docker': False, '_id': '5be75b31e15a02914a4be8f0', 'ui': 'raw', 'name': 'File Viewer', 'desc': ""Browse / download files via Brain-Life's File Browser"", 'avatar': 'https://brainlife.io/images/ui-logos/raw.png'}, {'docker': False, '_id': '5bf755abe15a02914af8ef62', 'ui': 'images', 'name': 'Image Tile', 'desc': 'Generic image viewer', 'avatar': 'https://brainlife.io/images/ui-logos/images.png'}]",False,"This datatype stores N number of images (with any image format supported by the modern browser)  and displays them in a table of 4 columns. images.json must enumerate all images stored inside /images subdirectory. 

We recommend using HTML datatype instead of this datatype.",,[],,,
5ed0352de3f453b13b267dae,generic/network,"Generic network data structure containing nodes and edges with various metadata using JGF v2 format. This datatype will replace the existing ""conmat"" datatype eventually.","[{'_id': '5ed0352de3f4530680267daf', 'id': 'network', 'desc': '', 'required': True, 'filename': 'network.json.gz'}]","['19', '704', '146', '239', '1']",28,"['EMD', 'SOE_mn', 'SOE_sd', 'SOE_th', 'bold', 'communities', 'count', 'denlen', 'density', 'fmriprep', 'identification', 'length', 'letter2backtask', 'measurements', 'network-preprocess', 'networkmatrices', 'null-model', 'preprocessed', 'rest', 'rmse_mn', 'rmse_sd', 'satellite', 'time series', 'volume']",2020-05-28T22:03:25.508Z,"[{'_id': '5fa415cae138ec977a4e996e', 'datatype_tag': 'networkneuro', 'desc': 'For this datatype we should have the following metadata attributes\n\n# graph\n\nsomekey: this is for xyz\nanotherkye: this is for another things (it should be float)\n\n# nodes\n\nsomekey: this is for xyz\nanotherkye: this is for another things (it should be float)\n\n# edges \n\nsomekey: this is for xyz\nanotherkye: this is for another things (it should be float)\n\n# example json\n\n```\n{\n  ""graph"": {\n    ""directed"": false,\n    ""type"": ""graph type"",\n    ""label"": ""graph label"",\n    ""metadata"": {\n      ""somekey"": ""values"",\n      ""anotherkey"": ""values""\n    },\n    ""nodes"": {\n      ""0"": {\n        ""type"": ""node type"",\n        ""label"": ""node label(0)"",\n        ""metadata"": {\n      ""somekey"": ""values"",\n      ""anotherkey"": ""values""\n        }\n      },\n      ""1"": {\n        ""type"": ""node type"",\n        ""label"": ""node label(1)"",\n        ""metadata"": {\n      ""somekey"": ""values"",\n      ""anotherkey"": ""values""\n        }\n      }\n    },\n    ""edges"": [\n      {\n        ""source"": ""0"",\n        ""relation"": ""edge relationship"",\n        ""target"": ""1"",\n        ""directed"": false,\n        ""label"": ""edge label"",\n        ""metadata"": {\n          ""user-defined"": ""values""\n        }\n      }\n    ]\n  }\n}\n\n```'}]",[],"[{'docker': False, '_id': '5be75b31e15a02914a4be8f0', 'ui': 'raw', 'name': 'File Viewer', 'desc': ""Browse / download files via Brain-Life's File Browser"", 'avatar': 'https://brainlife.io/images/ui-logos/raw.png'}]",True,"This datatype uses gzipped JSON structured in ""v2 JSON graph format"" (https://github.com/jsongraph/json-graph-specification) used by companies such as BioDati, ADSWorks, etc.

Here is an example JSON structure

```json
{
  ""graph"": {
    ""directed"": false,
    ""type"": ""graph type"",
    ""label"": ""graph label"",
    ""metadata"": {
      ""user-defined"": ""values""
    },
    ""nodes"": {
      ""0"": {
        ""type"": ""node type"",
        ""label"": ""node label(0)"",
        ""metadata"": {
          ""user-defined"": ""values""
        }
      },
      ""1"": {
        ""type"": ""node type"",
        ""label"": ""node label(1)"",
        ""metadata"": {
          ""user-defined"": ""values""
        }
      }
    },
    ""edges"": [
      {
        ""source"": ""0"",
        ""relation"": ""edge relationship"",
        ""target"": ""1"",
        ""directed"": false,
        ""label"": ""edge label"",
        ""metadata"": {
          ""user-defined"": ""values""
        }
      }
    ]
  }
}

```

# Notes

Although JGF allow for multiple graphs object by storing an array of objects under ""graph"" key, we ask that we only store one graph for this json as not all Apps are designed to handle multiple graphs. On the other hand, all Apps that uses this datatype should check to make sure that the object under ""graph"" key is no an array.
",brainlife/validator-network,,,,
604a4553ebfe4559de3af944,generic/timeseries,"A time series is a chronologically ordered series of numeric values. Time series will generally be stored as tables, with a row of column headers indicating the name of the series. ","[{'_id': '604a4553ebfe45e8de3af945', 'id': 'tsv', 'desc': '', 'required': True, 'filename': 'timeseries.tsv.gz'}, {'_id': '6092c02c8fe49f18dc1ca25a', 'id': 'json', 'desc': 'Associated label metadata for creation of func network', 'required': True, 'filename': 'timeseries.json'}]","['16', '704', '239', '1']",9,['time series'],2021-03-11T16:29:07.983Z,[],[],"[{'docker': False, '_id': '5be75b31e15a02914a4be8f0', 'ui': 'raw', 'name': 'File Viewer', 'desc': ""Browse / download files via Brain-Life's File Browser"", 'avatar': 'https://brainlife.io/images/ui-logos/raw.png'}]",False,"Based on https://github.com/bids-standard/bids-specification/pull/519/files

timeseries.tsv.gz will contain a table that looks like the following

```
colname1 colname2 colname3
12                98                 11
11                34                 53
54                34                 34
```

## metadata/sidecar (config.json)

```
{
    ""SamplingFrequency"": 1.5,
    ""StartTime"": ""2012-02-03T923:33:35Z"",
}
```

The metadata (sidecar) for this object contains information about a few key attributes (SamplingFrequency, and StartTime) and column definitions for each measurement

## timeseries.json

```
{
    ""colname1"": {
        ""CumulativeVarianceExplained"": 0.0783402075,
        ""Mask"": ""CSF"",
        ""Method"": ""aCompCor"",
        ""Retained"": true,
        ""SingularValue"": 93.9257549802,
        ""VarianceExplained"": 0.0783402075
     },
     ""colname2"": {
        ""CumulativeVarianceExplained"": 0.0783402075,
        ""Mask"": ""CSF"",
        ""Method"": ""aCompCor"",
        ""Retained"": true,
        ""SingularValue"": 93.9257549802,
        ""VarianceExplained"": 0.0783402075
     },
     ""colname3"": {
        ""CumulativeVarianceExplained"": 0.0783402075,
        ""Mask"": ""CSF"",
        ""Method"": ""aCompCor"",
        ""Retained"": true,
        ""SingularValue"": 93.9257549802,
        ""VarianceExplained"": 0.0783402075
     }
     ....
}
```

`SamplingFrequency` is required for uniform time series data (in seconds). 

For non-uniform time series data, there should be `onset`, and `duration` columns (units in seconds). Please see https://bids-specification.readthedocs.io/en/stable/04-modality-specific-files/05-task-events.html as an example.

`StartTime` is optional.


# label.json should look like this

```
[
    {
        ""voxel_value"": 1,
        ""label"": ""1001"",
        ""name"": ""lh.Background+FreeSurfer_Defined_Medial_Wall.label""
    },
    {
        ""voxel_value"": 2,
        ""label"": ""1002"",
        ""name"": ""lh.17Networks_LH_VisCent_ExStr_1.label""
    },
    {
        ""voxel_value"": 3,
        ""label"": ""1003"",
        ""name"": ""lh.17Networks_LH_VisCent_ExStr_2.label""
    },
```",brainlife/validator-timeseries,,main,,
5ed834cdda66453cde8edfb7,generic/timeseries-deprecated,Generic time-series datatype,"[{'_id': '5ed834f4da66454a638edfb8', 'id': 'timeseries', 'desc': '', 'required': True, 'filename': 'timeseries.hdf5'}, {'_id': '5edbb5bcc5972b7aadb387dc', 'id': 'key', 'desc': 'associated label metadata for creation of func network', 'required': False, 'filename': 'key.txt'}, {'_id': '5edbb5bcc5972ba9b6b387dd', 'id': 'label', 'desc': 'associated label metadata for creation of func network', 'required': False, 'filename': 'label.json'}]","['239', '1']",6,"['bold', 'fmriprep', 'preprocessed', 'rest', 'time series']",2020-06-03T23:39:57.723Z,[],[],"[{'docker': False, '_id': '5be75b31e15a02914a4be8f0', 'ui': 'raw', 'name': 'File Viewer', 'desc': ""Browse / download files via Brain-Life's File Browser"", 'avatar': 'https://brainlife.io/images/ui-logos/raw.png'}]",False,"This datatype can be used to store time-series data in .hdf5 data format. 

Inside the `timeseries.hdf5`, it is expected to have the following 2 objects

```
/timeseries
   --TODO describe--
/regionids
   --TODO describe--
```

timeseries and regionids are stored as following.
> https://github.com/brainlife/app-time-series-2-network/blob/master/src/makemat.py

```
                h5f.create_dataset('timeseries',
                                   data=times,
                                   compression=""gzip"")
                h5f.create_dataset('regionids',
                                   data=np.array(regions))

```",,,,,
6079f960f1481a4d788fba3e,jupyter/notebook,A datatype to store jupyter notebook content,"[{'_id': '6079f960f1481a4d788fba3f', 'id': 'notebook', 'desc': 'Directory containing .ipynb/.py and other content', 'required': True, 'dirname': 'notebook'}]",['1'],0,[],2021-04-16T20:53:52.790Z,[],[],"[{'docker': False, '_id': '5be75b31e15a02914a4be8f0', 'ui': 'raw', 'name': 'File Viewer', 'desc': ""Browse / download files via Brain-Life's File Browser"", 'avatar': 'https://brainlife.io/images/ui-logos/raw.png'}]",False,,,,,,
5ced86fe44947d8aeaa53d71,model/classifyber,a pickle object containing a dictionary of scaler[optional] and clf for each tracts,"[{'_id': '643852d4b32aa6e00a168362', 'id': 'model', 'filename': 'model.pickle', 'required': True}]",['1'],1,[],2020-09-08T15:43:02.963Z,[],[],"[{'docker': False, '_id': '5be75b31e15a02914a4be8f0', 'ui': 'raw', 'name': 'File Viewer', 'desc': ""Browse / download files via Brain-Life's File Browser"", 'avatar': 'https://brainlife.io/images/ui-logos/raw.png'}]",False,,,,,,
5ced859744947d8aeaa4add7,model/pytorch-weights,pytorch weights(.npz) generated by tractseg (for now),"[{'_id': '643852d4b32aa6e00a168363', 'id': 'npz', 'filename': 'weights.npz', 'required': True}, {'_id': '643852d4b32aa6e00a168364', 'id': 'hparam', 'filename': 'Hyperparameters.txt', 'required': True}]",['1'],1,[],2020-09-08T15:43:02.963Z,[],[],"[{'docker': False, '_id': '5be75b31e15a02914a4be8f0', 'ui': 'raw', 'name': 'File Viewer', 'desc': ""Browse / download files via Brain-Life's File Browser"", 'avatar': 'https://brainlife.io/images/ui-logos/raw.png'}]",False,,,,,,
59307a08436ee50ffd973278,neuro/3Dsurfaces,3D surface stored in .vtk(s),"[{'_id': '5e28ab182f45e2528e090063', 'id': 'surfaces', 'dirname': 'surfaces', 'required': True}]",['1'],6,"['freesurfer', 'lb_reconstructed', 'pial_wm_inflated', 'reduced']",2020-01-22T20:05:44.810Z,[],"['5e28c8de2f45e21d9b090825', '5e28c8d92f45e2cf34090808']","[{'docker': False, '_id': '5be75b31e15a02914a4be8f0', 'ui': 'raw', 'name': 'File Viewer', 'desc': ""Browse / download files via Brain-Life's File Browser"", 'avatar': 'https://brainlife.io/images/ui-logos/raw.png'}, {'docker': False, '_id': '5bf75667e15a02914af8f669', 'ui': 'surfaces', 'name': '3D Surfaces', 'desc': 'Display 3D Surfaces (vtk) using THREE.js(WebGL)', 'avatar': 'https://brainlife.io/images/ui-logos/surfaces.png'}]",False,A list of .vtk files with any names stored inside `surfaces` directory.,,"[{'id': 'subject', 'type': 'string', 'required': True}]",,,
5ace14a0d071a1753fada7a4,neuro/AFQ,AFQ_run output,"[{'_id': '617034a7fc8eb9311f005982', 'id': 'afq', 'filename': 'afq.mat', 'required': True}]",['1'],2,[],2020-09-08T15:43:02.950Z,[],[],"[{'docker': False, '_id': '5be75b31e15a02914a4be8f0', 'ui': 'raw', 'name': 'File Viewer', 'desc': ""Browse / download files via Brain-Life's File Browser"", 'avatar': 'https://brainlife.io/images/ui-logos/raw.png'}]",False,,,,,,
622138875d8ab5d5f0212b05,neuro/FSLBedpostX,This datatype is specific to FSL's Bedpost. It contains the entire folder with the results of Bedpost ,"[{'id': 'bedpostx', 'dirname': 'bedpostx', 'desc': 'This is a the top-folder generated as output of BedpostX', 'required': True, '_id': '622138875d8ab5d5f0212b06'}]","['41', '123']",0,[],2022-03-03T21:52:07.712Z,"[{'datatype_tag': 'connectivity', 'desc': '', '_id': '622138875d8ab5d5f0212b07'}]",[],"[{'docker': False, '_id': '5be75b31e15a02914a4be8f0', 'ui': 'raw', 'name': 'File Viewer', 'desc': ""Browse / download files via Brain-Life's File Browser"", 'avatar': 'https://brainlife.io/images/ui-logos/raw.png'}, {'_id': '5bf755e5e15a02914af8f194', 'ui': 'fslview', 'name': 'FSLView', 'desc': 'An old 2d/3d brain volume viewer. Replaced by fsleyes', 'avatar': 'https://brainlife.io/images/ui-logos/fslview.png', 'docker': True}]",False,,,,,,
58d15eaee13a50849b258844,neuro/LiFE,LiFE Output (fe structure),"[{'_id': '5fdb67dc57aacd5b932f2a88', 'id': 'fe', 'filename': 'output_fe.mat', 'desc': 'FE structure', 'ext': '.mat', 'required': True}, {'_id': '5fdb67dc57aacd36f22f2a89', 'id': 'life_results', 'filename': 'life_results.json', 'required': True}, {'_id': '5fdb67dc57aacdac2e2f2a8a', 'id': 'tracts', 'dirname': 'tracts', 'required': True}]",['1'],4,"['dt_stream', 'ensemble', 'roi2roi', 'sd_prob', 'sd_stream']",2020-09-08T15:43:02.922Z,[],['5e9f09402600c45fbf94ee61'],"[{'docker': False, '_id': '5be75b31e15a02914a4be8f0', 'ui': 'raw', 'name': 'File Viewer', 'desc': ""Browse / download files via Brain-Life's File Browser"", 'avatar': 'https://brainlife.io/images/ui-logos/raw.png'}, {'docker': False, '_id': '5be75568e15a02914a4badf8', 'ui': 'lifestats', 'name': 'Life Stats', 'desc': 'Display basic statistics from the LiFE output.', 'avatar': 'https://brainlife.io/images/ui-logos/lifestat.png'}, {'docker': False, '_id': '5c48ddbe12bbe55e4ac7fbbb', 'ui': 'lifeview', 'name': 'Life Tracts View', 'desc': 'Display non-0 weights tracts', 'avatar': 'https://brainlife.io/images/ui-logos/ui-lifeview.png'}]",False,"
## output_fe.mat structure

#### fe fields
```
• fe.name: [text], customized name of the structure.
• fe.type: [text], type description.
• fe.life: [1 × 1 struct], results of the LiFE method, see fe.life fields description below.
• fe.fg: [1 × 1 struct], input fiber group (connectome) information, see fe.fg fields description below.
• fe.roi: [1 × 1 struct], input fiber group (connectome) information, see fe.roi fields description below.
• fe.path: [1 × 1 struct], paths to input data (connectome, dMRI data, etc.).
• fe.rep: [1×1 struct], dMRI data for a repeated measurement if available. 
```

#### fe.life fields
```
• fe.life.M.Phi: [Na × Nv × Nf sptensor], sparse array Φ encoding the connectome.
• fe.life.M.Nphi: Discretization number in azimuth, default = 360.
• fe.life.M.Ntheta: Discretization number in elevation, default = 360.
• fe.life.M.orient: [3 × Na double], matrix containing in its columns the orientations for each Dictionary element.
• fe.life.M.DictSig: [Nθ × Na double], Dictionary matrix containing in its columns the canonical diffusion kernel (demeaned) at different orienta- tions.
• fe.life.xform.img2acpc: [4 × 4 double], Image to ACPC affine trans- form.
• fe.life.xform.acpc2img: [4 × 4 double], ACPC to image affine trans- form.
• fe.life.fibers: not used.
• fe.life.diffusion_signal_img: [Nv × Nθ double], dMRI data.
• fe.life.diffusion_S0_img: [Nv × 10 double], diffusion signal measured at b = 0 (ten times). Usually, we compute S0(v) by averaging over the ten available values.
• fe.life.bvecs: [Nθ × 3 double], each row indicates the gradient 3D di- rection.
• fe.life.bvals: [Nθ × 1 double], each row indicates the used b-value for each gradient.
• fe.life.bvecsindices: [Nθ × 1 int], indices for measurements with non- zero b-value.
• fe.life.imagedim: [Nx , Ny , Nz , Nm ], size of the input 4D dMRI dataset where (Nx,Ny,Nz) are the the sizes in each coordinate, x, y and z, respec- tivelly; and Nm correspond to the number of measurements with b = 0 and b ̸= 0.
• fe.life.voxel2FNpair: not used.
• fe.life.modelTensor: [λ1 , λ2 , λ3 ], parameters of the Diffusion Tensor (DT) model used to generate the Dictionary of diffusion kernels.
• fe.life.fit: this field contains the results of applying the LiFE method, see description below.
```

#### fe.life.fit fields
```
• fe.life.fit.randState: saved by the optimization algorithm.
• fe.life.fit.results: saved by the optimization algorithm.
• fe.life.fit.weights: [Nf × 1 double], fascicles weights obtained as a result of the optimization.
• fe.life.fit.params.fitMethod: [text], name of used optimization method, default is “bbnls”.
```

#### fe.fg fields
```
• fe.fg.name: [text], name of Fiber Group (connectome).
• fe.fg.colorRgb: [R, G, B], color specification for visualization.
• fe.fg.thickness: [double], thickness specificattion for visualization.
• fe.fg.visible: [binary], parameter for visualization.
• fe.fg.seeds: Seeds used by MRTRIX software to generate the connectome.
• fe.fg.seedRadius: MRTRIX parameter.
• fe.fg.seedVoxelOffsets: MRTRIX parameter.
• fe.fg.params: additional MRTRIX parameters.
• fe.fg.fibers: {Nf ×1 cell}, set of fascicles (streamlines), generated with a tractography algorithm. Each cell contains the x,y,z coordinates a list of 3D points describing the trajectory of a single fascicle.
```

#### fe.roi fields
```
• fe.roi.name: [text], name of ROI.
• fe.roi.color: [R, G, B], color specification for visualization.
• fe.roi.coords: [Nv ×3 double], voxel coordinates, each row specifies the spatial location of a single voxel.
• fe.roi.visible: [binary], parameter for visualization.
• fe.roi.mesh: not used.
• fe.roi.dirty: parameter for visualization
• fe.roi.query_id: not used.
```

",,,,"{'_id': '5fdb678157aacd23302f2a86', 'maps': [{'_id': '5fdb67dc57aacda2872f2a8b', 'src': 'output_fe.mat', 'dest': 'life.mat'}, {'_id': '5fdb67dc57aacdad132f2a8c', 'src': '_meta_', 'dest': 'life.json'}], 'derivatives': 'dwi'}",
61151f8ca5a04c1ad3f9a2d1,neuro/SNR_and_dMRI_stats,Edit me,"[{'id': 'tbd', 'filename': 'some.csv', 'desc': '', 'required': True, '_id': '629e34907f60950a54d26869'}]","['1', '56']",8,[],2021-08-12T13:18:04.592Z,[],[],"[{'_id': '5e56db217ba4a359997127ce', 'ui': 'html', 'name': 'HTML Viewer', 'desc': 'Show HTML contents', 'avatar': 'https://brainlife.io/images/ui-logos/html.png', 'docker': True}]",False,,,,,,
62b03ee2ab3e66978064ed79,neuro/anat/T2starw,"""In arbitrary units (arbitrary). The contrast of these images is mainly determined by spatial variations in the (observed) transverse relaxation time of the imaged specimen. In spin-echo sequences, this effect is negated as the excitation is followed by an inversion pulse. The contrast of gradient-echo images natively depends on T2-star effects. However, for T2-star variation to dominate the image contrast, gradient-echo acquisitions are carried out at long repetition and echo times, and at small flip angles."" - From BIDS - MRI (https://bids-specification.readthedocs.io/en/stable/04-modality-specific-files/01-magnetic-resonance-imaging-data.html)","[{'id': 't2starw-mag', 'filename': 't2star-mag.nii.gz', 'desc': '', 'required': True, '_id': '62b03ee2ab3e66978064ed7a'}, {'id': 't2starw-phase', 'filename': 't2starw-phase.nii.gz', 'desc': '', 'required': True, '_id': '62b07377ab3e669780650237'}]","['1', '2109']",1,[],2022-06-20T09:33:22.297Z,[],[],"[{'docker': False, '_id': '5be75b31e15a02914a4be8f0', 'ui': 'raw', 'name': 'File Viewer', 'desc': ""Browse / download files via Brain-Life's File Browser"", 'avatar': 'https://brainlife.io/images/ui-logos/raw.png'}]",False,"""In arbitrary units (arbitrary). The contrast of these images is mainly determined by spatial variations in the (observed) transverse relaxation time of the imaged specimen. In spin-echo sequences, this effect is negated as the excitation is followed by an inversion pulse. The contrast of gradient-echo images natively depends on T2-star effects. However, for T2-star variation to dominate the image contrast, gradient-echo acquisitions are carried out at long repetition and echo times, and at small flip angles."" - From [BIDS - MRI](https://bids-specification.readthedocs.io/en/stable/04-modality-specific-files/01-magnetic-resonance-imaging-data.html)",,,,,
5d9cf81c0eed545f51bf75df,neuro/anat/flair,"Fluid Attenuated Inversion Recovery (flair). The Flair sequence is similar to a T2-weighted image except that the TE and TR times are very long. By doing so, abnormalities remain bright but normal CSF fluid is attenuated and made dark. This sequence is very sensitive to pathology and makes the differentiation between CSF and an abnormality much easier.","[{'_id': '5e9611ed6365e94522471b90', 'id': 'flair', 'filename': 'flair.nii.gz', 'desc': 'The flair iamge', 'required': True}]",['1'],4,[],2020-04-14T19:41:33.707Z,[],[],"[{'docker': False, '_id': '5be75b31e15a02914a4be8f0', 'ui': 'raw', 'name': 'File Viewer', 'desc': ""Browse / download files via Brain-Life's File Browser"", 'avatar': 'https://brainlife.io/images/ui-logos/raw.png'}, {'docker': False, '_id': '5bf755c8e15a02914af8f084', 'ui': 'volumeviewer', 'name': 'Volume Viewer', 'desc': 'Web-based visualization tools for neurological data.', 'avatar': 'https://brainlife.io/images/ui-logos/ui-volumeviewer.png'}, {'_id': '5bf755f4e15a02914af8f22b', 'ui': 'fsleyes', 'name': 'FSLeyes', 'desc': 'A 2d/3d brain volume viewer.', 'avatar': 'https://brainlife.io/images/ui-logos/fsleyes.png', 'docker': True}, {'docker': False, '_id': '60da96878c1f96ddd4318b19', 'ui': 'papaya', 'name': 'Papaya Viewer', 'desc': 'A pure JavaScript medical research image viewer.', 'avatar': 'https://raw.github.com/rii-mango/Papaya/master/docs/images/splash1.png'}]",False,,brainlife/validator-neuro-anat,,,,
60634f0de4a8347569337f97,neuro/anat/mp2rage,(experimental) tentative data format for MP2RAGE in brainlife. Modeling after https://bids-specification.readthedocs.io/en/stable/99-appendices/11-qmri.html#inputs-are-file-collections,"[{'_id': '60634f0de4a834ae1e337f98', 'id': 'mag_inv1', 'desc': '', 'required': True, 'filename': 'mag.inv1.nii.gz'}, {'_id': '60634f0de4a8345998337f99', 'id': 'phase_inv1', 'desc': '', 'required': False, 'filename': 'phase.inv1.nii.gz'}, {'_id': '606351b1e4a834e8f13384e9', 'id': 'mag_inv2', 'desc': '', 'required': True, 'filename': 'mag.inv2.nii.gz'}, {'_id': '606351b1e4a83485e13384ea', 'id': 'phase_inv2', 'desc': '', 'required': False, 'filename': 'phase.inv2.nii.gz'}, {'_id': '606351b1e4a83446df3384eb', 'id': 'unit1', 'desc': '', 'required': False, 'filename': 'unit1.nii.gz'}, {'_id': '606f8368c7f80abee9955927', 'id': 'mag_inv1_json', 'desc': '', 'required': False, 'filename': 'mag.inv1.json'}, {'_id': '606f83e0c7f80a5a10955952', 'id': 'phase_inv1_json', 'desc': '', 'required': False, 'filename': 'phase.inv1.json'}, {'_id': '606f83e0c7f80a64df955953', 'id': 'mag_inv2_json', 'desc': '', 'required': False, 'filename': 'mag.inv2.json'}, {'_id': '606f83e0c7f80a46df955954', 'id': 'phase_inv2_json', 'desc': '', 'required': False, 'filename': 'phase.inv2.json'}, {'_id': '606f83e0c7f80ac515955955', 'id': 'unit1_json', 'desc': '(stored in bids derivatives)', 'required': False, 'filename': 'unit1.json'}]","['156', '1', '126']",10,"['acpc_aligned', 'denoised']",2021-03-30T16:17:17.079Z,[],[],"[{'docker': False, '_id': '5be75b31e15a02914a4be8f0', 'ui': 'raw', 'name': 'File Viewer', 'desc': ""Browse / download files via Brain-Life's File Browser"", 'avatar': 'https://brainlife.io/images/ui-logos/raw.png'}]",False,"I am not sure how we should import UNI images

There is a bit of information here
> https://bids-specification.readthedocs.io/en/stable/99-appendices/11-qmri.html#unit1-images

But Sophis says there is no inv- for UNI images although BIDS schema requires it.. ",,,,,
608ac8b089df43e33c758fa1,neuro/anat/qmri,Quantitative MRI derivatives,"[{'_id': '608ac8b089df4379db758fa2', 'id': 'T1map', 'desc': '', 'required': True, 'filename': 'T1.nii.gz'}, {'_id': '608ac8b089df434ddc758fa3', 'id': 'T1map_json', 'desc': '', 'required': False, 'filename': 'T1.json'}, {'_id': '608ac8b089df430503758fa4', 'id': 'R1map', 'desc': 'In general, this is for output only. For App, please assume this files to not exist and compute it by intervening T1map', 'required': False, 'filename': 'R1.nii.gz'}, {'_id': '608ac8b089df430864758fa5', 'id': 'R1map_json', 'desc': '', 'required': False, 'filename': 'R1.json'}, {'_id': '608ac8b089df4329b9758fa6', 'id': 'M0map', 'desc': 'In general, this is for output only. For App, please assume this files to not exist and compute it from T1map and pd', 'required': False, 'filename': 'M0.nii.gz'}, {'_id': '608ac8b089df437045758fa7', 'id': 'M0map_json', 'desc': '', 'required': False, 'filename': 'M0.json'}, {'_id': '608ac8b089df436005758fa8', 'id': 'PD', 'desc': 'proton density\n', 'required': False, 'filename': 'PD.nii.gz'}, {'_id': '608ac8b089df43a42b758fa9', 'id': 'MTV', 'desc': 'macromolecular tissue volume. In general, this is for output only. For App, please assume this files to not exist and compute it from T1map and pd', 'required': False, 'filename': 'MTV.nii.gz'}, {'_id': '608ac8b089df43a34e758faa', 'id': 'VIP', 'desc': 'volume of interacting water proton. In general, this is for output only. For App, please assume this files to not exist and compute it from T1map and pd', 'required': False, 'filename': 'VIP.nii.gz'}, {'_id': '608ac8b089df43db90758fab', 'id': 'SIR', 'desc': 'surface interaction rate. In general, this is for output only. For App, please assume this files to not exist and compute it from T1map and pd', 'required': False, 'filename': 'SIR.nii.gz'}, {'_id': '6115d777a5a04c2ae4f9f09f', 'id': 'WF', 'desc': 'Water fraction. In general, this is for output only. For App, please assume this files to not exist and compute it from T1map and pd', 'required': False, 'filename': 'WF.nii.gz'}]","['16', '1', '126']",5,['mp2rage'],2021-04-29T14:54:40.431Z,"[{'_id': '608ac8d989df432ac8758fc1', 'datatype_tag': 'mp2rage', 'desc': 'qmri data derived from mp2rage sequence'}]",[],"[{'docker': False, '_id': '5be75b31e15a02914a4be8f0', 'ui': 'raw', 'name': 'File Viewer', 'desc': ""Browse / download files via Brain-Life's File Browser"", 'avatar': 'https://brainlife.io/images/ui-logos/raw.png'}]",False,"https://bids-specification.readthedocs.io/en/stable/99-appendices/11-qmri.html

Quantitative MRI (qMRI) is a collection of methods aiming at generating parametric maps that can characterize underlying tissue properties. Unlike those of conventional MR images (for example, T1w or T2w), intensity values of quantitative maps are not represented in an arbitrary range. Instead, these maps are represented either in absolute physical units (for example, seconds for T1map), or within an application dependent range of arbitrary units (for example, myelin water fraction MWFmap in brain).",,,,,
58c33bcee13a50849b25879a,neuro/anat/t1w,"T1-weighted magnetic resonance data (MRI), saved in NIfTI-1 format.","[{'_id': '5e3ad2d19362b722a0f966b9', 'id': 't1', 'filename': 't1.nii.gz', 'ext': '.gz', 'required': True}]",['1'],48,"['1.25mm_brain', '3dSkullStrip', '7t', 'AC-PC aligned', 'ACPC', 'ANTs', 'CHM', 'Control', 'MNI152', 'MR', 'STGD', 'T1', 'T1WI', 'T1w', 'acpc_aligned', 'anat', 'baseline', 'bias_corrected', 'brain', 'brain_extracted', 'crop_reorient', 'debiased', 'defaced', 'deleteme', 'desc-preproc_T1w', 'dtag1', 'fmriprep', 'image 3', 'image 4', 'image 5', 'image 6', 'image 7', 'image 8', 'image_10', 'image_11', 'image_2', 'image_3', 'image_30', 'image_32', 'image_34', 'image_35', 'image_37', 'image_4', 'image_5', 'image_6', 'image_7', 'image_9', 'mni_space', 'mp2rage', 'norm', 'org-t1w', 'preprocessed', 'qsiprep', 'registered', 'second 1', 'session 1', 'session 2', 'session_1', 'session_2', 'standard', 't1w', 'warped']",2020-02-05T14:36:01.608Z,[],"['5d796fd303e8c916d5eaed4d', '5d796fd303e8c9853feaed51']","[{'docker': False, '_id': '5be75b31e15a02914a4be8f0', 'ui': 'raw', 'name': 'File Viewer', 'desc': ""Browse / download files via Brain-Life's File Browser"", 'avatar': 'https://brainlife.io/images/ui-logos/raw.png'}, {'docker': False, '_id': '5bf755c8e15a02914af8f084', 'ui': 'volumeviewer', 'name': 'Volume Viewer', 'desc': 'Web-based visualization tools for neurological data.', 'avatar': 'https://brainlife.io/images/ui-logos/ui-volumeviewer.png'}, {'_id': '5bf755e5e15a02914af8f194', 'ui': 'fslview', 'name': 'FSLView', 'desc': 'An old 2d/3d brain volume viewer. Replaced by fsleyes', 'avatar': 'https://brainlife.io/images/ui-logos/fslview.png', 'docker': True}, {'_id': '5bf755f4e15a02914af8f22b', 'ui': 'fsleyes', 'name': 'FSLeyes', 'desc': 'A 2d/3d brain volume viewer.', 'avatar': 'https://brainlife.io/images/ui-logos/fsleyes.png', 'docker': True}, {'_id': '5bf75608e15a02914af8f2e3', 'ui': 'mrview', 'name': 'mrView', 'desc': 'The MRtrix image viewer.', 'avatar': 'https://brainlife.io/images/ui-logos/mrview.png', 'docker': True}, {'_id': '5bf75623e15a02914af8f3d8', 'ui': 'mricrogl', 'name': 'MRIcroGL', 'desc': 'View 2D slices and renderings of your brain imaging data. It allows you to draw regions of interest which can aid lesion mapping and fMRI analysis.', 'avatar': 'https://brainlife.io/images/ui-logos/mricrogl.png', 'docker': True}, {'_id': '5bf75630e15a02914af8f44e', 'ui': 'fibernavigator', 'name': 'fiberNavigator', 'desc': 'A tool designed for a fast and versatile visualization of streamline datasets.', 'avatar': 'https://brainlife.io/images/ui-logos/fibernavigator.png', 'docker': True}, {'_id': '5bf7563de15a02914af8f4c5', 'ui': 'freeview-gpu', 'name': 'FreeView', 'desc': 'A freesurfer program used to view and work with structural, anatomical scans.', 'avatar': 'https://brainlife.io/images/ui-logos/freeview.png', 'docker': True}, {'docker': False, '_id': '60da96878c1f96ddd4318b19', 'ui': 'papaya', 'name': 'Papaya Viewer', 'desc': 'A pure JavaScript medical research image viewer.', 'avatar': 'https://raw.github.com/rii-mango/Papaya/master/docs/images/splash1.png'}]",False,,brainlife/validator-neuro-anat,,,"{'_id': '5e3ad2cd9362b7d887f966b7', 'maps': [{'_id': '5e3ad2d19362b71b99f966ba', 'src': 't1.nii.gz', 'dest': 'T1w.nii.gz'}, {'_id': '5e3ad2d19362b70bb5f966bb', 'src': '_meta_', 'dest': 'T1w.json'}], 'derivatives': 'anat'}",
594c0325fa1d2e5a1f0beda5,neuro/anat/t2w,T2 weighted,"[{'_id': '5e42cf44301ffc120434126c', 'id': 't2', 'filename': 't2.nii.gz', 'ext': '.gz', 'required': True}]",['1'],15,"['T2', 'acpc_aligned', 'brain', 'brain_extracted', 'crop_reorient', 'debiased', 'defaced', 'image_22', 'image_28', 'image_28a', 'image_30', 'image_31', 'image_32', 'image_33', 'preprocessed', 'session 1', 'session_1', 'session_2', 'standard']",2020-02-11T15:59:00.550Z,[],['5d796fd303e8c95c17eaed4e'],"[{'docker': False, '_id': '5be75b31e15a02914a4be8f0', 'ui': 'raw', 'name': 'File Viewer', 'desc': ""Browse / download files via Brain-Life's File Browser"", 'avatar': 'https://brainlife.io/images/ui-logos/raw.png'}, {'docker': False, '_id': '5bf755c8e15a02914af8f084', 'ui': 'volumeviewer', 'name': 'Volume Viewer', 'desc': 'Web-based visualization tools for neurological data.', 'avatar': 'https://brainlife.io/images/ui-logos/ui-volumeviewer.png'}, {'_id': '5bf755e5e15a02914af8f194', 'ui': 'fslview', 'name': 'FSLView', 'desc': 'An old 2d/3d brain volume viewer. Replaced by fsleyes', 'avatar': 'https://brainlife.io/images/ui-logos/fslview.png', 'docker': True}, {'_id': '5bf755f4e15a02914af8f22b', 'ui': 'fsleyes', 'name': 'FSLeyes', 'desc': 'A 2d/3d brain volume viewer.', 'avatar': 'https://brainlife.io/images/ui-logos/fsleyes.png', 'docker': True}, {'_id': '5bf75608e15a02914af8f2e3', 'ui': 'mrview', 'name': 'mrView', 'desc': 'The MRtrix image viewer.', 'avatar': 'https://brainlife.io/images/ui-logos/mrview.png', 'docker': True}, {'_id': '5bf75623e15a02914af8f3d8', 'ui': 'mricrogl', 'name': 'MRIcroGL', 'desc': 'View 2D slices and renderings of your brain imaging data. It allows you to draw regions of interest which can aid lesion mapping and fMRI analysis.', 'avatar': 'https://brainlife.io/images/ui-logos/mricrogl.png', 'docker': True}, {'_id': '5bf75630e15a02914af8f44e', 'ui': 'fibernavigator', 'name': 'fiberNavigator', 'desc': 'A tool designed for a fast and versatile visualization of streamline datasets.', 'avatar': 'https://brainlife.io/images/ui-logos/fibernavigator.png', 'docker': True}, {'_id': '5bf7563de15a02914af8f4c5', 'ui': 'freeview-gpu', 'name': 'FreeView', 'desc': 'A freesurfer program used to view and work with structural, anatomical scans.', 'avatar': 'https://brainlife.io/images/ui-logos/freeview.png', 'docker': True}, {'docker': False, '_id': '60da96878c1f96ddd4318b19', 'ui': 'papaya', 'name': 'Papaya Viewer', 'desc': 'A pure JavaScript medical research image viewer.', 'avatar': 'https://raw.github.com/rii-mango/Papaya/master/docs/images/splash1.png'}]",False,,brainlife/validator-neuro-anat,"[{'id': 'subject', 'type': 'string', 'required': True}]",,,
5e4c47041eafffca2efa3545,neuro/ashs,Output from ASHS (Automated Segmentation of Hippocampal Subfields) in ITKSNAP format,"[{'_id': '5e4c47041eafff59e3fa3546', 'id': 'ashs', 'desc': '', 'required': True, 'dirname': 'ashs'}]",['1'],5,[],2020-02-18T20:20:20.464Z,[],[],"[{'docker': False, '_id': '5be75b31e15a02914a4be8f0', 'ui': 'raw', 'name': 'File Viewer', 'desc': ""Browse / download files via Brain-Life's File Browser"", 'avatar': 'https://brainlife.io/images/ui-logos/raw.png'}, {'_id': '5fd24fd7a0aa8245361c1112', 'ui': 'itksnap', 'name': 'ITK-SNAP', 'desc': 'ITK-SNAP provides semi-automatic segmentation using active contour methods, as well as manual delineation and image navigation. In addition to these core functions, ITK-SNAP offers many supporting utilities. ', 'avatar': 'https://github.com/brainlife/brainlife.github.io/raw/master/images/ui-logos/itksnap.png', 'docker': True}]",False,,brainlife/validator-neuro-ashs,,,,
5fa9a60cafcdcc57e2c444ad,neuro/cifti,"CIFTI files are designed to handle data contained in multiple disjoint anatomical structures, such as both hemispheres of cerebral cortex (vertex-based surface data) and/or specific subcortical structures (gray matter voxels). Structures not of interest for the analysis at hand can be excluded (e.g., white matter, CSF, “medial wall”), thereby making the representation more compact. The vertices and voxels used in a CIFTI file are generically referred to as 'brainordinates' and as 'grayordinates' for the specific case of 'all gray matter locations'.","[{'_id': '5fa9a60cafcdcc9f9ec444ae', 'id': 'cifti', 'desc': '', 'required': True, 'filename': 'cifti.nii'}]",['1'],6,['dtseries'],2020-11-09T20:26:52.949Z,"[{'_id': '5fad54d67e8ecbc48caa0c2c', 'datatype_tag': 'dconn', 'desc': 'a ‘dense’ by ‘dense’ matrix (typically a ‘dense connectome’ from resting-state fMRI)'}, {'_id': '5fad54d67e8ecb5d1eaa0c2d', 'datatype_tag': 'dscalar', 'desc': ' one or more dense maps of scalar values (e.g., myelin maps, curvature maps)'}, {'_id': '5fad61257e8ecb05c9aa0f81', 'datatype_tag': 'dtseries', 'desc': 'one or more dense timeseries datasets (e.g., fMRI timeseries) or other data at equal intervals'}, {'_id': '5fad61257e8ecb2ee7aa0f82', 'datatype_tag': 'dlabel', 'desc': 'one or more dense maps of integer values, plus a ‘label table’ that defines each integer (e.g., one or more parcellations of cerebral cortex, subcortical nuclei, or all grayordinates)'}, {'_id': '5fad61257e8ecb1d88aa0f83', 'datatype_tag': 'dpconn', 'desc': 'a parcel by dense matrix'}, {'_id': '5fad61257e8ecb82d4aa0f84', 'datatype_tag': 'pconn', 'desc': ' a parcel by parcel matrix (typically, a ‘parcellated connectome’)'}, {'_id': '5fad61257e8ecbb91aaa0f85', 'datatype_tag': 'pdconn', 'desc': 'a dense by parcel matrix'}, {'_id': '5fad61257e8ecb279daa0f86', 'datatype_tag': 'pscalar', 'desc': 'one or more parcellated scalar maps (e.g., a parcellated thickness map having uniform thickness within each parcel'}, {'_id': '5fad61257e8ecbb5ddaa0f87', 'datatype_tag': 'ptseries', 'desc': 'parcellated timeseries'}, {'_id': '5fad61257e8ecb5baeaa0f88', 'datatype_tag': 'plabel', 'desc': 'one or more parcel maps, where each parcel is identified and colored using a label'}, {'_id': '5fad61257e8ecb7ae8aa0f89', 'datatype_tag': 'sdseries', 'desc': 'contains rows of series data (frequency, time, etc.). This data type is different than most other CIFTI files, as it is not mapped to brainordinates (i.e., it has neither a dense nor a parcels dimension).  The data is viewed in its entirety as a matrix chart, or individual rows are viewed as a line chart.'}, {'_id': '5fad61257e8ecb8688aa0f8a', 'datatype_tag': 'fibertemp', 'desc': 'contains orientations of dMRI fibers. This is actually the same format as a dscalar file (above), but the arrangement of maps in the file is fixed so that wb_view knows how to translate them into fiber orientations.'}]",[],"[{'docker': False, '_id': '5be75b31e15a02914a4be8f0', 'ui': 'raw', 'name': 'File Viewer', 'desc': ""Browse / download files via Brain-Life's File Browser"", 'avatar': 'https://brainlife.io/images/ui-logos/raw.png'}]",False,"A CIFTI file is a single rectangular data matrix (usually 2 dimensions, but supports 3). Each dimension is described using one of five available 'mapping types' (see datatype tags), and it is their combinations that give rise to the diversity of CIFTI file types. Each mapping contains all information needed to figure out what every index along the dimension means. A mapping of type 'brain models' (also known as 'dense') can represent both hemispheres and all subcortical structures concurrently, thus allowing one dimension to represent over a dozen structures, both surface-based and voxel-based. CIFTI supports an alternative spatial mapping (i.e., allowing display on surfaces and/or in the volume) that is based on ‘parcels’ (e.g., cortical areas, subcortical nuclei); parcels group related brainordinates into areas, resulting in much smaller data files by having fewer values to store (per parcel instead of per vertex/voxel). 

[https://balsa.wustl.edu/about/fileTypes]",,,,,
5d34d9f744947d8aea0e0d2f,neuro/conmat,Connectivity Matrix,"[{'_id': '5e546c6f5b9d905f4b72daf4', 'id': 'index', 'filename': 'index.json', 'required': True}, {'_id': '5e546c6f5b9d90472872daf5', 'id': 'label', 'filename': 'label.json', 'required': True}, {'_id': '5e546c6f5b9d90700b72daf6', 'id': 'csv', 'dirname': 'csv', 'required': True}]",['1'],28,"['EMD', 'SOE_mn', 'SOE_sd', 'SOE_th', 'bart', 'bold', 'count', 'denlen', 'denlen_out', 'density', 'desc-preproc_bold', 'facerecognition', 'fmriprep', 'identification', 'length', 'letter2backtask', 'localizer', 'networkmatrices', 'pamret', 'pieman', 'preprocessed', 'regress', 'rest', 'rmse_mn', 'rmse_sd', 'satellite', 'space-T1w', 'stopsignal', 'taskswitch', 'volume']",2020-02-25T00:38:07.035Z,[],['5e546c265b9d90396f72dac4'],"[{'docker': False, '_id': '5be75b31e15a02914a4be8f0', 'ui': 'raw', 'name': 'File Viewer', 'desc': ""Browse / download files via Brain-Life's File Browser"", 'avatar': 'https://brainlife.io/images/ui-logos/raw.png'}]",True,"
# `index.json`

`/csv` directory contains any number of .csv files. `index.json` is used to describe each .csv files. It looks like this

```
[
    {
        ""filename"": ""correlation.csv"",
        ""unit"": ""xyz^3"",
        ""name"": ""corrleation between 2 parc"",
        ""desc"": ""edit me""
    }
]
```

# `label.json`

Describes what each column/row corresponds to (in the same order of the column/row in the correlation.csv). It hould look like this.

```
[
    {
        ""name"": ""self-loop"",
        ""desc"": ""index(x,x) is the diagonal""
    },
    {
        ""name"": ""lh.Background+FreeSurfer_Defined_Medial_Wall.label"",
        ""label"": ""1001"",
        ""voxel_value"": 1
    },
    {
        ""name"": ""lh.17Networks_LH_VisCent_Striate.label"",
        ""label"": ""1002"",
        ""voxel_value"": 2
    },
    {
        ""name"": ""lh.17Networks_LH_VisCent_ExStr.label"",
        ""label"": ""1003"",
        ""voxel_value"": 3
    },
...
]
```",,,,,{'code': 'ObjectId() { }'}
594c688bfa1d2e5a1f0e33f1,neuro/conneval,Output Connectome Evaluator,"[{'_id': '643852d4b32aa6e00a16839d', 'id': 'output', 'filename': 'out.json', 'required': True}]",['1'],1,[],2020-09-08T15:43:02.940Z,[],[],"[{'docker': False, '_id': '5be75b31e15a02914a4be8f0', 'ui': 'raw', 'name': 'File Viewer', 'desc': ""Browse / download files via Brain-Life's File Browser"", 'avatar': 'https://brainlife.io/images/ui-logos/raw.png'}, {'docker': False, '_id': '5bf75654e15a02914af8f5c1', 'ui': 'conneval', 'name': 'Connectome Evaluator', 'desc': 'Display results from connectome evaluator showing the quality of your connectome data determined by LiFE', 'avatar': 'https://brainlife.io/images/ui-logos/conneval.png'}]",False,,,"[{'id': 'subject', 'type': 'string', 'required': True}]",,,
5c58aa5ef9109beac4b52f61,neuro/cortexmap,Cortext Mapping,"[{'_id': '5df15c1f2d1c25f06d92b89f', 'id': 'cortexmap', 'dirname': 'cortexmap', 'required': True}]",['1'],16,"['averaged', 'freesurfer_longitudinal', 'gray_matter_density', 'myelin_mapping', 'resampled', 'structural_derivatives', 't1-t2-ratio']",2019-12-11T21:14:07.739Z,[],[],"[{'docker': False, '_id': '5be75b31e15a02914a4be8f0', 'ui': 'raw', 'name': 'File Viewer', 'desc': ""Browse / download files via Brain-Life's File Browser"", 'avatar': 'https://brainlife.io/images/ui-logos/raw.png'}, {'_id': '5df153f28bb79170e29d8b83', 'ui': 'wb_view', 'name': 'Connectome Workbench', 'desc': 'Vis tool used to map neuroimaging data, especially data generated by the Human Connectome Project.', 'avatar': 'https://www.humanconnectome.org/storage/app/media/news/2014/09/Screen-shot-2014-09-10-at-2.52.13-PM.png', 'docker': True}]",False,todo,,,,,
5c536bf0f9109beac46adb45,neuro/csd,CSD responses containing multiple lmaxN.nii.gz,"[{'_id': '5db317568aeeee7631f2874b', 'id': 'response', 'filename': 'response.txt', 'required': True}, {'_id': '5db317568aeeee5b9bf2874a', 'id': 'lmax2', 'filename': 'lmax2.nii.gz', 'required': False}, {'_id': '5db317568aeeee5cf0f28749', 'id': 'lmax4', 'filename': 'lmax4.nii.gz', 'required': False}, {'_id': '5db317568aeeee82bff28748', 'id': 'lmax6', 'filename': 'lmax6.nii.gz', 'required': False}, {'_id': '5db317568aeeee229bf28747', 'id': 'lmax8', 'filename': 'lmax8.nii.gz', 'required': False}, {'_id': '5db317568aeeee2759f28746', 'id': 'lmax10', 'filename': 'lmax10.nii.gz', 'required': False}, {'_id': '5db317568aeeee5faff28745', 'id': 'lmax12', 'filename': 'lmax12.nii.gz', 'required': False}, {'_id': '5db317568aeeee9a4ff28744', 'id': 'lmax14', 'filename': 'lmax14.nii.gz', 'required': False}]","['41', '1']",17,"['AP', 'PA', 'SENSE', 'aligned_dtiinit', 'b0', 'brain_extracted', 'extracted_volumes', 'full_sequence', 'image_24', 'image_3', 'image_30', 'image_30a', 'image_31', 'image_32', 'image_33', 'image_34', 'image_35', 'image_5', 'merged', 'mrtrix2', 'new_sequence', 'normalized', 'preprocessed', 'raw', 'session 1', 'session_1', 'session_2', 'single_shell', 't1_aligned']",2019-10-25T15:40:06.086Z,[],['5d7c0635f59daffc868c3818'],"[{'docker': False, '_id': '5be75b31e15a02914a4be8f0', 'ui': 'raw', 'name': 'File Viewer', 'desc': ""Browse / download files via Brain-Life's File Browser"", 'avatar': 'https://brainlife.io/images/ui-logos/raw.png'}]",False,,,,,,
5afe38b15858d874a48650a6,neuro/dp/optimal,Optimal Fitting by DP,"[{'_id': '643852d4b32aa6e00a1683a7', 'id': 'fe_optimal', 'filename': 'fe_optimal.mat', 'desc': 'result of optimal fitting by dp', 'ext': '.mat', 'required': True}, {'_id': '643852d4b32aa6e00a1683a8', 'id': 'info', 'filename': 'info.mat', 'desc': 'fitting info', 'ext': '.mat', 'required': True}]",['1'],1,[],2020-09-08T15:43:02.952Z,[],[],"[{'docker': False, '_id': '5be75b31e15a02914a4be8f0', 'ui': 'raw', 'name': 'File Viewer', 'desc': ""Browse / download files via Brain-Life's File Browser"", 'avatar': 'https://brainlife.io/images/ui-logos/raw.png'}]",False,,,,,,
5f6957e2cfa3659a64c96606,neuro/dsistudio/fib,"The FIB file (*.fib.gz) stores the vector field (fiber orientations) and anisotropy information (the magnitude) that can be used by DSI Studio to conduct fiber tracking. The FIB files are MATLAB matrix file stored in V4 version. The fib.gz files are the FIB files compressed by gzip. To load an FIB file into Matlab, extract the *.fib.gz file into an uncompressed .fib file. Then rename the .fib file to .mat file and load it using Matlab. ","[{'_id': '5f69582ecfa365d454c96607', 'id': 'fib', 'desc': '', 'required': True, 'filename': 'fib.gz'}, {'_id': '5f6baa42cfa3654311ca5e8a', 'id': 'mapping', 'desc': '', 'required': False, 'filename': 'inv.mapping.gz'}]","['1179', '1']",9,[],2020-09-22T01:48:18.276Z,[],['5f748af34ad0a67312f50f8f'],"[{'docker': False, '_id': '5be75b31e15a02914a4be8f0', 'ui': 'raw', 'name': 'File Viewer', 'desc': ""Browse / download files via Brain-Life's File Browser"", 'avatar': 'https://brainlife.io/images/ui-logos/raw.png'}, {'_id': '5f724b403ad30ab2f0c0ce5e', 'ui': 'dsistudio', 'name': 'dsi-studio', 'desc': 'DSI Studio is a tractography software tool that maps brain connections and correlates findings with neuropsychological disorders.', 'avatar': 'https://raw.githubusercontent.com/brainlife/brainlife.hugo/master/static/images/ui-logos/dsi_studio.png', 'docker': True}]",False,"The following is a list of matrix used in the SRC file.
 
dimension
    A 1-by-3 vector storing the dimension of the containing image. 

voxel_size
    A 1-by-3 vector storing the voxel size in mm.

fa0, fa1, fa2,...

The fa0, fa1,... matrices are image volume recording the anisotropy values of the first fiber (fa0), second fiber (fa1) ...etc. Note that a voxel can have multiple fiber orientations. These FA matrices are originally three-dimensional matrices but stored as one-dimensional vectors. To restore the matrix back to three-dimensional, use the following command.

```
fa0 = reshape(fa0,dimension);
```

If there is no fiber resolved in a voxel, the corresponding FA value is assigned by zero. Note that in DSI, QBI, and GQI reconstruction, the fa matrices stores the QA values (The definition of QA is documented in Yet et al., ""generalized q-sampling imaging"", IEEE TMI, 2010), not the FA value. These fa matrices will be used as the fiber termination threshold to determine the end point of the tracks.

Any matrix stored with a dimension of 1-by-n will be viewed as the quantitative measurements if n matches the total image volume. You can store any mapping such as ""gfa"", ""diffusivity"", ""t1_map"" and DSI Studio can use them in track specific analysi

index0, index1, index2,...
  
    These index matrices store the ""directional index"" of the fiber orientation instead of the full orientation vector. For example: 

```
%the 1st fiber orientation at coordinate (10,10,10) stored as dir0
index0 = reshape(index0,dimension);
dir0 = odf_vertices(:,index0(10,10,10)+1);

%the 2nd fiber orientation at coordinate (10,10,10) stored as dir1
index1 = reshape(index1,dimension);
dir1 = odf_vertices(:,index1(10,10,10)+1);
```
    
    The orientation table is stored in a matrix named odf_vertices. The index is zero based. For instance, if a voxel's index0 value is 5, the voxel's first fiber has an orientation of odf_vertices(:,5+1).

    DSI Studio also supports storing the directional vector instead of directional index. The directional vectors will be stored by ""dir0"", ""dir1"" ..etc. Each has a dimension of 3xN.

    dir0 is the directional vector of the most prominent fiber, and dir1 is the vector of the second most prominent fiber. These matrices have to be ""reshaped"" to restore to its original form:

```
 dir0 = reshape(dir0,[3 dimension]);
```

    This will make it a 3-by-x-by-y-by-z matrix. 

    To determine the number of fibers in a voxel, we need to refer to fa0, fa1, fa2...etc. For example, if a voxel has two fibers, its fa0 and fa1 have nonzero values, whereas fa2, fa3,... are zero. 

ODF information (optional)

odf1, odf2, ....
     The ODF values of each voxel can also be exported from DSI Studio. To get the ODF data, check the ""output ODF"" check box in advance option of the reconstruction window. DSI Studio will store a series of matrices named odf1, odf2,.... For each these odf matrices, the dimension is e.g. 321-by-20000. 321 is the dimension of an ODF vector (the actual value depends on the ODF order), and 20000 is the number of the ODFs stored. Note that only the ODFs from the voxels with QA > 0 or FA > 0 are stored.

     For more detail about how to use the ODF matrix and visualize them, please refer to the ODF visualization document. If you are using the ODFs calculated from QSDR, you may also need to look into this document to handle the discrepancy between ODF counts and a number of voxels with qa > 0.

Example: load a fib.gz file and get the information

```
function [fa index odf_vertices odf_faces]= read_fib(file_name)
if ~exist('file_name')
    file_name =  uigetfile('*.fib.gz');
end
if file_name == 0
    image = [];
    return
end
gunzip(file_name);
[pathstr, name, ext] = fileparts(file_name);
movefile(name,strcat(name,'.mat'));
fib = load(strcat(name,'.mat'));

max_fib = 0;
for i = 1:10
    if isfield(fib,strcat('fa',int2str(i-1)))
        max_fib = i;
    else
        break;
    end
end

fa = zeros([fib.dimension max_fib]);
index = zeros([fib.dimension max_fib]);

for i = 1:max_fib
    eval(strcat('fa(:,:,:,i) = reshape(fib.fa',int2str(i-1),',fib.dimension);'));
    eval(strcat('index(:,:,:,i) = reshape(fib.index',int2str(i-1),',fib.dimension);'));
end

odf_vertices = fib.odf_vertices;
odf_faces = fib.odf_faces;
delete(strcat(name,'.mat'));
end
```

The odf_vertices matrix stores the ODF sampling orientations table. This table stores sampling orientations that are equally-distributed (almost) on a sphere with the radius of one. You can use the table generated from DSI Studio or any table you prefer. The odf_face matrix indicates which three orientations forms a triangle on an ODF. YOU may use the one generated from DSI Studio. The exemplary table can be download at the bottom of this page.
Examples:
Get the fiber orientation at coordinate (x,y,z)

```
% decompress the fib.gz to fib file
% the (x,y,z) coordinates starts from (0,0,0)
load xxx.fib
index0 = reshape(index0,dimension);
fiber_orientation = odf_vertices(:,index0(x+1,y+1,z+1)+1);
```

Save an FIB file

     Similar to saving .src file, users can save the .fib file using the ""save xxx.fib -v4"" command. The generated .fib files are readily loadable in DSI Studio. Note that some matricies are required in a .fib file, including the dimension (matrix named ""dimension""), voxel size (matrix named ""voxel_size""), fiber directions (dir0, dir1, dir2 or index0, index1, index2), and fiber anisotropy (fa0, fa1, fa2). ODF information is in optional and can be left out.
",,,,,
5f6956d9cfa365c3dcc965ec,neuro/dsistudio/src,"The SRC file (*.src, *.src.gz) stores the diffusion weighted images and b-table that can be used to do reconstruction. The SRC files are MATLAB matrix file stored in V4 version. The src.gz is the SRC file compressed by gzip. To load an SRC file in MATLAB, uncompress the file and rename it as .mat.","[{'_id': '5f6956d9cfa365041ec965ed', 'id': 'src', 'desc': '', 'required': True, 'filename': 'src.gz'}]","['1179', '1']",7,[],2020-09-22T01:43:53.867Z,[],['5f733f0b3bc35c681d8689b4'],"[{'docker': False, '_id': '5be75b31e15a02914a4be8f0', 'ui': 'raw', 'name': 'File Viewer', 'desc': ""Browse / download files via Brain-Life's File Browser"", 'avatar': 'https://brainlife.io/images/ui-logos/raw.png'}, {'_id': '5f724b403ad30ab2f0c0ce5e', 'ui': 'dsistudio', 'name': 'dsi-studio', 'desc': 'DSI Studio is a tractography software tool that maps brain connections and correlates findings with neuropsychological disorders.', 'avatar': 'https://raw.githubusercontent.com/brainlife/brainlife.hugo/master/static/images/ui-logos/dsi_studio.png', 'docker': True}]",False,"> http://dsi-studio.labsolver.org/Manual/export-data-to-matlab

An SRC file stores the raw image volumes in addition to image dimension, voxel size, and b-table (see how to get .src file). The SRC files are MATLAB matrix file stored in V4 version. To load an SRC file into Matlab, extract .src.gz file to create an uncompressed .src file. Then rename the .src file to .mat file and load it in Matlab. The meanings of each exported matrix are explained as follows.

The following is a list of matrix used in the SRC file.

dimension
    A 1-by-3 vector storing the dimension of the containing image.

voxel_size
    A 1-by-3 vector storing the voxel size in mm.

image0~imageN
    The images extracted from DICOM or NIFTI files. These matrices can be restored to a 3-dimensional image volume by the command ""reshape(image0,dimension);""

b-table
    The b-table of the extracted images. b(1,:) stores b-value, whereas b(2:4,:) stores gradient vector.

After loading the .src file in Matlab, the user can process the data and save it back to an SRC file using ""save('filename.src','-v4');"" Note that you have to specify '-v4' so that DSI Studio can read the .src file.",,,,,
5f6954c7cfa36577f4c96595,neuro/dsistudio/tinytrack,"The TinyTrack (*.tt.gz) file is a track format used in DSI Studio to store track coordinates. The TT files are MATLAB matrix file stored in V4 version. The tt.gz files are the TT files compressed by gzip. To load a TT file into Matlab, extract the *.tt.gz file into an uncompressed .tt file. Then rename the .tt file to .mat file and load it using Matlab. ","[{'_id': '5f6954c7cfa365d912c96596', 'id': 'tt', 'desc': '', 'required': True, 'filename': 'tt.gz'}]","['1179', '1']",10,[],2020-09-22T01:35:03.645Z,[],['5f748d4b0b0159119bc9077a'],"[{'docker': False, '_id': '5be75b31e15a02914a4be8f0', 'ui': 'raw', 'name': 'File Viewer', 'desc': ""Browse / download files via Brain-Life's File Browser"", 'avatar': 'https://brainlife.io/images/ui-logos/raw.png'}, {'_id': '5f724b403ad30ab2f0c0ce5e', 'ui': 'dsistudio', 'name': 'dsi-studio', 'desc': 'DSI Studio is a tractography software tool that maps brain connections and correlates findings with neuropsychological disorders.', 'avatar': 'https://raw.githubusercontent.com/brainlife/brainlife.hugo/master/static/images/ui-logos/dsi_studio.png', 'docker': True}]",False,"> http://dsi-studio.labsolver.org/Manual/export-data-to-matlab

The following is a list of matrix used in TT file:

## dimension

A 1-by-3 vector storing the dimension of the containing image. 

## voxel_size

A 1-by-3 vector storing the voxel size in mm.
 
## track

A int8 array storing the coordinates. The array has the following format

[16-byte track header][3 x n_1 bytes of track data][16-byte track header][3 x n_2 bytes of track data]...

The 16-byte header stores 4 bytes of coordinate count, followed (x,y,z) of the first coodinate multiplied by 32 and converted to 32-bit signed integer.
   
```
   struct {
        uint32_t count;    // number of coordinates
        int32_t x;         // first coordinate (x*32,y*32,z*32)
        int32_t y; 
        int32_t z; 
        } h;
 ```

The track data are series of coodinates intervals (dx1,dy1,dz1)(dx2,dy2,dz2) multiplied by 32 and converted to 8-bit signed integer.

For example, the first track coordinates is (x,y,z)/32, and the second coodinates is calculated by { (x,y,z) + (dx1,dy1,dz1) }/32",,,,,
5f6a9c7ecfa365847cc9dc75,neuro/dsistudio/tinytrack-s,multi-file version of track/tinytrack. It contains multiple *.tt.gz inside a single directory,"[{'_id': '5f6a9c7ecfa365569dc9dc76', 'id': 'tts', 'desc': '', 'required': True, 'dirname': 'tts'}]",['1'],5,[],2020-09-23T00:53:18.902Z,[],[],"[{'docker': False, '_id': '5be75b31e15a02914a4be8f0', 'ui': 'raw', 'name': 'File Viewer', 'desc': ""Browse / download files via Brain-Life's File Browser"", 'avatar': 'https://brainlife.io/images/ui-logos/raw.png'}, {'_id': '5f724b403ad30ab2f0c0ce5e', 'ui': 'dsistudio', 'name': 'dsi-studio', 'desc': 'DSI Studio is a tractography software tool that maps brain connections and correlates findings with neuropsychological disorders.', 'avatar': 'https://raw.githubusercontent.com/brainlife/brainlife.hugo/master/static/images/ui-logos/dsi_studio.png', 'docker': True}]",False,,,,,,
5f6aa135cfa3656ab4c9e245,neuro/dsistudio/tractmeasures,Directory containing .tsv formatted tractmeasures,"[{'_id': '5f6aa135cfa365efdcc9e246', 'id': 'tractmeasures', 'desc': '', 'required': True, 'dirname': 'tractmeasures'}]",['1'],4,[],2020-09-23T01:13:25.905Z,[],[],"[{'docker': False, '_id': '5be75b31e15a02914a4be8f0', 'ui': 'raw', 'name': 'File Viewer', 'desc': ""Browse / download files via Brain-Life's File Browser"", 'avatar': 'https://brainlife.io/images/ui-logos/raw.png'}]",False,Edit me,,,,,
58cb234be13a50849b25882f,neuro/dtiinit,Folder structure containing all files generated by the VISTASOFT dtiInit.m,"[{'_id': '5e9634656365e929cb472313', 'id': 'output', 'dirname': '.', 'required': True}]",['1'],2,[],2020-04-14T22:08:37.680Z,[],['5e9631ed6365e90a074722c3'],"[{'docker': False, '_id': '5be75b31e15a02914a4be8f0', 'ui': 'raw', 'name': 'File Viewer', 'desc': ""Browse / download files via Brain-Life's File Browser"", 'avatar': 'https://brainlife.io/images/ui-logos/raw.png'}, {'docker': False, '_id': '5bf75573e15a02914af8ed65', 'ui': 't1pdd', 'name': 'dtiInit T1PDD', 'desc': 'Show T1 background and the principal diffusion directions as an RGB overlay', 'avatar': 'https://brainlife.io/images/ui-logos/dtiinit.png'}]",False,,,,,"{'_id': '5e96345b6365e9512e472311', 'maps': [{'_id': '5e9634656365e95e0d472314', 'src': 'dwi_aligned*.nii.gz', 'dest': 'dwi.nii.gz'}, {'_id': '5e9634656365e9caab472315', 'src': 'dwi_aligned*.bvecs', 'dest': 'dwi.bvecs'}, {'_id': '5e9634656365e9373f472316', 'src': 'dwi_aligned*.bvals', 'dest': 'dwi.bvals'}, {'_id': '5e9634656365e933e1472317', 'src': '_meta_', 'dest': 'dwi.json'}], 'derivatives': 'dwi'}",
58c33c5fe13a50849b25879b,neuro/dwi,"Diffusion-weighted magnetic resonance data (dMRI), saved in NIfTI-1 format.","[{'_id': '5dd857f7936ca314d2c57810', 'id': 'dwi', 'filename': 'dwi.nii.gz', 'ext': '.gz', 'required': True}, {'_id': '5dd857f7936ca314e2c5780f', 'id': 'bvecs', 'filename': 'dwi.bvecs', 'required': True}, {'_id': '5dd857f7936ca3e6a0c5780e', 'id': 'bvals', 'filename': 'dwi.bvals', 'required': True}, {'_id': '600b4b6cc9e1f5a62612b86b', 'id': 'sbref', 'desc': 'Single-band reference for one or more multi-band dwi images.', 'required': False, 'filename': 'sbref.nii.gz'}, {'_id': '600b4b6cc9e1f5229312b86c', 'id': 'sbref_json', 'desc': '', 'required': False, 'filename': 'sbref.json'}]","['16', '1']",40,"['2Merged?', '3Merged', '4Merged', '4_merged', '4merged', '7t', 'ACPC', 'AP', 'CHM', 'Control', 'GND_corrected', 'MPPCA', 'MotionCorrected', 'PA', 'SENSE', 'SOS', 'STGD', 'Unrung', 'aligned', 'aligned_dtiinit', 'aligned_dwi', 'ap', 'b0', 'blip', 'brain_extracted', 'clean', 'debiased', 'denoised', 'diffusion', 'dtag1', 'dtiinit', 'dwi', 'eddy', 'eddy_correct', 'eddy_unwarped', 'epi_reg', 'extracted_volumes', 'full_sequence', 'image_2', 'image_23', 'image_24', 'image_29', 'image_29a', 'image_3', 'image_30', 'image_30a', 'image_31', 'image_32', 'image_33', 'image_34', 'image_35', 'image_4', 'image_5', 'masked', 'merged', 'new_sequence', 'non_b0', 'normalized', 'old_sequence', 'org-dwi-1k-AP', 'org-dwi-1k-PA', 'org-dwi-2k-AP', 'org-dwi-2k-PA', 'org-dwi-300-AP', 'org-dwi-300-PA', 'pa', 'preprocessed', 'qsiprep', 'raw', 'resliced', 'run_1', 'run_2', 'sense', 'session 1', 'session_1', 'session_2', 'single_shell', 't1_aligned', 'unrotated_bvecs']",2019-11-22T21:49:43.326Z,"[{'_id': '5dd857f7936ca3084ac57816', 'datatype_tag': 'single_shell', 'desc': 'Only contains b0 and specific bvalue slices'}, {'_id': '5dd857f7936ca378a5c57815', 'datatype_tag': 'b0', 'desc': 'Only contains b0'}, {'_id': '5ed7e185da6645108b8ecf47', 'datatype_tag': 'preprocessed', 'desc': 'Image is preprocessed by various dwi preprocessing App, and in general, the image is aligned to the t1w from the same subject.'}]",['5d796fd303e8c96171eaed52'],"[{'docker': False, '_id': '5be75b31e15a02914a4be8f0', 'ui': 'raw', 'name': 'File Viewer', 'desc': ""Browse / download files via Brain-Life's File Browser"", 'avatar': 'https://brainlife.io/images/ui-logos/raw.png'}, {'_id': '5bf755e5e15a02914af8f194', 'ui': 'fslview', 'name': 'FSLView', 'desc': 'An old 2d/3d brain volume viewer. Replaced by fsleyes', 'avatar': 'https://brainlife.io/images/ui-logos/fslview.png', 'docker': True}, {'_id': '5bf755f4e15a02914af8f22b', 'ui': 'fsleyes', 'name': 'FSLeyes', 'desc': 'A 2d/3d brain volume viewer.', 'avatar': 'https://brainlife.io/images/ui-logos/fsleyes.png', 'docker': True}, {'_id': '5bf75608e15a02914af8f2e3', 'ui': 'mrview', 'name': 'mrView', 'desc': 'The MRtrix image viewer.', 'avatar': 'https://brainlife.io/images/ui-logos/mrview.png', 'docker': True}, {'_id': '5bf75623e15a02914af8f3d8', 'ui': 'mricrogl', 'name': 'MRIcroGL', 'desc': 'View 2D slices and renderings of your brain imaging data. It allows you to draw regions of interest which can aid lesion mapping and fMRI analysis.', 'avatar': 'https://brainlife.io/images/ui-logos/mricrogl.png', 'docker': True}, {'_id': '5bf75630e15a02914af8f44e', 'ui': 'fibernavigator', 'name': 'fiberNavigator', 'desc': 'A tool designed for a fast and versatile visualization of streamline datasets.', 'avatar': 'https://brainlife.io/images/ui-logos/fibernavigator.png', 'docker': True}, {'_id': '5bf7563de15a02914af8f4c5', 'ui': 'freeview-gpu', 'name': 'FreeView', 'desc': 'A freesurfer program used to view and work with structural, anatomical scans.', 'avatar': 'https://brainlife.io/images/ui-logos/freeview.png', 'docker': True}]",False,Used brainlife/validator-neuro-dwi for validator,brainlife/validator-neuro-dwi,,,"{'_id': '5dd857d0936ca38046c5780c', 'maps': [{'_id': '5dd857f7936ca3d362c57814', 'src': 'dwi.nii.gz', 'dest': 'dwi.nii.gz'}, {'_id': '5dd857f7936ca30300c57813', 'src': 'dwi.bvecs', 'dest': 'dwi.bvecs'}, {'_id': '5dd857f7936ca30e67c57812', 'src': 'dwi.bvals', 'dest': 'dwi.bvals'}, {'_id': '5dd857f7936ca38269c57811', 'src': '_meta_', 'dest': 'dwi.json'}], 'derivatives': 'dwi'}",
5ddf1381936ca39318c5f045,neuro/dwi/b0,b0 files extracted from dwi,"[{'id': 'dwi', 'filename': 'dwi.nii.gz', 'desc': '', 'required': True, '_id': '61d5d2df33cb3deb49821a50'}, {'id': 'bvecs', 'filename': 'dwi.bvecs', 'desc': '', 'required': True, '_id': '61d5d2df33cb3deb49821a51'}, {'id': 'bvals', 'filename': 'dwi.bvals', 'desc': '', 'required': True, '_id': '61d5d2df33cb3deb49821a52'}]","['1', '822']",6,"['1dnf', '2dnf', 'attention', 'attentionalblink', 'audiocuewalkingstudy', 'brainvision', 'edf', 'eegfmrinf', 'eeglab', 'eegnf', 'experiment', 'facerecognition', 'fmrinf', 'gonogo', 'mipre', 'motorloc', 'offline', 'offlinecatch', 'onlinereal', 'onlinesham', 'run3', 'run4', 'run5', 'run6', 'tmseeg1', 'tmseeg2', 'tmseegrest', 'washout']",2019-11-28T00:23:29.944Z,[],[],"[{'docker': False, '_id': '5be75b31e15a02914a4be8f0', 'ui': 'raw', 'name': 'File Viewer', 'desc': ""Browse / download files via Brain-Life's File Browser"", 'avatar': 'https://brainlife.io/images/ui-logos/raw.png'}, {'_id': '5bf755f4e15a02914af8f22b', 'ui': 'fsleyes', 'name': 'FSLeyes', 'desc': 'A 2d/3d brain volume viewer.', 'avatar': 'https://brainlife.io/images/ui-logos/fsleyes.png', 'docker': True}, {'_id': '5bf755e5e15a02914af8f194', 'ui': 'fslview', 'name': 'FSLView', 'desc': 'An old 2d/3d brain volume viewer. Replaced by fsleyes', 'avatar': 'https://brainlife.io/images/ui-logos/fslview.png', 'docker': True}]",True,"We normally store b0 as another neuro/dwi, but this datatype is registered to be ""Analysis"" datatype which means you can access the data through brainlife's group analysis / jupyter notebook.",,,,,
60007567aacf9e1615a691dd,neuro/eeg/bdf,EEG / Biosemi data forma,"[{'_id': '60007567aacf9e6a5aa691de', 'id': 'bdf', 'desc': '', 'required': True, 'filename': 'eeg.bdf'}, {'_id': '6006fed9af402b72a8483f85', 'id': 'channels', 'desc': 'This file is RECOMMENDED as it provides easily searchable information across BIDS datasets for for example, general curation, response to queries or batch analysis. The required columns are channel name, type and units in this specific order. To avoid confusion, the channels SHOULD be listed in the order they appear in the EEG data file. Any number of additional columns may be added to provide additional information about the channels. Note that electrode positions SHOULD NOT be added to this file, but to *_electrodes.tsv. Please see https://bids-specification.readthedocs.io/en/stable/04-modality-specific-files/03-electroencephalography.html#channels-description-_channelstsv', 'required': False, 'filename': 'channels.tsv'}, {'_id': '600700b0af402b03fb484038', 'id': 'electrodes', 'desc': 'File that gives the location of EEG electrodes. Note that coordinates are expected in cartesian coordinates according to the EEGCoordinateSystem and EEGCoordinateUnits fields in *_coordsystem.json. If an *_electrodes.tsv file is specified, a *_coordsystem.json file MUST be specified as well. The order of the required columns in the *_electrodes.tsv file MUST be as listed below.', 'required': False, 'filename': 'electrodes.tsv'}, {'_id': '6007042caf402b710b4841cd', 'id': 'coordsystem', 'desc': 'A *_coordsystem.json file is used to specify the fiducials, the location of anatomical landmarks, and the coordinate system and units in which the position of electrodes and landmarks is expressed. The *_coordsystem.json is REQUIRED if the optional *_electrodes.tsv is specified. If a corresponding anatomical MRI is available, the locations of landmarks and fiducials according to that scan should also be stored in the *_T1w.json file which goes alongside the MRI data.', 'required': False, 'filename': 'coordsystem.json'}, {'_id': '606f73a3c7f80a6a4e95572a', 'id': 'events', 'desc': '', 'required': False, 'filename': 'events.tsv'}, {'_id': '606f73a3c7f80a7d6795572b', 'id': 'events_json', 'desc': '', 'required': False, 'filename': 'events.json'}]","['1342', '1348', '1']",10,"['innerspeech', 'p300', 'rest']",2021-01-14T16:46:31.470Z,[],[],"[{'docker': False, '_id': '5be75b31e15a02914a4be8f0', 'ui': 'raw', 'name': 'File Viewer', 'desc': ""Browse / download files via Brain-Life's File Browser"", 'avatar': 'https://brainlife.io/images/ui-logos/raw.png'}]",False,,,,,,
6000753eaacf9e6591a691d9,neuro/eeg/brainvision,"EEG / BrainVision Core Data Format (.vhdr, .vmrk, .eeg)","[{'_id': '6000753eaacf9ecbc5a691da', 'id': 'eeg', 'desc': '', 'required': True, 'filename': 'eeg.eeg'}, {'_id': '6000753eaacf9e6e6ca691db', 'id': 'vhdr', 'desc': '', 'required': True, 'filename': 'eeg.vhdr'}, {'_id': '6000753eaacf9e8681a691dc', 'id': 'vmrk', 'desc': '', 'required': True, 'filename': 'eeg.vmrk'}, {'_id': '6006fec8af402bbd9e483f83', 'id': 'channels', 'desc': 'This file is RECOMMENDED as it provides easily searchable information across BIDS datasets for for example, general curation, response to queries or batch analysis. The required columns are channel name, type and units in this specific order. To avoid confusion, the channels SHOULD be listed in the order they appear in the EEG data file. Any number of additional columns may be added to provide additional information about the channels. Note that electrode positions SHOULD NOT be added to this file, but to *_electrodes.tsv.', 'required': False, 'filename': 'channels.tsv'}, {'_id': '60070140af402b17b548409d', 'id': 'electrodes', 'desc': 'File that gives the location of EEG electrodes. Note that coordinates are expected in cartesian coordinates according to the EEGCoordinateSystem and EEGCoordinateUnits fields in *_coordsystem.json. If an *_electrodes.tsv file is specified, a *_coordsystem.json file MUST be specified as well. The order of the required columns in the *_electrodes.tsv file MUST be as listed below.', 'required': False, 'filename': 'electrodes.tsv'}, {'_id': '600703f3af402b82784841c0', 'id': 'coordsystem', 'desc': 'A *_coordsystem.json file is used to specify the fiducials, the location of anatomical landmarks, and the coordinate system and units in which the position of electrodes and landmarks is expressed. The *_coordsystem.json is REQUIRED if the optional *_electrodes.tsv is specified. If a corresponding anatomical MRI is available, the locations of landmarks and fiducials according to that scan should also be stored in the *_T1w.json file which goes alongside the MRI data.', 'required': False, 'filename': 'coordsystem.json'}, {'_id': '606f73c9c7f80a22ba955732', 'id': 'events', 'desc': '', 'required': False, 'filename': 'events.tsv'}, {'_id': '606f73c9c7f80aee9c955733', 'id': 'events_json', 'desc': '', 'required': False, 'filename': 'events.json'}]","['1342', '1348', '1']",19,"['1dnf', '2dnf', 'appleseedexample', 'attentionalblink', 'cnos', 'ctos', 'eegfmrinf', 'eegnf', 'fmrinf', 'main', 'mipost', 'mipre', 'motorloc', 'picturesnaming', 'proposer', 'responder', 'rest', 'rsvp', 'sleep', 'unknown']",2021-01-14T16:45:50.848Z,[],[],"[{'docker': False, '_id': '5be75b31e15a02914a4be8f0', 'ui': 'raw', 'name': 'File Viewer', 'desc': ""Browse / download files via Brain-Life's File Browser"", 'avatar': 'https://brainlife.io/images/ui-logos/raw.png'}]",False,"https://bids-specification.readthedocs.io/en/stable/04-modality-specific-files/03-electroencephalography.html#electroencephalography

For the content of channels and electrodes, please see https://bids-specification.readthedocs.io/en/stable/04-modality-specific-files/03-electroencephalography.html#channels-description-_channelstsv",,,,,
600074f6aacf9e7acda691d7,neuro/eeg/edf,Electroencephalography (EEG) / EDF - European Data format (.edf),"[{'_id': '600074f6aacf9e6a93a691d8', 'id': 'edf', 'desc': '', 'required': True, 'filename': 'eeg.edf'}, {'_id': '6006feb1af402b1a27483f5c', 'id': 'channels', 'desc': 'This file is RECOMMENDED as it provides easily searchable information across BIDS datasets for for example, general curation, response to queries or batch analysis. The required columns are channel name, type and units in this specific order. To avoid confusion, the channels SHOULD be listed in the order they appear in the EEG data file. Any number of additional columns may be added to provide additional information about the channels. Note that electrode positions SHOULD NOT be added to this file, but to *_electrodes.tsv.', 'required': False, 'filename': 'channels.tsv'}, {'_id': '60070108af402baab248407b', 'id': 'electrodes', 'desc': 'File that gives the location of EEG electrodes. Note that coordinates are expected in cartesian coordinates according to the EEGCoordinateSystem and EEGCoordinateUnits fields in *_coordsystem.json. If an *_electrodes.tsv file is specified, a *_coordsystem.json file MUST be specified as well. The order of the required columns in the *_electrodes.tsv file MUST be as listed below.', 'required': False, 'filename': 'electrodes.tsv'}, {'_id': '6007040faf402b70c84841c4', 'id': 'coordsystem', 'desc': 'A *_coordsystem.json file is used to specify the fiducials, the location of anatomical landmarks, and the coordinate system and units in which the position of electrodes and landmarks is expressed. The *_coordsystem.json is REQUIRED if the optional *_electrodes.tsv is specified. If a corresponding anatomical MRI is available, the locations of landmarks and fiducials according to that scan should also be stored in the *_T1w.json file which goes alongside the MRI data.', 'required': False, 'filename': 'coordsystem.json'}, {'_id': '606f7365c7f80a0a5595571d', 'id': 'events', 'desc': '', 'required': False, 'filename': 'events.tsv'}, {'_id': '606f7365c7f80a4e9995571e', 'id': 'events_json', 'desc': '', 'required': False, 'filename': 'events.json'}]","['1342', '1348', '1']",15,"['classicalmusic', 'foodchoice', 'genmusic01', 'genmusic02', 'genmusic03', 'hfo', 'imagechoice', 'offline', 'offlinecatch', 'onlinereal', 'onlinesham', 'rest', 'resteyesc', 'run1', 'run2', 'run3', 'run4', 'run5', 'run6', 'washout', 'wordchoice']",2021-01-14T16:44:38.509Z,[],[],"[{'docker': False, '_id': '5be75b31e15a02914a4be8f0', 'ui': 'raw', 'name': 'File Viewer', 'desc': ""Browse / download files via Brain-Life's File Browser"", 'avatar': 'https://brainlife.io/images/ui-logos/raw.png'}]",False,"https://bids-specification.readthedocs.io/en/stable/04-modality-specific-files/03-electroencephalography.html#electroencephalography


For the content of channels and electrodes, please see https://bids-specification.readthedocs.io/en/stable/04-modality-specific-files/03-electroencephalography.html#channels-description-_channelstsv",,,,,
60007410aacf9e4edda691d4,neuro/eeg/eeglab,The format used by MATLAB toolbox EEGLAB (.set and .fdt),"[{'_id': '60007410aacf9e4a04a691d5', 'id': 'fdt', 'desc': '', 'required': True, 'filename': 'eeg.fdt'}, {'_id': '60007410aacf9e2ad9a691d6', 'id': 'set', 'desc': '', 'required': True, 'filename': 'eeg.set'}, {'_id': '6006fedcaf402b1289483f88', 'id': 'channels', 'desc': 'This file is RECOMMENDED as it provides easily searchable information across BIDS datasets for for example, general curation, response to queries or batch analysis. The required columns are channel name, type and units in this specific order. To avoid confusion, the channels SHOULD be listed in the order they appear in the EEG data file. Any number of additional columns may be added to provide additional information about the channels. Note that electrode positions SHOULD NOT be added to this file, but to *_electrodes.tsv.', 'required': False, 'filename': 'channels.tsv'}, {'_id': '60070160af402b559e4840aa', 'id': 'electrodes', 'desc': 'File that gives the location of EEG electrodes. Note that coordinates are expected in cartesian coordinates according to the EEGCoordinateSystem and EEGCoordinateUnits fields in *_coordsystem.json. If an *_electrodes.tsv file is specified, a *_coordsystem.json file MUST be specified as well. The order of the required columns in the *_electrodes.tsv file MUST be as listed below.', 'required': False, 'filename': 'electrodes.tsv'}, {'_id': '60070423af402b6a8a4841c9', 'id': 'coordsystem', 'desc': 'A *_coordsystem.json file is used to specify the fiducials, the location of anatomical landmarks, and the coordinate system and units in which the position of electrodes and landmarks is expressed. The *_coordsystem.json is REQUIRED if the optional *_electrodes.tsv is specified. If a corresponding anatomical MRI is available, the locations of landmarks and fiducials according to that scan should also be stored in the *_T1w.json file which goes alongside the MRI data.', 'required': False, 'filename': 'coordsystem.json'}, {'_id': '606f7380c7f80a8dcd955724', 'id': 'events', 'desc': '', 'required': False, 'filename': 'events.tsv'}, {'_id': '606f7380c7f80a78bc955725', 'id': 'events_json', 'desc': '', 'required': False, 'filename': 'events.json'}]","['1342', '1348', '1']",21,"['5ccptxpstxamphetamine', 'attendedspeakerparadigmownname', 'attention', 'auditoryoddballchords', 'auditoryvisualshift', 'faceperception', 'facerecognition', 'gonogo', 'gxtesctt', 'imaginedemotion', 'reinforcementlearning', 'rest', 'simonconflict', 'threearmedbandit', 'visualworkingmemory']",2021-01-14T16:40:48.726Z,[],[],"[{'docker': False, '_id': '5be75b31e15a02914a4be8f0', 'ui': 'raw', 'name': 'File Viewer', 'desc': ""Browse / download files via Brain-Life's File Browser"", 'avatar': 'https://brainlife.io/images/ui-logos/raw.png'}]",False,"https://bids-specification.readthedocs.io/en/stable/04-modality-specific-files/03-electroencephalography.html#electroencephalography

For the content of channels and electrodes, please see https://bids-specification.readthedocs.io/en/stable/04-modality-specific-files/03-electroencephalography.html#channels-description-_channelstsv",,,,,
5dec20ff6c0bd9f84485779f,neuro/eeg/egi,EGI EEG datatype,"[{'id': 'egi', 'filename': 'eeg', 'desc': 'EGI data', 'required': True, '_id': '5dec20ff6c0bd91e1f8577a7'}]","['1', '1348']",30,"['bart', 'bold', 'fmriprep', 'pamret', 'rest', 'stopsignal', 'taskswitch']",2019-12-07T22:00:31.009Z,[],[],"[{'docker': False, '_id': '5be75b31e15a02914a4be8f0', 'ui': 'raw', 'name': 'File Viewer', 'desc': ""Browse / download files via Brain-Life's File Browser"", 'avatar': 'https://brainlife.io/images/ui-logos/raw.png'}]",False,Edit me,,,,,
5c390505f9109beac42b00df,neuro/fmap,"fieldmaps measure the magnetic field inhomogeniety. epi images often exhibit signal dropout and spatial distortion in regions where the magnetic field is inhomogenous (often around the fontal cortex and medial temporal lobe). We can not recover the lost signal, but we can attempt to undistort images using fieldmaps","[{'_id': '5db853e28aeeeeff86f2fd2e', 'id': 'phasediff', 'filename': 'phasediff.nii.gz', 'ext': '.gz', 'required': False, 'desc': 'for phasediff'}, {'_id': '5db853e28aeeee57e0f2fd2d', 'id': 'phasediff_json', 'filename': 'phasediff.json', 'required': False, 'ext': '.json', 'desc': 'for phasediff'}, {'_id': '5db853e28aeeeed343f2fd2c', 'id': 'magnitude', 'filename': 'magnitude.nii.gz', 'ext': '.gz', 'required': False, 'desc': 'for single'}, {'_id': '5f7f3d0d268f76704d2a659a', 'id': 'magnitude_json', 'desc': '', 'ext': '.json', 'required': False, 'filename': 'magnitude.json'}, {'_id': '5db853e28aeeee7044f2fd2b', 'id': 'magnitude1', 'filename': 'magnitude1.nii.gz', 'ext': '.gz', 'required': False, 'desc': 'for 2phasemag, phasediff'}, {'_id': '5f7f3d0d268f760b132a659b', 'id': 'magnitude1_json', 'desc': '', 'ext': '.json', 'required': False, 'filename': 'magnitude1.json'}, {'_id': '5db853e28aeeee50f4f2fd2a', 'id': 'magnitude2', 'filename': 'magnitude2.nii.gz', 'ext': '.gz', 'required': False, 'desc': 'for 2phasemag, phasediff(optional)'}, {'_id': '5f7f3d0d268f76b8db2a659c', 'id': 'magnitude2_json', 'desc': '', 'ext': '.json', 'required': False, 'filename': 'magnitude2.json'}, {'_id': '5db853e28aeeee0359f2fd29', 'id': 'fieldmap', 'filename': 'fieldmap.nii.gz', 'ext': '.gz', 'required': False, 'desc': 'for single'}, {'_id': '5db853e28aeeee80b1f2fd28', 'id': 'fieldmap_json', 'filename': 'fieldmap.json', 'ext': '.json', 'required': False, 'desc': 'for single'}, {'_id': '5db853e28aeeee7087f2fd27', 'id': 'phase1', 'filename': 'phase1.nii.gz', 'ext': '.gz', 'required': False, 'desc': 'for 2phasemag'}, {'_id': '5db853e28aeeee62d9f2fd26', 'id': 'phase1_json', 'filename': 'phase1.json', 'ext': '.json', 'required': False, 'desc': 'for 2phasemag'}, {'_id': '5db853e28aeeee5e2cf2fd25', 'id': 'phase2', 'filename': 'phase2.nii.gz', 'ext': '.gz', 'required': False, 'desc': 'for 2phasemag'}, {'_id': '5db853e28aeeeec617f2fd24', 'id': 'phase2_json', 'filename': 'phase2.json', 'ext': '.json', 'required': False, 'desc': 'for 2phasemag'}, {'_id': '5db853e28aeeee0e47f2fd23', 'id': 'epi1', 'filename': 'epi1.nii.gz', 'ext': '.gz', 'required': False, 'desc': 'for pepolar'}, {'_id': '5db853e28aeeee7c56f2fd22', 'id': 'epi1_json', 'filename': 'epi1.json', 'ext': '.json', 'required': False, 'desc': 'for pepolar'}, {'_id': '5db853e28aeeee5382f2fd21', 'id': 'epi2', 'filename': 'epi2.nii.gz', 'required': False, 'ext': '.gz', 'desc': 'for pepolar'}, {'_id': '5db853e28aeeee40ebf2fd20', 'id': 'epi2_json', 'filename': 'epi2.json', 'required': False, 'ext': '.json', 'desc': 'for pepolar'}]",['1'],15,"['2phasemag', 'AP', 'PA', 'epi', 'pepolar', 'phasediff', 'single']",2019-10-29T14:59:46.732Z,"[{'_id': '5db853e28aeeee20d6f2fd41', 'datatype_tag': '2phasemag', 'desc': 'Case 2: Two phase images and two magnitude images. \n\nphase1, phase2, magnitude1, magnitude2 should be present. \n\nSimilar to the case1, but instead of a precomputed phase difference map two separate phase images are\npresented. The two sidecar JSON file need to specify corresponding EchoTime values. For example:\n{\n""EchoTime"": 0.00746,\n""IntendedFor"": ""<brainlife dataset ID for bold>""\n}'}, {'_id': '5db853e28aeeeeb3e9f2fd40', 'datatype_tag': 'phasediff', 'desc': ' Case 1: Phase difference image and at least one magnitude image. phasediff and magnitude1 should be present.\n\nmagnitude2 is optional. EchoTime1 and EchoTime2 should be set in metadata.\n\nThis is a common output for build in fieldmap sequence on Siemens scanners. In this particular case the sidecar\nJSON file has to define the Echo Times of the two phase images used to create the difference image. EchoTime1\ncorresponds to the shorter echo time and EchoTime2 to the longer echo time. Similarly _magnitude1 image\ncorresponds to the shorter echo time and the OPTIONAL _magnitude2 image to the longer echo time. For example:\n{\n""EchoTime1"": 0.00600,\n""EchoTime2"": 0.00746,\n""IntendedFor"": ""<brainlife dataset ID for bold>""\n}'}, {'_id': '5db853e28aeeee64a5f2fd3f', 'datatype_tag': 'single', 'desc': 'Case 3: A single, real fieldmap image (showing the field inhomogeneity in each voxel).  \n\nmagnitude and fieldmap should be present\n\nIn some cases (for example GE) the scanner software will output a precomputed fieldmap denoting the B0\ninhomogeneities along with a magnitude image used for coregistration. In this case the sidecar JSON file needs to\ninclude the units of the fieldmap. The possible options are: “Hz”, “rad/s”, or “Tesla”. For example:\n{\n""Units"": ""rad/s"",\n""IntendedFor"": ""<brainlife dataset ID for bold>""\n}'}, {'_id': '5db853e28aeeee1934f2fd3e', 'datatype_tag': 'pepolar', 'desc': 'Case 4: Multiple phase encoded directions (“pepolar”)\n\nepi1.nii.gz and epi2.nii.gz should be present.\n\nThe phase-encoding polarity (PEpolar) technique combines two or more Spin Echo EPI scans with different phase\nencoding directions to estimate the underlying inhomogeneity/deformation map. Examples of tools using this kind\nof images are FSL TOPUP, AFNI 3dqwarp and SPM . In such a case, the phase encoding direction is specified in the\ncorresponding JSON file as one of: “i”, “j”, “k”, “i-”, “j-, “k-”. For these differentially phase encoded sequences, one also\nneeds to specify the Total Readout Time defined as the time (in seconds) from the center of the first echo to the\ncenter of the last echo (aka “FSL definition” - see here and here how to calculate it). For example\n{\n""PhaseEncodingDirection"": ""j-"",\n""TotalReadoutTime"": 0.095,\n""IntendedFor"": ""<brainlife dataset ID for bold>""\n}\ndir_label value can be set to arbitrary alphanumeric label ([a-zA-Z0-9]+ for example “LR” or “AP”) that can help\nusers to distinguish between different files, but should not be used to infer any scanning parameters (such as phase\nencoding directions) of the corresponding sequence. Please rely only on the JSON file to obtain scanning\nparameters. _epi files can be a 3D or 4D - in the latter case all timepoints share the same scanning parameters. To\nindicate which run is intended to be used with which functional or diffusion scan the IntendedFor field in the\nJSON file should be used.'}]",['5d796fd303e8c90e5deaed4f'],"[{'docker': False, '_id': '5be75b31e15a02914a4be8f0', 'ui': 'raw', 'name': 'File Viewer', 'desc': ""Browse / download files via Brain-Life's File Browser"", 'avatar': 'https://brainlife.io/images/ui-logos/raw.png'}, {'_id': '5bf755f4e15a02914af8f22b', 'ui': 'fsleyes', 'name': 'FSLeyes', 'desc': 'A 2d/3d brain volume viewer.', 'avatar': 'https://brainlife.io/images/ui-logos/fsleyes.png', 'docker': True}]",False,"This datatype follows the BIDS fieldmap specification

> https://bids-specification.readthedocs.io/en/stable/04-modality-specific-files/01-magnetic-resonance-imaging-data.html#types-of-fieldmaps

Although all of the files in this datatypes are ""optional"", in reality, depending on which *case* the fmap uses, a different set of files are required.",brainlife/validator-fmap,,main,"{'_id': '5db8515c8aeeee4142f2fcaf', 'maps': [{'_id': '5db853e28aeeee28bef2fd3d', 'src': 'phasediff.nii.gz', 'dest': 'phasediff.nii.gz'}, {'_id': '5db853e28aeeee1c07f2fd3c', 'src': 'phasediff.json', 'dest': 'phasediff.json'}, {'_id': '5db853e28aeeee8ac7f2fd3b', 'src': 'magnitude1.nii.gz', 'dest': 'magnitude1.nii.gz'}, {'_id': '5db853e28aeeee9aadf2fd3a', 'src': 'magnitude2.nii.gz', 'dest': 'magnitude2.nii.gz'}, {'_id': '5db853e28aeeeee86bf2fd39', 'src': '_meta_', 'dest': 'fmap.json'}, {'_id': '5db853e28aeeee44cdf2fd38', 'src': 'fieldmap.nii.gz', 'dest': 'fieldmap.nii.gz'}, {'_id': '5db853e28aeeeec87ff2fd37', 'src': 'fieldmap.json', 'dest': 'fieldmap.json'}, {'_id': '5db853e28aeeee345cf2fd36', 'src': 'phase1.nii.gz', 'dest': 'phase1.nii.gz'}, {'_id': '5db853e28aeeee7be6f2fd35', 'src': 'phase1.json', 'dest': 'phase1.json'}, {'_id': '5db853e28aeeeec549f2fd34', 'src': 'phase2.nii.gz', 'dest': 'phase2.nii.gz'}, {'_id': '5db853e28aeeee44dbf2fd33', 'src': 'phase2.json', 'dest': 'phase2.json'}, {'_id': '5db853e28aeeee9ca2f2fd32', 'src': 'ap.epi.nii.gz', 'dest': 'dir-AP_epi.nii.gz'}, {'_id': '5db853e28aeeee124ef2fd31', 'src': 'ap.epi.json', 'dest': 'dir-AP_epi.json'}, {'_id': '5db853e28aeeee0189f2fd30', 'src': 'pa.epi.nii.gz', 'dest': 'dir-PA_epi.nii.gzz'}, {'_id': '5db853e28aeeeeef58f2fd2f', 'src': 'pa.epi.json', 'dest': 'dir-PA_epi.json'}], 'derivatives': 'fmap'}",
58cb22c8e13a50849b25882e,neuro/freesurfer,Folder structure generated by FreeSurfer recon-all process.,"[{'_id': '5dfd36f732bff080d8e281ee', 'id': 'output', 'dirname': 'output', 'required': True}]",['1'],30,"['1.25mm_brain', '3dSkullStrip', '7t', 'AC-PC aligned', 'ACPC', 'RAW', 'STGD', 'T1', 'T1w', 'acpc_aligned', 'anat', 'bias_corrected', 'bids_hcp', 'brain_extracted', 'crop_reorient', 'debiased', 'defaced', 'desc-preproc_T1w', 'fmriprep', 'hippocampal', 'image 5', 'image 7', 'image 8', 'image_10', 'image_3', 'image_5', 'image_7', 'longitudinal', 'norm', 'org-t1w', 'preprocessed', 'qsiprep', 'second 1', 'session 1', 'session 2', 'session_1', 'session_2', 'standard', 'thalamic_nuclei', 'v5']",2019-12-20T21:02:47.905Z,"[{'_id': '5dfd36f732bff02cf4e281ef', 'datatype_tag': 'v5', 'desc': 'Output from freesurfer version 5 (like HCP preprocessed). Some App might not work with v5 generated output.'}]",['5d79da36b057821ae1917f9e'],"[{'docker': False, '_id': '5be75b31e15a02914a4be8f0', 'ui': 'raw', 'name': 'File Viewer', 'desc': ""Browse / download files via Brain-Life's File Browser"", 'avatar': 'https://brainlife.io/images/ui-logos/raw.png'}, {'_id': '5bf7563de15a02914af8f4c5', 'ui': 'freeview-gpu', 'name': 'FreeView', 'desc': 'A freesurfer program used to view and work with structural, anatomical scans.', 'avatar': 'https://brainlife.io/images/ui-logos/freeview.png', 'docker': True}]",False,,brainlife/validator-neuro-freesurfer,,,,
59bbfadd6b956e1c2ae89ef3,neuro/freesurfer/longitudinal-template,Freesurfer longitudinal base template and mri/ files for each timepoints used to generate the template ,"[{'id': 'template', 'dirname': 'template', 'required': True, '_id': '60087ec1af402baf7d488d46'}, {'id': 'timepoints', 'dirname': 'timepoints', 'desc': '', 'required': True, '_id': '61eacebcc1773a8c1e3599e3'}]",['1'],7,"['hippocampal', 'thalamic_nuclei']",2020-09-08T15:43:02.942Z,[],[],"[{'docker': False, '_id': '5be75b31e15a02914a4be8f0', 'ui': 'raw', 'name': 'File Viewer', 'desc': ""Browse / download files via Brain-Life's File Browser"", 'avatar': 'https://brainlife.io/images/ui-logos/raw.png'}]",False,Run freesurfer ,,"[{'id': 'subject', 'type': 'string', 'required': True}]",,,
5f5fa310aff27a5569361cf3,neuro/func/multiecho,(experimental datatype) Functional bold image using multi-echo ,"[{'_id': '5f5fa310aff27a4277361cf4', 'id': 'echo1', 'desc': '', 'required': True, 'filename': 'echo-1_bold.nii.gz'}, {'_id': '5f5fa310aff27a1e1e361cf5', 'id': 'echo2', 'desc': '', 'required': True, 'filename': 'echo-2_bold.nii.gz'}, {'_id': '5f5fa310aff27a7f9a361cf6', 'id': 'echo3', 'desc': '', 'required': False, 'filename': 'echo-3_bold.nii.gz'}, {'_id': '5f5fa310aff27a015f361cf7', 'id': 'echo4', 'desc': '', 'required': False, 'filename': 'echo-4_bold.nii.gz'}, {'_id': '5f5fa310aff27a646d361cf8', 'id': 'echo5', 'desc': '', 'required': False, 'filename': 'echo-5_bold.nii.gz'}, {'_id': '5f5fa310aff27a6923361cf9', 'id': 'echo6', 'desc': '', 'required': False, 'filename': 'echo-6_bold.nii.gz'}]",['1'],1,[],2020-09-14T17:06:24.014Z,[],[],"[{'docker': False, '_id': '5be75b31e15a02914a4be8f0', 'ui': 'raw', 'name': 'File Viewer', 'desc': ""Browse / download files via Brain-Life's File Browser"", 'avatar': 'https://brainlife.io/images/ui-logos/raw.png'}]",False,"Metadata must contain EchoTime in Array for each bold image. This array will be split into individual .json by bl2bids to create BIDS compliant file structure. 

```
""EchoTime"": [ 1.0, 1.2, 1.3 ]
```",,,,,
59b685a08e5d38b0b331ddc5,neuro/func/task,fMRI Task,"[{'_id': '5dbc3d2b8aeeee06daf36472', 'id': 'bold', 'filename': 'bold.nii.gz', 'ext': '.gz', 'required': True}, {'_id': '5dbc3d2b8aeeee2787f36471', 'id': 'events', 'filename': 'events.tsv', 'ext': '.tsv', 'required': False}, {'_id': '5dbc3d2b8aeeeedd1df36470', 'id': 'events_json', 'filename': 'events.json', 'ext': '.json', 'required': False}, {'_id': '5dbc3d2b8aeeee290ef3646f', 'id': 'sbref', 'filename': 'sbref.nii.gz', 'ext': '.gz', 'required': False}, {'_id': '5dbc3d2b8aeeee69a1f3646e', 'id': 'sbref_json', 'filename': 'sbref.json', 'ext': '.json', 'required': False}, {'_id': '5dbc3d2b8aeeee6b9cf3646d', 'id': 'physio', 'filename': 'physio.tsv.gz', 'ext': '.gz', 'required': False}, {'_id': '5dbc3d2b8aeeee6b74f3646c', 'id': 'physio_json', 'filename': 'physio.json', 'ext': '.json', 'required': False}]",['1'],94,"['12yearsaslave', '1dnf', '21styear', '2dnf', '5000scenes', '500daysofsummer', 'BREATHHOLD', 'CHECKERBOARD', 'Classificationprobewithoutfeedback', 'DMNTRACKINGTEST', 'DMNTRACKINGTRAIN', 'Dualtaskweatherprediction', 'IncidentalencodingtaskusingPosnercueingparadigmwithobjectvgreeblejudgment', 'MASK', 'MORALDILEMMA', 'MSIT', 'MerlinAudio', 'MerlinFreerecall', 'MerlinMovie', 'PEER1', 'PEER2', 'REST', 'SherlockAudio', 'SherlockFreerecall', 'SherlockMovie', 'Singletaskweatherprediction', 'TrainedHandTrainedSequence', 'TrainedHandUntrainedSequence', 'UntrainedHandTrainedSequence', 'UntrainedHandUntrainedSequence', 'a', 'aanonword', 'aaword', 'abstractconcretejudgment', 'acquisition', 'adorsal', 'affect', 'alice', 'allruns-concatenated', 'alm', 'ambiguity', 'ant', 'antisaccadetaskwithfixedorder', 'arc', 'archiemotional', 'archisocial', 'archispatial', 'archistandard', 'arithm', 'arrows', 'auditory', 'auditoryoddballwithbuttonresponsetotargetstimuli', 'auditoryperception', 'audsem', 'audspell', 'autobio', 'avnonword', 'avsceneslong', 'avscenesshort', 'avword', 'b', 'backtothefuture', 'balloonanalogrisktask', 'bart', 'baseline', 'bcl', 'bht', 'bilateralfingertapping', 'black', 'bold', 'breathhold', 'bronx', 'carit', 'catchanimaldetect', 'cdorsal', 'checkerboard', 'citizenfour', 'classicalmusic', 'classificationprobewithoutfeedback', 'cmp', 'collaborativetask', 'colordots', 'compl1', 'compln', 'conditionalstopsignal', 'conj19sel', 'conj1inh', 'conj9inh', 'convers', 'coverage', 'covertverbgeneration', 'cuedSGT', 'cuedmfm', 'cuedsfm', 'cuedsgt', 'cueexposure', 'cyberball', 'd1', 'd2', 'delay', 'desc-preproc_bold', 'deterministicclassification', 'dis', 'discounting', 'dotstop', 'dualtaskweatherprediction', 'ec', 'eegfmrinf', 'eegnf', 'effort', 'efs', 'emotid', 'emotion', 'emotionalfaces', 'emotionalregulation', 'emptyslicetimingfield', 'episodic', 'erfast', 'erslow', 'erst', 'es', 'exemplarlocaliser', 'exp89', 'exp90', 'exp91', 'exp92', 'exp93', 'exp94', 'extinction', 'eyes', 'eyesopen', 'faceidentityoddball', 'facerecognition', 'faces', 'faceshouseste27', 'fb', 'feat19sel', 'feat1inh', 'feat9inh', 'figure2backwith1backlures', 'film', 'fingerfootlips', 'first_volumes_removed', 'flanker', 'flavorrun1', 'flavorrun2', 'flavorrun3', 'flavorrun4', 'flickeringcheckerboard', 'floc', 'flocalizer', 'fmrinf', 'fmriprep', 'food', 'foodchoice', 'forgot', 'forrestgump', 'freq1', 'freq2', 'freqreports1', 'freqreports2', 'functionallocalizer', 'genmusic01', 'genmusic02', 'genmusic03', 'gist', 'glasslexical', 'gonogo', 'gradcpt', 'gram', 'grasp', 'guessing', 'hands', 'hcpemotion', 'hcpgambling', 'hcplanguage', 'hcpmotor', 'hcprelational', 'hcpsocial', 'hcpwm', 'heatpainwithregulationandratings', 'identification', 'imagery', 'images', 'infant', 'languagewm', 'ldt', 'learn', 'letter0backtask', 'letter1backtask', 'letter2backtask', 'life', 'linebisection', 'listen', 'littlemisssunshine', 'livingnonlivingdecisionwithplainormirrorreversedtext', 'loc', 'localiser', 'localizer', 'lost', 'lppcn', 'lppen', 'lppfr', 'ltm', 'lucy', 'main', 'matrix', 'memory', 'memoryfaces', 'memoryscenes', 'memorywords', 'memsamp', 'memtest1', 'memtest2', 'merlin', 'merlinmovie', 'mid', 'milkyway', 'mipost', 'mipre', 'mixed', 'mixedeventrelatedprobe', 'mixedgamblestask', 'motionlocaliser', 'motor', 'motorloc', 'motorseq', 'movie', 'moviedm', 'movielocalizer', 'movies', 'movietp', 'moviewatching', 'mst', 'mult', 'music', 'nback', 'nonmusic', 'notthefall', 'notthefallintact', 'notthefalllongscram', 'notthefallshortscram', 'num', 'obj', 'objectcategories', 'objects', 'objectviewing', 'onebacktask', 'opto', 'opto5', 'org-fmri', 'orientation', 'overtverbgeneration', 'overtwordrepetition', 'pacpal', 'pair', 'pairedassociates1', 'pairedassociates2', 'pamenc', 'pamret', 'passiveimageviewing', 'passivelistening', 'pc', 'pebackward', 'peer', 'peforward', 'perception', 'persondescription', 'pheromoneolfaction', 'phon', 'picturenaming', 'pieman', 'piemanpni', 'pitchheard', 'pitchheardxclarxe', 'pitchheardxclarxf', 'pitchheardxtrumxe', 'pitchheardxtrumxf', 'pitchimagined', 'pitchimaginedxclarxe', 'pitchimaginedxclarxf', 'pitchimaginedxtrumxe', 'pitchimaginedxtrumxf', 'pixar', 'plaus', 'ppaffalomapper', 'pred', 'preprocessed', 'prettymouth', 'prf', 'probabilisticclassification', 'prodl1', 'prodln', 'pulpfiction', 'raiders', 'random', 'raw', 'read', 'regress', 'renewal', 'rerun', 'resptrain', 'rest', 'rest2', 'rest3', 'rest4', 'restbaseline', 'restfixationadaptive', 'restfixationfixed', 'restfixationnofeedback', 'resting', 'restmovieadaptive', 'restmoviefixed', 'restmovienofeedback', 'retinotopy', 'retmapccw', 'retmapclw', 'retmapcon', 'retmapexp', 'reversalweatherprediction', 'reward', 'rhymejudgment', 'rhyming', 'ring', 'rllearningphase', 'rltestphase', 'routelearning', 'rpflavourtask', 'rs', 'rsvp', 'rsvplanguage01', 'rsvplanguage02', 'rsvplanguage03', 'rsvplanguage04', 'rsvplanguage05', 'sae', 'sar', 'satellite', 'scap', 'scene', 'schema', 'sem', 'semantic', 'shape', 'shapesphysical', 'shapessocial', 'sherlock', 'sherlockaudio', 'sherlockmovie', 'sic', 'simon', 'singletaskweatherprediction', 'sld', 'sleep', 'sleepiness', 'sli', 'slowreveal', 'slumlordreach', 'smt', 'soccer', 'socialcomparison', 'sourcememory', 'space-T1w', 'spanav', 'spatialwm', 'split', 'ssd', 'ssi', 'sst', 'starttoe', 'stopmanual', 'stopsignal', 'stopvocal', 'stopword', 'stroke', 'stroop', 'sub', 'taskswitch', 'td', 'test', 'test99', 'theoryofmindwithmanualresponse', 'theprestige', 'theshawshankredemption', 'theusualsuspects', 'ti', 'tom', 'tomloc', 'tonecounting', 'tps', 'trainedhandtrainedsequence', 'trainedhanduntrainedsequence', 'training', 'trust', 'tunnel', 'unknown', 'untrainedhandtrainedsequence', 'untrainedhanduntrainedsequence', 'ventral', 'verbal', 'verbalmemory', 'verbnback', 'verbs', 'view', 'viewFigure', 'viewRandom', 'viewfigure', 'viewingfoodlowres', 'viewrandom', 'visnback', 'visrhyme', 'vissem', 'visspell', 'visual', 'visualattentiontask', 'visualimageryfalsememory', 'visualoddballwithbuttonresponsetotargetstimuli', 'vld', 'vli', 'vsd', 'vsi', 'vvnonword', 'vvword', 'warped', 'washout', 'wcst', 'weatherprediction', 'whiskerasl', 'whiskerepi', 'wm', 'wml']",2019-11-01T14:11:55.192Z,"[{'_id': '5dbc3d2b8aeeee730cf3647b', 'datatype_tag': 'rest', 'desc': 'resting state'}]",['5d796fd303e8c94d24eaed50'],"[{'docker': False, '_id': '5be75b31e15a02914a4be8f0', 'ui': 'raw', 'name': 'File Viewer', 'desc': ""Browse / download files via Brain-Life's File Browser"", 'avatar': 'https://brainlife.io/images/ui-logos/raw.png'}, {'_id': '5bf755e5e15a02914af8f194', 'ui': 'fslview', 'name': 'FSLView', 'desc': 'An old 2d/3d brain volume viewer. Replaced by fsleyes', 'avatar': 'https://brainlife.io/images/ui-logos/fslview.png', 'docker': True}, {'_id': '5bf755f4e15a02914af8f22b', 'ui': 'fsleyes', 'name': 'FSLeyes', 'desc': 'A 2d/3d brain volume viewer.', 'avatar': 'https://brainlife.io/images/ui-logos/fsleyes.png', 'docker': True}, {'_id': '5bf75608e15a02914af8f2e3', 'ui': 'mrview', 'name': 'mrView', 'desc': 'The MRtrix image viewer.', 'avatar': 'https://brainlife.io/images/ui-logos/mrview.png', 'docker': True}, {'_id': '5bf75623e15a02914af8f3d8', 'ui': 'mricrogl', 'name': 'MRIcroGL', 'desc': 'View 2D slices and renderings of your brain imaging data. It allows you to draw regions of interest which can aid lesion mapping and fMRI analysis.', 'avatar': 'https://brainlife.io/images/ui-logos/mricrogl.png', 'docker': True}, {'_id': '5bf75630e15a02914af8f44e', 'ui': 'fibernavigator', 'name': 'fiberNavigator', 'desc': 'A tool designed for a fast and versatile visualization of streamline datasets.', 'avatar': 'https://brainlife.io/images/ui-logos/fibernavigator.png', 'docker': True}]",False,,brainlife/validator-neuro-func-task,,,"{'_id': '5dbc3d1f8aeeeef269f3646a', 'maps': [{'_id': '5dbc3d2b8aeeee08b8f3647a', 'src': 'bold.nii.gz', 'dest': 'bold.nii.gz'}, {'_id': '5dbc3d2b8aeeeef1c9f36479', 'src': 'events.tsv', 'dest': 'events.tsv'}, {'_id': '5dbc3d2b8aeeee58d3f36478', 'src': 'events.json', 'dest': 'events.json'}, {'_id': '5dbc3d2b8aeeee1ffdf36477', 'src': 'sbref.nii.gz', 'dest': 'sbref.nii.gz'}, {'_id': '5dbc3d2b8aeeee1e01f36476', 'src': 'sbref.json', 'dest': 'sbref.json'}, {'_id': '5dbc3d2b8aeeee71d2f36475', 'src': 'physio.tsv.gz', 'dest': 'physio.tsv.gz'}, {'_id': '5dbc3d2b8aeeee8beaf36474', 'src': 'physio.json', 'dest': 'physio.json'}, {'_id': '5dbc3d2b8aeeeee48ff36473', 'src': '_meta_', 'dest': 'bold.json'}], 'derivatives': 'func'}",
61e8834d33cb3deb49960f3c,neuro/hcp/abcd-fmri,Output folder containing files like in https://github.com/DCAN-Labs/abcd-hcp-pipeline?ref=https://githubhelp.com#outputs,"[{'id': 'output', 'dirname': 'output', 'desc': '', 'required': True, '_id': '61e883fd33cb3deb49960f80'}]","['146', '1']",2,[],2022-01-19T21:31:57.729Z,[],[],"[{'docker': False, '_id': '5be75b31e15a02914a4be8f0', 'ui': 'raw', 'name': 'File Viewer', 'desc': ""Browse / download files via Brain-Life's File Browser"", 'avatar': 'https://brainlife.io/images/ui-logos/raw.png'}]",False,"The outputs are organized in the following structure:
```
output_dir/
|__ sub-id
    |__ ses-session
        |__ files
        |   |__ executive_summary
        |   |__ MNINonLinear
        |   |   |__ fsaverage_LR32k
        |   |   |__ Results
        |   |__ T1w
        |   |   |__ id
        |   |__ task-taskname
        |__ logs
```",,,,,
5e767ddcde643b260e2a8a52,neuro/hcp/freesurferpost,Contains content similar to /N/dcwan/projects/hcp/517239/MNINonLinear,"[{'_id': '5e767ddcde643b0a352a8a53', 'id': 'output', 'desc': '', 'required': True, 'dirname': 'output'}]","['16', '1']",2,[],2020-03-21T20:49:32.703Z,[],[],"[{'docker': False, '_id': '5be75b31e15a02914a4be8f0', 'ui': 'raw', 'name': 'File Viewer', 'desc': ""Browse / download files via Brain-Life's File Browser"", 'avatar': 'https://brainlife.io/images/ui-logos/raw.png'}]",False,,,,,,
5b3abb88d7b3f1e24e431321,neuro/hcp/freesurferpre,HCP PreFS Output,"[{'_id': '643852d4b32aa6e00a168420', 'id': 'hcp_freesurferpre', 'dirname': 'output', 'required': True}]",['1'],1,[],2020-09-08T15:43:02.952Z,[],[],"[{'docker': False, '_id': '5be75b31e15a02914a4be8f0', 'ui': 'raw', 'name': 'File Viewer', 'desc': ""Browse / download files via Brain-Life's File Browser"", 'avatar': 'https://brainlife.io/images/ui-logos/raw.png'}]",False,,,,,,
606345ade4a8347b6f337de4,neuro/labels,Experimental (Giulia),"[{'id': 'index', 'filename': 'index.csv', 'desc': '', 'required': True, '_id': '606345ade4a8348e99337de5'}, {'id': 'names', 'filename': 'names.csv', 'desc': '', 'required': True, '_id': '606345ade4a834756c337de6'}]","['146', '16']",6,['connectivity_assignments'],2021-03-30T15:37:17.966Z,"[{'datatype_tag': 'binary', 'desc': ""This tag is useful for indicating that the index.csv file is binary, meaning that the streamlines to keep are labelled '1' and those to remove are '0'."", '_id': '626afef2f3858674a2a560ce'}]",[],"[{'docker': False, '_id': '5be75b31e15a02914a4be8f0', 'ui': 'raw', 'name': 'File Viewer', 'desc': ""Browse / download files via Brain-Life's File Browser"", 'avatar': 'https://brainlife.io/images/ui-logos/raw.png'}]",False,,,,,,
59399b95436ee50ffdc08381,neuro/laplace_beltrami_spectrum,Output from Laplace Beltrami Spectrum App,"[{'_id': '6043bb8e66d5ce4e526f5d91', 'id': 'spectrum', 'filename': 'spectrum.json', 'required': True}, {'_id': '6043bb8e66d5ce5dfd6f5d92', 'id': 'eigenvectors', 'filename': 'eigenvectors.mat', 'required': False}]",['1'],2,[],2020-09-08T15:43:02.927Z,[],[],"[{'docker': False, '_id': '5be75b31e15a02914a4be8f0', 'ui': 'raw', 'name': 'File Viewer', 'desc': ""Browse / download files via Brain-Life's File Browser"", 'avatar': 'https://brainlife.io/images/ui-logos/raw.png'}]",True,,,"[{'id': 'subject', 'type': 'string', 'required': True}]",,,
6123cffd2301763fddd57054,neuro/maps,"(experimental) similar to neuro/rois, this datatype contains any number of nifti files in a directory. Unlike neuro/rois, each nifti can contain any value (not just 0 or 1). The type of values that it contains are determined by datatype tags.","[{'_id': '6123cffd2301760489d57056', 'id': 'maps', 'desc': 'A directory containing *.nii.gz files. ', 'required': True, 'filename': 'maps'}]","['56', '1']",2,[],2021-08-23T16:42:37.101Z,"[{'_id': '6123cffd23017662e0d57055', 'datatype_tag': 'Masks', 'desc': 'A series of NIfTI outputs (presumably in the same reference space) each of which contains **only** _binary_ data representations (i.e. 1s and 0s in the NIfTI data section).\n\nTypically, a MASK is used in a downstream algorithm/application to select the specified voxels from a NIfTI object (representing the same dataspace), for example in the case of a region of interest (ROI) extracted from an atlas.'}, {'_id': '6123d16b23017669a3d571b6', 'datatype_tag': 'Parcellation(s)', 'desc': 'A series of NIfTI outputs (presumably in the same reference space) each of which contains **only** _positive integer_ data representations.\n\nTypically, a PARCELLATION is used in a downstream algorithm/application to select the specified voxels from a NIfTI object (representing the same dataspace), in a similar fashion as a MASK.  However, in the case of a PARCELLATION, there can be multiple regions of interest demarcated in accordance with the numbering scheme.  Typically this demarcation scheme is not useful unless an associated ""key"" or ""dictionary"" is provided.  Ideally, users would make use of the [neuro/parcellation/volume](https://brainlife.io/datatype/5c1a7489f9109beac4a88a1f) for this purpose.\n\nBecause in a single, 3D NIfTI parcellation, any given voxel can only have _one_ identity assignment, the possibility of applying multiple labels to the same voxel is precluded when using _a single_ 3D NIfTI parcellation.  By including multiple parcellations in a directory, it is possible to work around this shortcoming.'}, {'_id': '612d371c23017625a5da4ee5', 'datatype_tag': '', 'desc': ''}]",[],"[{'docker': False, '_id': '5be75b31e15a02914a4be8f0', 'ui': 'raw', 'name': 'File Viewer', 'desc': ""Browse / download files via Brain-Life's File Browser"", 'avatar': 'https://brainlife.io/images/ui-logos/raw.png'}]",False,,,,,,
5a281aee2c214c9ba83ce620,neuro/mask,Volume Mask,"[{'_id': '5f2d60bdbeafe97ba562fd09', 'id': 'mask', 'filename': 'mask.nii.gz', 'ext': '.gz', 'required': True}]",['1'],38,"['5tt', '5tt_masks', 'AP', 'CC', 'CHM', 'CNN', 'Control', 'PA', 'SENSE', 'SNR', 'SOS', 'STGD', 'X-mask', 'acpc_aligned', 'aligned_dtiinit', 'anat', 'anatomical', 'atlas-corrected', 'atlas-initial', 'bold', 'brain', 'brain_extracted', 'brain_mask', 'complete', 'cropped_to_gt', 'debiased', 'denoised', 'desc-brain_mask', 'dki', 'dtiinit', 'dwi', 'fa', 'facerecognition', 'fmriprep', 'freesurfer', 'func', 'image_24', 'image_29', 'image_3', 'image_30', 'image_30a', 'image_31', 'image_32', 'image_33', 'image_34', 'image_35', 'image_5', 'manual', 'mask', 'masked', 'merged', 'new_sequence', 'noddi', 'noise', 'normalized', 'old_sequence', 'peaks', 'preprocessed', 'qsiprep', 'raw', 'rest', 'session 1', 'session_1', 'session_2', 'single_shell', 'space-T1w', 'space-dwi', 't1_aligned', 'task', 'white_matter']",2020-08-07T14:10:05.997Z,"[{'_id': '5f2d60bdbeafe9992262fd0a', 'datatype_tag': 'brain', 'desc': '(type) binary mask where 1 indicating area of image where white and gray matter can be found'}, {'_id': '5f2d60bebeafe94db262fd0b', 'datatype_tag': 'white_matter', 'desc': '(type) binary mask where 1 indicating area of image where only the white matter can be found'}, {'_id': '5f2d65dcbeafe96e0562fe9c', 'datatype_tag': '5tt', 'desc': '(type) The mask.nii.gz is stored as 4D image where the value in the 4th dimension indicating the type of brain tissue: 0-Cortical-Gray-Matter, 1-Subcortical/Deep-Gray-Matter, 2-White-Matter/Brainstem, 3-CSF/Ventricles, 4-Anything of pathological interest, or empty if not applicable'}, {'_id': '5f2d65dcbeafe959c462fe9d', 'datatype_tag': 'anat', 'desc': '(space) The mask was created from anatomy (t1) input'}, {'_id': '5f2d65dcbeafe93af362fe9e', 'datatype_tag': 'dwi', 'desc': '(space) The mask was created from dwi input'}, {'_id': '5f2d65dcbeafe98bbc62fe9f', 'datatype_tag': 'func', 'desc': '(space) The mask was created from functional/bold input'}, {'_id': '5f2dab74beafe94a04630c3f', 'datatype_tag': 'gray_matter', 'desc': '(type) binary mask where 1 indicating area of image where only the gray_matter can be found'}, {'_id': '5f2dab74beafe917f9630c40', 'datatype_tag': 'csf', 'desc': '(type) binary mask where 1 indicating area of image where only the csf can be found'}]",['5d7beb1df59daf563c8b8bad'],"[{'docker': False, '_id': '5be75b31e15a02914a4be8f0', 'ui': 'raw', 'name': 'File Viewer', 'desc': ""Browse / download files via Brain-Life's File Browser"", 'avatar': 'https://brainlife.io/images/ui-logos/raw.png'}, {'docker': False, '_id': '5bf755c8e15a02914af8f084', 'ui': 'volumeviewer', 'name': 'Volume Viewer', 'desc': 'Web-based visualization tools for neurological data.', 'avatar': 'https://brainlife.io/images/ui-logos/ui-volumeviewer.png'}, {'docker': False, '_id': '60da96878c1f96ddd4318b19', 'ui': 'papaya', 'name': 'Papaya Viewer', 'desc': 'A pure JavaScript medical research image viewer.', 'avatar': 'https://raw.github.com/rii-mango/Papaya/master/docs/images/splash1.png'}]",True,"All mask data should have 2 datatype tags, one for the space and another one for mask type.",,"[{'id': 'subject', 'type': 'string', 'required': True}]",,,
5afb21465858d874a4b393a1,neuro/meeg/mne/covariance,To be edited by Saeed,"[{'id': 'cov', 'filename': 'cov.fif', 'dirname': '', 'desc': 'A small fif file containing the covariant matrix', 'required': True, '_id': '6283d7e2d0697cf1eade7ae0'}]","['1', '2076']",7,[],2020-09-08T15:43:02.951Z,[],[],"[{'docker': False, '_id': '5be75b31e15a02914a4be8f0', 'ui': 'raw', 'name': 'File Viewer', 'desc': ""Browse / download files via Brain-Life's File Browser"", 'avatar': 'https://brainlife.io/images/ui-logos/raw.png'}]",False,To be edited by Saeed,,,,,
61797fc39538685e5db952b0,neuro/meeg/mne/epochs,Datatype to describe the mne.Epochs class,"[{'id': 'epo', 'filename': 'meg-epo.fif', 'desc': 'mne.Epochs class which contains Epochs extracted from a Raw MEEG data instance.', 'required': True, '_id': '617a76f8b0856ce5c6e45fd8'}]","['1348', '1']",10,"['epochs', 'equal', 'maxfilt', 'maxwell', 'movecomp', 'rest', 'retest', 'split', 'test']",2021-10-27T16:35:15.583Z,[],[],"[{'docker': False, '_id': '5be75b31e15a02914a4be8f0', 'ui': 'raw', 'name': 'File Viewer', 'desc': ""Browse / download files via Brain-Life's File Browser"", 'avatar': 'https://brainlife.io/images/ui-logos/raw.png'}, {'_id': '606c8d75fc87ce0007f2093b', 'ui': 'mnefif', 'name': 'FIF viewer using MNE python', 'desc': 'Runs various visualization tools provided by MNEpython on a jupyter notebook', 'avatar': 'https://brainlife.io/images/ui-logos/mnepython.png', 'docker': True}]",False,"mne.Epochs class: https://mne.tools/stable/generated/mne.Epochs.html
which contains Epochs extracted from a Raw MEEG data instance.
It is stored in a file named: `-epo.fif` or `-epo.fif.gz`",,,,,
5978fd38b09297d8d8aa8746,neuro/meeg/mne/evoked,To be edited by Saeed,"[{'id': 'evoked', 'filename': 'ave.fif', 'required': True, '_id': '6283d98dd0697cf1eade8609'}]","['1', '2076']",3,[],2020-09-08T15:43:02.941Z,[],[],"[{'docker': False, '_id': '5be75b31e15a02914a4be8f0', 'ui': 'raw', 'name': 'File Viewer', 'desc': ""Browse / download files via Brain-Life's File Browser"", 'avatar': 'https://brainlife.io/images/ui-logos/raw.png'}]",False,To be edited by Saseed,,"[{'id': 'subject', 'type': 'string', 'required': True}]",,,
6283e916d0697cf1eadea5a3,neuro/meeg/mne/forward-inverse,to be edited,"[{'id': 'forward', 'filename': 'fwd.fif', 'desc': '', 'required': True, '_id': '6283e916d0697cf1eadea5a4'}, {'id': 'inverse', 'filename': 'inv.fif', 'desc': 'Inverse operator', 'required': False, '_id': '6283ea76d0697cf1eadeaa79'}]","['1', '2076']",4,[],2022-05-17T18:27:34.442Z,[],[],"[{'docker': False, '_id': '5be75b31e15a02914a4be8f0', 'ui': 'raw', 'name': 'File Viewer', 'desc': ""Browse / download files via Brain-Life's File Browser"", 'avatar': 'https://brainlife.io/images/ui-logos/raw.png'}]",False,to be edited,,,,,
6283e821d0697cf1eade9d5c,neuro/meeg/mne/ica,to be edited,"[{'id': 'ica', 'filename': 'ica.fif', 'desc': '', 'required': True, '_id': '6283e821d0697cf1eade9d5d'}]","['1', '2076']",2,[],2022-05-17T18:23:29.938Z,[],[],"[{'docker': False, '_id': '5be75b31e15a02914a4be8f0', 'ui': 'raw', 'name': 'File Viewer', 'desc': ""Browse / download files via Brain-Life's File Browser"", 'avatar': 'https://brainlife.io/images/ui-logos/raw.png'}]",False,to be edited,,,,,
6283e7e9d0697cf1eade9bda,neuro/meeg/mne/projection,to be edited,"[{'id': 'projection', 'filename': 'proj.fif', 'desc': '', 'required': True, '_id': '6283e7e9d0697cf1eade9bdb'}]","['1', '2076']",0,[],2022-05-17T18:22:33.300Z,[],[],"[{'docker': False, '_id': '5be75b31e15a02914a4be8f0', 'ui': 'raw', 'name': 'File Viewer', 'desc': ""Browse / download files via Brain-Life's File Browser"", 'avatar': 'https://brainlife.io/images/ui-logos/raw.png'}]",False,to be edited,,,,,
61893398e8be76b34cb9826e,neuro/meeg/mne/raw,https://mne.tools/stable/generated/mne.io.Raw.html#mne.io.Raw,"[{'id': 'mne', 'filename': 'raw.fif', 'desc': '', 'required': True, '_id': '61893398e8be76b34cb9826f'}]","['41', '1348', '1']",1,[],2021-11-08T14:26:32.150Z,[],[],"[{'docker': False, '_id': '5be75b31e15a02914a4be8f0', 'ui': 'raw', 'name': 'File Viewer', 'desc': ""Browse / download files via Brain-Life's File Browser"", 'avatar': 'https://brainlife.io/images/ui-logos/raw.png'}]",False,,,,,,
60c7669e7657d98fe5e128b1,neuro/meeg/psd,Power spectral densities of MEG/EEG signals,"[{'id': 'psd', 'filename': 'psd.tsv', 'desc': 'Rows correspond to channels and columns to the frequencies.', 'required': True, '_id': '60c7669e7657d92279e128b2'}]","['1342', '1348', '1']",12,"['alpha_peak', 'avg', 'epochs', 'equal', 'grad', 'mag', 'maxfilt', 'maxwell', 'movecomp', 'peak_ampl', 'peak_freq', 'psd', 'rest', 'retest', 'split', 'test']",2021-06-14T14:24:30.301Z,[],[],"[{'docker': False, '_id': '5be75b31e15a02914a4be8f0', 'ui': 'raw', 'name': 'File Viewer', 'desc': ""Browse / download files via Brain-Life's File Browser"", 'avatar': 'https://brainlife.io/images/ui-logos/raw.png'}]",True,Dimensions: channels x freqs,,,,,
61a4e7d709959fabbdcef50c,neuro/meg/BTi4D,Each experimental run on a 4D neuroimaging/BTi system results in a folder containing multiple files without extensions.,"[{'id': 'headshape', 'filename': 'headshape.pos', 'desc': '', 'required': False, '_id': '61a4e7d709959fabbdcef50d'}, {'id': 'meg', 'dirname': 'meg', 'desc': 'A directory containing the following files; ""config"", ""hs_file"", ""e,rfhp1.0Hz.COH"", ""c,rfDC""', 'required': True, '_id': '61a4e7d709959fabbdcef50e'}, {'id': 'scans', 'filename': 'scans.tsv', 'desc': '', 'required': False, '_id': '61a4e7d709959fabbdcef50f'}]","['1', '670', '1348']",1,[],2021-11-29T14:46:47.389Z,[],[],"[{'docker': False, '_id': '5be75b31e15a02914a4be8f0', 'ui': 'raw', 'name': 'File Viewer', 'desc': ""Browse / download files via Brain-Life's File Browser"", 'avatar': 'https://brainlife.io/images/ui-logos/raw.png'}]",False,https://bids-specification.readthedocs.io/en/stable/99-appendices/06-meg-file-formats.html#bti4d-neuroimaging,,,,,
6000714baacf9e22a6a691c8,neuro/meg/ctf,Magnetoencephalography (MEG) in CTF (folder with .ds extension),"[{'_id': '6000714baacf9e4421a691c9', 'id': 'ds', 'desc': 'this directory contains various CTF items (.meg4, .res4, .acq, .hc, .hist, ,ec..)', 'required': True, 'dirname': 'meg.ds'}, {'_id': '6000714baacf9e6228a691ca', 'id': 'headshape', 'desc': 'The OPTIONAL digitized positions of the head points. Head shape and electrode description', 'required': False, 'filename': 'headshape.pos'}, {'_id': '600702d0af402b61aa48414c', 'id': 'channels', 'desc': 'This file is RECOMMENDED as it provides easily searchable information across BIDS datasets for for example, general curation, response to queries or batch analysis. To avoid confusion, the channels SHOULD be listed in the order they appear in the MEG data file. Missing values MUST be indicated with n/a.', 'required': False, 'filename': 'channels.tsv'}, {'_id': '600702d0af402b27af48414d', 'id': 'coordsystem', 'desc': ' A JSON document specifying the coordinate system(s) used for the MEG, EEG, head localization coils, and anatomical landmarks.', 'required': False, 'filename': 'coordsystem.json'}, {'_id': '606f730cc7f80ab7d4955717', 'id': 'events', 'desc': '', 'required': False, 'filename': 'events.tsv'}, {'_id': '606f730cc7f80a897b955718', 'id': 'events_json', 'desc': '', 'required': False, 'filename': 'events.json'}]","['1342', '1348', '1']",12,"['aef', 'mapping', 'movie', 'noise', 'rest']",2021-01-14T16:28:59.769Z,[],[],"[{'docker': False, '_id': '5be75b31e15a02914a4be8f0', 'ui': 'raw', 'name': 'File Viewer', 'desc': ""Browse / download files via Brain-Life's File Browser"", 'avatar': 'https://brainlife.io/images/ui-logos/raw.png'}, {'_id': '60130352757b8e08c346913f', 'ui': 'brainstorm', 'name': 'Brainstorm', 'desc': 'Brainstorm is a collaborative, open-source application dedicated to the analysis of brain recordings: MEG, EEG, fNIRS, ECoG, depth electrodes and multiunit electrophysiology.', 'avatar': 'https://neuroimage.usc.edu/brainstorm/Screenshots?action=AttachFile&do=get&target=snap_median.jpg', 'docker': True}, {'_id': '606c8d75fc87ce0007f2093b', 'ui': 'mnefif', 'name': 'FIF viewer using MNE python', 'desc': 'Runs various visualization tools provided by MNEpython on a jupyter notebook', 'avatar': 'https://brainlife.io/images/ui-logos/mnepython.png', 'docker': True}]",False,"Each experimental run with a CTF system yields a folder with a .ds extension, containing several files. 

To learn more about CTF’s data organization: 
> https://www.fieldtriptoolbox.org/getting_started/ctf

https://bids-specification.readthedocs.io/en/stable/99-appendices/06-meg-file-formats.html#ctf",,,,,
6000737faacf9ee51fa691cb,neuro/meg/fif,Magnetoencephalography (MEG) / FIFF - Neuromag/Elekta/MEGIN data and Tristan Technologies BabyMEG data ,"[{'id': 'fif', 'filename': 'meg.fif', 'desc': '', 'required': True, '_id': '6000737faacf9e1198a691cc'}, {'id': 'channels', 'filename': 'channels.tsv', 'desc': '\nAlthough this information can often be extracted from the EEG recording, listing it in a simple .tsv document makes it easy to browse or search. The required columns are channel name, type and units in this specific order. Channel names should furthermore appear in the table in the same order they do in the EEG data file. Any number of additional columns may be provided to provide additional information about the channels. Note that electrode positions should not be added to this file, but to *_electrodes.tsv.', 'required': False, '_id': '6000737faacf9ec18ea691cd'}, {'id': 'headshape', 'filename': 'headshape.pos', 'desc': 'The OPTIONAL digitized positions of the head points. Head shape and electrode description', 'required': False, '_id': '6000737faacf9e00cda691ce'}, {'id': 'coordsystem', 'filename': 'coordsystem.json', 'desc': 'A *_coordsystem.json file is used to specify the fiducials, the location of anatomical landmarks, and the coordinate system and units in which the position of electrodes and landmarks is expressed. The *_coordsystem.json is REQUIRED if the optional *_electrodes.tsv is specified. If a corresponding anatomical MRI is available, the locations of landmarks and fiducials according to that scan should also be stored in the *_T1w.json file which goes alongside the MRI data.', 'required': False, '_id': '6000737faacf9e9895a691cf'}, {'id': 'calibration', 'filename': 'calibration_meg.dat', 'desc': 'calibration coefficients. File can have 1D or 3D gradiometer imbalance correction. This file is machine/site-specific.\n', 'required': False, '_id': '602e8bfe3a0011098b4d5785'}, {'id': 'crosstalk', 'filename': 'crosstalk_meg.fif', 'desc': 'cross-talk correction information.', 'required': False, '_id': '602e8bfe3a00112d8c4d5786'}, {'id': 'destination', 'filename': 'destination.fif', 'desc': '(tentative .. might disappear!) This file is only present if the data is preprocessed with maxwell_filter (FIF file containing a MEG device<->head transformation, or a 3-element array giving the coordinates to translate to (with no rotations). For example, destination=(0, 0, 0.04) would translate the bases as --trans default would in MaxFilter™ (i.e., to the default head location).', 'required': False, '_id': '602e8bfe3a001198a14d5787'}, {'id': 'events', 'filename': 'events.tsv', 'desc': '', 'required': False, '_id': '606f72dac7f80a2746955711'}, {'id': 'events_json', 'filename': 'events.json', 'desc': '', 'required': False, '_id': '606f72dac7f80af4c2955712'}]","['1342', '1348', '1']",26,"['audiovisual', 'avlearn', 'deduction', 'emptyroom', 'faceperception', 'facerecognition', 'induction', 'listeningtospeech', 'maxfilt', 'maxwell', 'mem', 'movecomp', 'noise', 'passive', 'rest', 'retest', 'smt', 'split', 'test']",2021-01-14T16:38:23.579Z,[],[],"[{'docker': False, '_id': '5be75b31e15a02914a4be8f0', 'ui': 'raw', 'name': 'File Viewer', 'desc': ""Browse / download files via Brain-Life's File Browser"", 'avatar': 'https://brainlife.io/images/ui-logos/raw.png'}, {'_id': '606c8d75fc87ce0007f2093b', 'ui': 'mnefif', 'name': 'FIF viewer using MNE python', 'desc': 'Runs various visualization tools provided by MNEpython on a jupyter notebook', 'avatar': 'https://brainlife.io/images/ui-logos/mnepython.png', 'docker': True}]",False,"https://bids-specification.readthedocs.io/en/stable/99-appendices/06-meg-file-formats.html#neuromagelektamegin

The company based in Helsinki (Finland) making these MEG systems started as Neuromag, and later was acquired by Elekta, a much larger Swedish company. Since 2018 it operates under the name Megin and now is part of Croton Healthcare (which also happens to be the parent company of York Instruments). We usually refer to these systems as “Neuromag” systems.
",,,,,
608195ce89df435fd26893c1,neuro/meg/fif-override,"This datatype augments the original neuro/meg/fif data with various extra information, such as bad channels stored in channels.tsv, and bad epoch (TODO which file stores this?)","[{'_id': '608195ce89df43ce2f6893c2', 'id': 'channels', 'desc': 'channels.tsv containing any columns that were not present on the original channels.tsv. For example, ""status"" column could contain good/bad values to indicate that the channel should be removed from the further processing. Please see https://bids-specification.readthedocs.io/en/latest/04-modality-specific-files/03-electroencephalography.html#channels-description-_channelstsv for full descriptions.', 'required': False, 'filename': 'channels.tsv'}, {'_id': '609a8f51408e3c2189d56537', 'id': 'headshape', 'desc': '', 'required': False, 'filename': 'headshape.pos'}, {'_id': '609a8f51408e3c77a9d56538', 'id': 'destination', 'desc': '', 'required': False, 'filename': 'destination.fif'}, {'_id': '609a8f51408e3c5baad56539', 'id': 'events', 'desc': '', 'required': False, 'filename': 'events.tsv'}, {'_id': '609a8f51408e3c6652d5653a', 'id': 'events_json', 'desc': '', 'required': False, 'filename': 'events.json'}]","['1342', '146', '1348', '1']",5,['rest'],2021-04-22T15:27:10.321Z,[],[],"[{'docker': False, '_id': '5be75b31e15a02914a4be8f0', 'ui': 'raw', 'name': 'File Viewer', 'desc': ""Browse / download files via Brain-Life's File Browser"", 'avatar': 'https://brainlife.io/images/ui-logos/raw.png'}]",False,"channels.tsv  
> https://bids-specification.readthedocs.io/en/latest/04-modality-specific-files/03-electroencephalography.html#channels-description-_channelstsv
",,,,,
604976b3ebfe45c4633ae3d2,neuro/microperimetry,Microperimetry or fundus-controlled perimetry provides an evaluation of visual function by testing the visual field with incorporated eye-tracking. [https://pubmed.ncbi.nlm.nih.gov/33022378/]. This app is optimised for use on binocular integrated data produced by  https://ocular.shinyapps.io/MAIA_binocular_field_app/,"[{'_id': '604976b3ebfe452bf13ae3d3', 'id': 'microperimetry', 'desc': 'A tab-separated values (TSV) file containing 4 columns (ID, x_deg, y_deg, and Threshold"") and sets of values. \n', 'required': True, 'filename': 'microperimetry.tsv'}]","['56', '521', '1']",7,['mp'],2021-03-11T01:47:31.876Z,"[{'_id': '6049f083ebfe452cef3aeb07', 'datatype_tag': 'mp', 'desc': 'microperimetry binocular field result'}]",['605b91bbbc89fe21415e1958'],"[{'docker': False, '_id': '5be75b31e15a02914a4be8f0', 'ui': 'raw', 'name': 'File Viewer', 'desc': ""Browse / download files via Brain-Life's File Browser"", 'avatar': 'https://brainlife.io/images/ui-logos/raw.png'}]",True,"
Example microperimetry.tsv

* File will be read as ""space delimited"" in validator and then converted to a proper tsv (tab delimited) files

```
""ID""  ""x_deg""   ""y_deg""   ""Threshold""
69  -9.04   -0.61   28
62  -8.95   1.39    28
59  -7.21   -4.69   26
```",brainlife/validator-neuro-microperimetry,,,,
5fad54c27e8ecba2c3aa0c24,neuro/myelin-map,nifti volume containing myelin map,"[{'_id': '5faec3657e8ecb978aaa6fb6', 'id': 'map', 'desc': 'The myelin map', 'required': True, 'filename': 'map.nii.gz'}]","['16', '1']",3,['t1-t2-ratio'],2020-11-12T15:29:06.147Z,[],[],"[{'docker': False, '_id': '5be75b31e15a02914a4be8f0', 'ui': 'raw', 'name': 'File Viewer', 'desc': ""Browse / download files via Brain-Life's File Browser"", 'avatar': 'https://brainlife.io/images/ui-logos/raw.png'}]",False,,,,,,
58e6e21e6cd4e826de4537ee,neuro/networkneuro,Various .mat files generated from Network Neuro Application,"[{'_id': '5e4b65731eafffbc39f9edb4', 'id': 'output', 'dirname': 'output', 'required': True}, {'_id': '5e4b65731eafff71c0f9edb5', 'id': 'roipairs', 'dirname': 'roipairs', 'required': True}, {'_id': '5e4b65731eafff59f9f9edb6', 'id': 'surfaces', 'dirname': 'surfaces', 'required': True}, {'_id': '5e4b65731eafff6949f9edb7', 'id': 'labels', 'filename': 'labels.json', 'required': True}]",['1'],2,"['dt_stream', 'ensemble', 'sd_prob', 'sd_stream']",2020-02-18T04:17:55.016Z,[],['5e4b64f184616f7ce505433b'],"[{'docker': False, '_id': '5be75b31e15a02914a4be8f0', 'ui': 'raw', 'name': 'File Viewer', 'desc': ""Browse / download files via Brain-Life's File Browser"", 'avatar': 'https://brainlife.io/images/ui-logos/raw.png'}, {'docker': False, '_id': '5c74614ae0917b1439edaf88', 'ui': 'nnview', 'name': 'NetworkNeuro', 'desc': 'NetworkNeuro surfaces/tracts', 'avatar': 'https://brainlife.io/images/ui-logos/nnview.png'}]",False,,,,,"{'_id': '5e4b65241eaffff087f9edb2', 'maps': [{'_id': '5e4b65731eafff124ff9edb8', 'src': 'output/aparc+aseg_labels.nii.gz', 'dest': 'label-GM_dseg.nii.gz'}, {'_id': '5e4b65731eafff6376f9edb9', 'src': 'output/count.csv', 'dest': 'tag-count_connectivity.csv'}, {'_id': '5e4b65731eafffb249f9edba', 'src': 'output/density.csv', 'dest': 'tag-density_connectivity.csv'}, {'_id': '5e4b65731eafff899ef9edbb', 'src': '_meta_', 'dest': 'connectivity.json'}], 'derivatives': 'dwi'}",
5ed02a620a8ed8e39c482a61,neuro/noddi,"NODDI: Neurite Orientation Dispersion and Density Imaging. 4D image with ICVF, OD, ISOVF; where ICVF is the intracellular volume fraction (also known as NDI), OD is the orientation dispersion (the variance of the Bingham; also known as ODI) and ISOVF is the isotropic component volume fraction (also known as IVF).","[{'_id': '5ed02a620a8ed83830482a62', 'id': 'dir', 'desc': '', 'required': True, 'filename': 'dir.nii.gz'}, {'_id': '5ed02a620a8ed8dbe5482a63', 'id': 'ndi', 'desc': '', 'required': True, 'filename': 'ndi.nii.gz'}, {'_id': '5ed02a620a8ed8f507482a64', 'id': 'isovf', 'desc': '', 'required': True, 'filename': 'isovf.nii.gz'}, {'_id': '5ed02a620a8ed810d0482a65', 'id': 'odi', 'desc': '', 'required': True, 'filename': 'odi.nii.gz'}]","['16', '1']",2,[],2020-05-28T21:17:22.335Z,[],[],"[{'docker': False, '_id': '5be75b31e15a02914a4be8f0', 'ui': 'raw', 'name': 'File Viewer', 'desc': ""Browse / download files via Brain-Life's File Browser"", 'avatar': 'https://brainlife.io/images/ui-logos/raw.png'}, {'_id': '5bf755e5e15a02914af8f194', 'ui': 'fslview', 'name': 'FSLView', 'desc': 'An old 2d/3d brain volume viewer. Replaced by fsleyes', 'avatar': 'https://brainlife.io/images/ui-logos/fslview.png', 'docker': True}, {'_id': '5bf755f4e15a02914af8f22b', 'ui': 'fsleyes', 'name': 'FSLeyes', 'desc': 'A 2d/3d brain volume viewer.', 'avatar': 'https://brainlife.io/images/ui-logos/fsleyes.png', 'docker': True}, {'_id': '5bf75623e15a02914af8f3d8', 'ui': 'mricrogl', 'name': 'MRIcroGL', 'desc': 'View 2D slices and renderings of your brain imaging data. It allows you to draw regions of interest which can aid lesion mapping and fMRI analysis.', 'avatar': 'https://brainlife.io/images/ui-logos/mricrogl.png', 'docker': True}, {'_id': '5bf7563de15a02914af8f4c5', 'ui': 'freeview-gpu', 'name': 'FreeView', 'desc': 'A freesurfer program used to view and work with structural, anatomical scans.', 'avatar': 'https://brainlife.io/images/ui-logos/freeview.png', 'docker': True}]",False,,,,,"{'_id': '5ed0298ace9bbc3fb7e186b2', 'maps': [{'_id': '5ed02a620a8ed818e5482a67', 'src': 'icvf.nii.gz', 'dest': 'ICVF.nii.gz'}, {'_id': '5ed02a620a8ed8db46482a68', 'src': 'isovf.nii.gz', 'dest': 'ISOVF.nii.gz'}, {'_id': '5ed02a620a8ed89c32482a69', 'src': 'od.nii.gz', 'dest': 'ODI.nii.gz'}], 'derivatives': 'dwi'}",
5bd77a8615a8683a39440dab,neuro/noddi-deprecated,"NODDI: Neurite Orientation Dispersion and Density Imaging. 4D image with ICVF, OD, ISOVF; where ICVF is the intracellular volume fraction (also known as NDI), OD is the orientation dispersion (the variance of the Bingham; also known as ODI) and ISOVF is the isotropic component volume fraction (also known as IVF).","[{'_id': '5ed02b1d0a8ed8243f482bc3', 'id': 'dir', 'filename': 'dir.nii.gz', 'required': True}, {'_id': '5ed02b1d0a8ed846ad482bc4', 'id': 'icvf', 'filename': 'icvf.nii.gz', 'required': True}, {'_id': '5ed02b1d0a8ed84e3f482bc5', 'id': 'isovf', 'filename': 'isovf.nii.gz', 'required': True}, {'_id': '5ed02b1d0a8ed8cb47482bc6', 'id': 'od', 'filename': 'od.nii.gz', 'required': True}]",['1'],2,[],2020-05-28T21:20:29.774Z,[],[],"[{'docker': False, '_id': '5be75b31e15a02914a4be8f0', 'ui': 'raw', 'name': 'File Viewer', 'desc': ""Browse / download files via Brain-Life's File Browser"", 'avatar': 'https://brainlife.io/images/ui-logos/raw.png'}, {'_id': '5bf755e5e15a02914af8f194', 'ui': 'fslview', 'name': 'FSLView', 'desc': 'An old 2d/3d brain volume viewer. Replaced by fsleyes', 'avatar': 'https://brainlife.io/images/ui-logos/fslview.png', 'docker': True}, {'_id': '5bf755f4e15a02914af8f22b', 'ui': 'fsleyes', 'name': 'FSLeyes', 'desc': 'A 2d/3d brain volume viewer.', 'avatar': 'https://brainlife.io/images/ui-logos/fsleyes.png', 'docker': True}, {'_id': '5bf75623e15a02914af8f3d8', 'ui': 'mricrogl', 'name': 'MRIcroGL', 'desc': 'View 2D slices and renderings of your brain imaging data. It allows you to draw regions of interest which can aid lesion mapping and fMRI analysis.', 'avatar': 'https://brainlife.io/images/ui-logos/mricrogl.png', 'docker': True}, {'_id': '5bf7563de15a02914af8f4c5', 'ui': 'freeview-gpu', 'name': 'FreeView', 'desc': 'A freesurfer program used to view and work with structural, anatomical scans.', 'avatar': 'https://brainlife.io/images/ui-logos/freeview.png', 'docker': True}]",False,,,,,"{'_id': '5ed02b130a8ed858e2482ba4', 'maps': [{'_id': '5ed02b1d0a8ed8483a482bc7', 'src': 'icvf.nii.gz', 'dest': 'ICVF.nii.gz'}, {'_id': '5ed02b1d0a8ed8a195482bc8', 'src': 'isovf.nii.gz', 'dest': 'ISOVF.nii.gz'}, {'_id': '5ed02b1d0a8ed82aaf482bc9', 'src': 'od.nii.gz', 'dest': 'ODI.nii.gz'}], 'derivatives': 'dwi'}",
5edd3b77c5972b8c47b3a2c3,neuro/parc-stats,Parcellation Stats,"[{'id': 'parc-stats', 'dirname': 'parc-stats', 'desc': '', 'required': True, '_id': '5edff2e1c5972bb7d1b410c5'}]","['16', '1']",34,"['SupraTentorial', 'acpc_aligned', 'aparc', 'aparc_DKTatlas', 'aparc_a2009s', 'benson14_visual_areas', 'cortex_mapping_stats', 'crop_reorient', 'defaced', 'dice_similarity', 'diffusion', 'diffusion_metrics', 'eccentricity', 'eccentricity-binned', 'freesurfer', 'freesurfer_longitudinal', 'gray_matter_density', 'hippocampal', 'image 5', 'image 7', 'image_10', 'image_3', 'image_5', 'image_7', 'mri_segstats', 'myelin_mapping', 'parcellations', 'preprocessed', 'resampled', 'rois', 'session 1', 'session_1', 'standard', 'subcort_stats', 'surface', 't1-t2-ratio', 'thalamic_nuclei', 'tract_endpoints', 'v5', 'volume']",2020-06-07T19:09:43.412Z,"[{'datatype_tag': 'dan', 'desc': 'This is parc file nameing / columns proposed and used by Dan. Which are .....(TODO)...\n\nIf ""dan"" is not set, the it should be structured in the brainlife\'s standard format.', '_id': '6308d45419b13f0a0ee2ac86'}]",['60a677ea8aef1a4faed2cd77'],"[{'docker': False, '_id': '5be75b31e15a02914a4be8f0', 'ui': 'raw', 'name': 'File Viewer', 'desc': ""Browse / download files via Brain-Life's File Browser"", 'avatar': 'https://brainlife.io/images/ui-logos/raw.png'}]",True,"Multiple .csv files stored inside parc-stats directory.


## Metadata

To specify which atlases are used to generate the parcellation, please set `parcellations` key in the product.json.

```json
{
    ""parcellations"": [
        ""aparc"",
        ""aparc.a2009s"",
        ""aparc.DKTatlas"",
        ""gordon333dil"",
        ""yeo17dil"",
        ""hcp-mmp-b"",
        ""schaefer100-yeo17""
    ]
}
```

!!! There could be multiple parcellations


TODO  - We should decide on the standard structure for newer apps and separate out files/structures used by Dan's apps (see ""dan"" datatype tags)

Files such as 

```csv
cortex.csv
whole_brain.csv
subcortical.csv
rh.cortex.csv
rois.csv
lh.cortex.csv
```

## cortex.csv

```
parcID,subjectID,structureID,nodeID,number_of_vertices,surface_area_mm^2,gray_matter_volume_mm^3,average_thickness_mm,thickness_stddev_mm,integrated_rectified_mean_curvature_mm^-1,integrated_rectified_gaussian_curvature_mm^-2,folding_index,intrinsic_curvature_index
1,9003,lh_bankssts,1,1780,1228,2926,2.346,0.39,0.121,0.025,22,1.8
2,9003,lh_caudalanteriorcingulate,1,912,574,1603,2.758,0.439,0.11699999999999999,0.02,12,0.7
...
```

## whole_brain.csv

```
subjectID,Total_Brain_volume,Total_Intracranial_volume,Total_Gray_Matter_volume,Total_White_Matter_volume,Left_Hemisphere_Gray_Matter_volume,Right_Hemisphere_Gray_Matter_volume,Left_Hemisphere_White_Matter_volume,Right_Hemisphere_White_Matter_volume,Left_Hemisphere_Mean_Gray_Matter_thickness,Right_Hemisphere_Mean_Gray_Matter_thickness
9003,1188616.0,1567924.561886,474650.381882,478554.070072,236495.549389,238154.832493,239598.493474,238955.576599,2.4264200000000002,2.40468
```

## subcorticalc.csv

```
segID,subjectID,structureID,nodeID,number_of_voxels,gray_matter_volume_mm^3
4,9003,Left-Lateral-Ventricle,1,18699,18989.0
5,9003,Left-Inf-Lat-Vent,1,538,567.5
7,9003,Left-Cerebellum-White-Matter,1,14628,15512.1
8,9003,Left-Cerebellum-Cortex,1,56695,56583.7
10,9003,Left-Thalamus-Proper,1,6561,6306.5
11,9003,Left-Caudate,1,3552,3440.8
...
```

## rh.cortex.csv

```
parcID,subjectID,structureID,nodeID,number_of_vertices,surface_area_mm^2,gray_matter_volume_mm^3,average_thickness_mm,thickness_stddev_mm,integrated_rectified_mean_curvature_mm^-1,integrated_rectified_gaussian_curvature_mm^-2,folding_index,intrinsic_curvature_index
1,9003,rh_bankssts,1,1226,875,2002,2.318,0.426,0.111,0.022000000000000002,10,1.1
2,9003,rh_caudalanteriorcingulate,1,1337,849,2222,2.444,0.695,0.141,0.036000000000000004,26,1.5
3,9003,rh_caudalmiddlefrontal,1,3182,2114,5504,2.324,0.452,0.11699999999999999,0.026000000000000002,36,3.3
4,9003,rh_cuneus,1,2787,1629,3812,2.072,0.49200000000000005,0.132,0.032,38,3.5
5,9003,rh_entorhinal,1,574,408,2443,3.8369999999999997,0.7340000000000001,0.128,0.031,6,0.7
...
```

## rois.csv

```
subjectID,ROI_name,actual_vol,BrainVol_proportion,centroid_x,centroid_y,centroid_z,medialBorder,lateralBorder,anteriorBorder,posteriorBorder,superiorBorder,inferiorBorder
9003,ROI_2,237758,0.19665739175315697,-28.221893690222803,-20.7661160211293,18.9966259265654,4.5,-67.5,61.234405517578104,-98.76559448242192,72.2344055175781,-36.765594482421896
9003,ROI_4,18699,0.0154665524120841,-16.5521418257661,-21.568685556810898,14.330667349761699,2.5,-39.5,26.2344055175781,-81.7655944824219,29.2344055175781,-3.76559448242188
9003,ROI_5,538,0.00044499733663304103,-37.8847583643123,-24.4644792407862,-10.618754333723,-30.5,-41.5,-9.76559448242188,-38.765594482421896,-1.7655944824218797,-20.7655944824219
9003,ROI_7,14628,0.0120992956138813,-18.2914957615532,-51.2071449336114,-27.1413806459439,1.5,-43.5,-25.7655944824219,-79.7655944824219,-3.76559448242188,-41.765594482421896
9003,ROI_8,56695,0.0468942825286436,-24.657209630478896,-60.7273547787443,-31.0537327662212,2.5,-53.5,-30.7655944824219,-88.76559448242192,0.234405517578125,-55.765594482421896
9003,ROI_10,6561,0.00542681696217357,-13.042295381801601,-20.0311027890824,7.32356875488951,-0.5,-28.5,-2.76559448242188,-34.765594482421896,18.2344055175781,-3.76559448242188
9003,ROI_11,3552,0.0029379749808932398,-16.9197635135135,5.03254740947002,11.729901013073599,-7.5,-22.5,22.2344055175781,-25.7655944824219,28.2344055175781,-2.76559448242188
...
```

## lh.cortex.csv

```
parcID,subjectID,structureID,nodeID,number_of_vertices,surface_area_mm^2,gray_matter_volume_mm^3,average_thickness_mm,thickness_stddev_mm,integrated_rectified_mean_curvature_mm^-1,integrated_rectified_gaussian_curvature_mm^-2,folding_index,intrinsic_curvature_index
1,9003,lh_bankssts,1,1780,1228,2926,2.346,0.39,0.121,0.025,22,1.8
2,9003,lh_caudalanteriorcingulate,1,912,574,1603,2.758,0.439,0.11699999999999999,0.02,12,0.7
3,9003,lh_caudalmiddlefrontal,1,4343,2589,6297,2.322,0.451,0.11800000000000001,0.035,48,6.1
4,9003,lh_cuneus,1,2455,1449,3195,2.029,0.415,0.12,0.027000000000000003,30,2.8
5,9003,lh_entorhinal,1,618,439,2148,3.6069999999999998,0.898,0.11900000000000001,0.027999999999999997,5,0.7
6,9003,lh_fusiform,1,3866,2819,9737,2.877,0.657,0.141,0.033,56,5.6
7,9003,lh_inferiorparietal,1,5654,3827,9888,2.336,0.49700000000000005,0.128,0.027999999999999997,80,6.0
8,9003,lh_inferiortemporal,1,4354,3111,10985,2.83,0.688,0.13699999999999998,0.036000000000000004,65,6.4
9,9003,lh_isthmuscingulate,1,1496,939,2460,2.427,0.871,0.126,0.038,20,2.1
10,9003,lh_lateraloccipital,1,8642,5186,12962,2.2,0.49700000000000005,0.12300000000000001,0.027999999999999997,102,9.8
11,9003,lh_lateralorbitofrontal,1,4082,2686,7184,2.539,0.649,0.152,0.046,70,7.5
12,9003,lh_lingual,1,4713,2947,7722,2.323,0.594,0.135,0.038,65,7.0
...
```

Please see sample object for more detailed example",brainlife/validator-neuro-parc-stats,,,,
5c478b7bf9109beac4520be6,neuro/parcellation/surface-deprecated,"(this datatype has been deprecated by  surface/data and surface/vertices) Contains lh.parc.annot.gii and rh.parc.annot.gii for surface parcellation / annotation. key.txt contains the labels. This datatype also contains various surface files (inflated, pial, and white) for reference purpose. For more advanced analysis, you will probably want to provide your own surface file.","[{'_id': '5e52b1b05fb03301f5f9a8d9', 'id': 'lh_annot', 'filename': 'lh.parc.annot.gii', 'required': True}, {'_id': '5e52b1b05fb033c87df9a8da', 'id': 'rh_annot', 'filename': 'rh.parc.annot.gii', 'required': True}, {'_id': '5e52b1b05fb0331dd7f9a8db', 'id': 'lh_inflated_surf', 'filename': 'lh.parc.inflated.gii', 'required': True}, {'_id': '5e52b1b05fb03300a8f9a8dc', 'id': 'rh_inflated_surf', 'filename': 'rh.parc.inflated.gii', 'required': True}, {'_id': '5e52b1b05fb0338bfcf9a8dd', 'id': 'lh_pial_surf', 'filename': 'lh.parc.pial.gii', 'required': True}, {'_id': '5e52b1b05fb0331907f9a8de', 'id': 'rh_pial_surf', 'filename': 'rh.parc.pial.gii', 'required': True}, {'_id': '5e52b1b05fb0338549f9a8df', 'id': 'lh_white_surf', 'filename': 'lh.parc.white.gii', 'required': True}, {'_id': '5e52b1b05fb033bb58f9a8e0', 'id': 'rh_white_surf', 'filename': 'rh.parc.white.gii', 'required': True}, {'_id': '5e52b1b05fb033003ff9a8e1', 'id': 'key', 'filename': 'key.txt', 'required': False, 'desc': 'deprecated. please use label.json.. example 1001 -> 1 == lh.Background+FreeSurfer_Defined_Medial_Wall.label 1002 -> 2 == lh.17Networks_LH_VisCent_Striate.label 1003 -> 3 == lh.17Networks_LH_VisCent_ExStr.label 1004 -> 4 == lh.17Networks_LH_VisPeri_Striate.label'}, {'_id': '5e52b1b05fb033aef9f9a8e2', 'id': 'label', 'desc': 'json file mapping each voxel values to parcellation label / desc. [ { ""name"": ""unknown"", ""desc"": ""voxel value 0 indicates that this voxel doesn\'t belong to any segmentation"", ""voxel_value"": 0 },', 'required': True, 'filename': 'label.json'}]","['16', '1']",10,"['benson14_retinotopy', 'parcellation', 'varea']",2020-02-23T17:09:04.606Z,[],['5e53f26b5b9d90f74372ba83'],"[{'docker': False, '_id': '5be75b31e15a02914a4be8f0', 'ui': 'raw', 'name': 'File Viewer', 'desc': ""Browse / download files via Brain-Life's File Browser"", 'avatar': 'https://brainlife.io/images/ui-logos/raw.png'}, {'_id': '5df153f28bb79170e29d8b83', 'ui': 'wb_view', 'name': 'Connectome Workbench', 'desc': 'Vis tool used to map neuroimaging data, especially data generated by the Human Connectome Project.', 'avatar': 'https://www.humanconnectome.org/storage/app/media/news/2014/09/Screen-shot-2014-09-10-at-2.52.13-PM.png', 'docker': True}]",False,,,,,,
5c1a7489f9109beac4a88a1f,neuro/parcellation/volume,"(aka ""segmentation"") parc.nii.gz containing volumetric parcellation / atlas, along with a key.txt file indicating the coorespondance between parc.nii.gz labels and human readable region names.","[{'_id': '5daf19cc5d1916069c2076a8', 'id': 'parc', 'filename': 'parc.nii.gz', 'required': True}, {'_id': '5daf19cc5d191639ff2076a7', 'id': 'key', 'filename': 'key.txt', 'required': False, 'desc': 'deprecated. please use label.json'}, {'_id': '5daf19cc5d19164b2e2076a6', 'id': 'label', 'desc': 'json file mapping each voxel values to parcellation label / desc.', 'required': True, 'filename': 'label.json'}]",['1'],27,"['7t', 'SupraTentorial', 'T1', 'a2009s', 'acpc_aligned', 'aparc', 'aparc.DKTAtlas', 'aparc.a2009s', 'benson', 'benson14_retinotopy', 'bias_corrected', 'brain_extracted', 'crop_reorient', 'defaced', 'desc-preproc_T1w', 'eccentricity', 'fmriprep', 'freesurfer', 'hcp-mmp', 'hippocampal', 'optic_radiation', 'preprocessed', 'qsiprep', 'subcortical', 'thalamic_nuclei', 'varea', 'visual_areas', 'visual_white_matter', 'warped']",2019-10-22T15:01:32.688Z,[],"['5e505862cb8094a8c9f50f82', '5e50585fcb80942f49f50f81', '5e505853cb80942863f50f80', '5e50584dcb809434e9f50f7f']","[{'docker': False, '_id': '5be75b31e15a02914a4be8f0', 'ui': 'raw', 'name': 'File Viewer', 'desc': ""Browse / download files via Brain-Life's File Browser"", 'avatar': 'https://brainlife.io/images/ui-logos/raw.png'}, {'_id': '5bf755e5e15a02914af8f194', 'ui': 'fslview', 'name': 'FSLView', 'desc': 'An old 2d/3d brain volume viewer. Replaced by fsleyes', 'avatar': 'https://brainlife.io/images/ui-logos/fslview.png', 'docker': True}, {'_id': '5bf755f4e15a02914af8f22b', 'ui': 'fsleyes', 'name': 'FSLeyes', 'desc': 'A 2d/3d brain volume viewer.', 'avatar': 'https://brainlife.io/images/ui-logos/fsleyes.png', 'docker': True}, {'_id': '5bf7563de15a02914af8f4c5', 'ui': 'freeview-gpu', 'name': 'FreeView', 'desc': 'A freesurfer program used to view and work with structural, anatomical scans.', 'avatar': 'https://brainlife.io/images/ui-logos/freeview.png', 'docker': True}]",False,"`label.json` should look like this
```
[
    {
        ""name"": ""unknown"",
        ""desc"": ""voxel value 0 indicates that the voxel doesn't belong to any segmentation"",
        ""voxel_value"": 0
    },
    {
        ""name"": ""Left-Cerebral-Exterior"",
        ""desc"": ""voxel value 1 indicates that the voxel belong to Left-Cerebral-Exterior"",
        ""voxel_value"": 1
    },
...
]

```

`key.txt`(deprecated by label.json) should look like this

```
0 -> 0 == Unknown
1 -> 1 == Left-Cerebral-Exterior
2 -> 2 == Left-Cerebral-White-Matter
3 -> 3 == Left-Cerebral-Cortex
4 -> 4 == Left-Lateral-Ventricle
5 -> 5 == Left-Inf-Lat-Vent
6 -> 6 == Left-Cerebellum-Exterior
7 -> 7 == Left-Cerebellum-White-Matter
8 -> 8 == Left-Cerebellum-Cortex
9 -> 9 == Left-Thalamus
10 -> 10 == Left-Thalamus-Proper
11 -> 11 == Left-Caudate
12 -> 12 == Left-Putamen
13 -> 13 == Left-Pallidum
14 -> 14 == 3rd-Ventricle
15 -> 15 == 4th-Ventricle
16 -> 16 == Brain-Stem
17 -> 17 == Left-Hippocampus
18 -> 18 == Left-Amygdala
19 -> 19 == Left-Insula
20 -> 20 == Left-Operculum
21 -> 21 == Line-1
22 -> 22 == Line-2
23 -> 23 == Line-3
24 -> 24 == CSF
25 -> 25 == Left-Lesion
26 -> 26 == Left-Accumbens-area
27 -> 27 == Left-Substancia-Nigra
28 -> 28 == Left-VentralDC
29 -> 29 == Left-undetermined
```",,,,,
5c9276dc44947d8aea7d6454,neuro/peaks,4D nifti image containing the peaks of a spherical harmonic function at each voxel (from sh2peaks),"[{'id': 'peaks', 'filename': 'peaks.nii.gz', 'required': True, '_id': '61a983e77577fd306826b771'}]",['1'],6,['CFA'],2020-09-08T15:43:02.962Z,[],[],"[{'_id': '5bf755f4e15a02914af8f22b', 'ui': 'fsleyes', 'name': 'FSLeyes', 'desc': 'A 2d/3d brain volume viewer.', 'avatar': 'https://brainlife.io/images/ui-logos/fsleyes.png', 'docker': True}, {'_id': '5bf755e5e15a02914af8f194', 'ui': 'fslview', 'name': 'FSLView', 'desc': 'An old 2d/3d brain volume viewer. Replaced by fsleyes', 'avatar': 'https://brainlife.io/images/ui-logos/fslview.png', 'docker': True}, {'docker': False, '_id': '60da96878c1f96ddd4318b19', 'ui': 'papaya', 'name': 'Papaya Viewer', 'desc': 'A pure JavaScript medical research image viewer.', 'avatar': 'https://raw.github.com/rii-mango/Papaya/master/docs/images/splash1.png'}, {'docker': False, '_id': '5be75b31e15a02914a4be8f0', 'ui': 'raw', 'name': 'File Viewer', 'desc': ""Browse / download files via Brain-Life's File Browser"", 'avatar': 'https://brainlife.io/images/ui-logos/raw.png'}]",False,,,,,,
59494478fa1d2e5a1ffd23b4,neuro/peaks_and_metrics,Model fit parameters in PeaksAndMetrics(HDF5),"[{'_id': '643852d4b32aa6e00a16847c', 'id': 'peaks', 'filename': 'peaks.pam5', 'ext': '.pam5', 'required': True}]",['1'],1,"['csa_model_fit', 'csd_model_fit']",2020-09-08T15:43:02.927Z,[],[],"[{'docker': False, '_id': '5be75b31e15a02914a4be8f0', 'ui': 'raw', 'name': 'File Viewer', 'desc': ""Browse / download files via Brain-Life's File Browser"", 'avatar': 'https://brainlife.io/images/ui-logos/raw.png'}]",False,,,,,,
60d497eecdfdb58f46ffdc45,neuro/perf/ASL,"Arterial Spin Labeling (ASL) for perfusion measurements
","[{'_id': '60d498f6cdfdb53283ffdd3e', 'id': 'asl', 'desc': '', 'required': True, 'filename': 'asl.nii.gz'}, {'_id': '60d498f6cdfdb5c59bffdd3f', 'id': 'context', 'desc': '', 'required': False, 'filename': 'aslcontext.tsv'}, {'_id': '60d498f6cdfdb5f8feffdd40', 'id': 'm0scan', 'desc': 'A M0 image is a calibration or reference image, used to estimate the M0 of blood. It is usually weighted toward the M0 of tissue, and is required especially when ASL is acquired with background suppression and/or pre-saturation pulses. ', 'required': False, 'filename': 'm0scan.nii.gz'}, {'_id': '60d498f6cdfdb573deffdd41', 'id': 'm0scan_json', 'desc': 'Sidecar for m0scan', 'required': False, 'filename': 'm0scan.json'}, {'_id': '60d498f6cdfdb592ebffdd42', 'id': 'asllabeling', 'desc': 'It is recommended to specify as much labeling information as possible for quality control, such as: a description of the location of the labeling slab, the labeling slab orientation, labeling slab distance and labeling slab thickness, and the labeling efficiency. Different approaches can be utilized for labeling positioning, depending on the preference of the researcher, as well as the flexibility of the sequence to manually optimize the labeling position. Therefore, an anonymized screenshot of the planning of the labeling plane for each session, saved as *_asllabeling.jpg, can clarify exact positioning and is recommended.', 'required': False, 'filename': 'asllabeling.jpg'}]","['156', '1']",2,[],2021-06-24T14:34:22.294Z,[],[],"[{'docker': False, '_id': '5be75b31e15a02914a4be8f0', 'ui': 'raw', 'name': 'File Viewer', 'desc': ""Browse / download files via Brain-Life's File Browser"", 'avatar': 'https://brainlife.io/images/ui-logos/raw.png'}]",False,"## BIDS Extension Proposal 5 (BEP005)

https://docs.google.com/document/d/15tnn5F10KpgHypaQJNNGiNKsni9035GtDqJzWqkkP6c/edit

",,,,,
5d9d18d8e30ae43bb0612715,neuro/prf,Nifti files containing various pRF measures,"[{'_id': '5dae51745d1916dba5205e98', 'id': 'r2', 'filename': 'r2.nii.gz', 'desc': ""This is generated for kendric and justin's prf apps - but no noah benson's prF"", 'required': False}, {'_id': '5dae51745d1916d50e205e97', 'id': 'polarAngle', 'filename': 'polarAngle.nii.gz', 'desc': 'TBD', 'required': True}, {'_id': '5dae51745d1916a7ab205e96', 'id': 'eccentricity', 'filename': 'eccentricity.nii.gz', 'desc': 'TBD', 'required': True}, {'_id': '5dae51745d191655f7205e95', 'id': 'rfWidth', 'filename': 'rfWidth.nii.gz', 'desc': 'TBD', 'required': True}, {'_id': '5dae51745d19166c24205e94', 'id': 'varea', 'desc': ""Optional varea parcellation. Only generated for noah benson's prF app."", 'required': False, 'filename': 'varea.nii.gz'}, {'_id': '5dae55705d1916f89c205f5c', 'id': 'surfaces', 'desc': 'vtk surfaces for visualization purpose. It should contain 8 VTK files with combinations of {lh/rh}.{pial/white/inflated/sphere}.vtk', 'required': True, 'dirname': 'surfaces'}, {'_id': '5dbc9c348aeeee0847f36f6c', 'id': 'prf_surfaces', 'desc': 'Directory containing freesurfer curv formatted files with the names of {rh/lh}.{sigma,angle,eccen,varea}. Only the benson and analyzePRF-gifti App currently generates this.', 'required': False, 'dirname': 'prf_surfaces'}]",['1'],12,['benson14_retinotopy'],2019-10-22T00:46:44.883Z,[],['5daf6a1455718d57f377472b'],"[{'docker': False, '_id': '5be75b31e15a02914a4be8f0', 'ui': 'raw', 'name': 'File Viewer', 'desc': ""Browse / download files via Brain-Life's File Browser"", 'avatar': 'https://brainlife.io/images/ui-logos/raw.png'}, {'docker': False, '_id': '5daf120e0d21a329cda38ff8', 'ui': 'prf', 'name': 'PRF', 'desc': 'Perception Receptive Field Map Viewer', 'avatar': 'https://raw.githubusercontent.com/brainlife/ui-prf/master/prf.png'}]",False,,,,,,
5a04b08b2c214c9ba8033391,neuro/recon,Diffusion Signal Voxel Reconstruction Model,"[{'_id': '643852d4b32aa6e00a168489', 'id': 'response', 'filename': 'response.txt', 'ext': '.txt', 'required': True}, {'_id': '643852d4b32aa6e00a16848a', 'id': 'fa', 'filename': 'fa.nii.gz', 'ext': '.nii.gz', 'required': True}, {'_id': '643852d4b32aa6e00a16848b', 'id': 'dt', 'filename': 'dt.nii.gz', 'ext': '.nii.gz', 'required': True}, {'_id': '643852d4b32aa6e00a16848c', 'id': 'wm', 'filename': 'whitematter.nii.gz', 'ext': '.nii.gz', 'required': True}, {'_id': '643852d4b32aa6e00a16848d', 'id': 'brainmask', 'filename': 'brainmask.nii.gz', 'ext': '.nii.gz', 'required': True}, {'_id': '643852d4b32aa6e00a16848e', 'id': 'csd', 'filename': 'csd.nii.gz', 'ext': '.nii.gz', 'required': True}]",['1'],1,[],2020-09-08T15:43:02.946Z,[],[],"[{'docker': False, '_id': '5be75b31e15a02914a4be8f0', 'ui': 'raw', 'name': 'File Viewer', 'desc': ""Browse / download files via Brain-Life's File Browser"", 'avatar': 'https://brainlife.io/images/ui-logos/raw.png'}, {'_id': '5bf755f4e15a02914af8f22b', 'ui': 'fsleyes', 'name': 'FSLeyes', 'desc': 'A 2d/3d brain volume viewer.', 'avatar': 'https://brainlife.io/images/ui-logos/fsleyes.png', 'docker': True}]",False,,,,,"{'derivatives': 'dwi', 'maps': [{'_id': '643852d4b32aa6e00a16848f', 'src': 'fa.nii.gz', 'dest': 'FA.nii.gz'}, {'_id': '643852d4b32aa6e00a168490', 'src': 'dt.nii.gz', 'dest': 'model-DTI_diffmodel.nii.gz'}, {'_id': '643852d4b32aa6e00a168491', 'src': 'csd.nii.gz', 'dest': 'model-CSD_diffmodel.nii.gz'}, {'_id': '643852d4b32aa6e00a168492', 'src': 'brainmask.nii.gz', 'dest': 'type-Brain_mask.nii.gz'}, {'_id': '643852d4b32aa6e00a168493', 'src': 'whitematter.nii.gz', 'dest': 'type-Whitematter_mask.nii.gz'}], '_id': '643852d4b32aa6e00a168494'}",
5c4f6a8af9109beac4b3dae0,neuro/regressors,"Confounds (or nuisance regressors) are variables representing fluctuations with a potential non-neuronal origin. Such non-neuronal fluctuations may drive spurious results in fMRI data analysis, including standard activation GLM and functional It is possible to minimize confounding effects of non-neuronal signals by including them as nuisance regressors in the GLM design matrix or regressing them out from the fMRI data - a procedure known as denoising. connectivity analyses. ","[{'id': 'regressors', 'filename': 'regressors.tsv', 'required': True, '_id': '5df93b8a32bff07c86e23e05'}, {'id': 'json', 'filename': 'regressors.json', 'desc': 'JSON file containing a dictionary with key corresponding to each column in regressors.tsv and object containing information such as     \n\n""CumulativeVarianceExplained"": 0.1424663887,\n    ""Mask"": ""CSF"",\n    ""Method"": ""aCompCor"",\n    ""Retained"": true,\n    ""SingularValue"": 146.001826739,\n    ""VarianceExplained"": 0.1424663887\n\nThis information is used to perform a component based noise correction method (CompCor)\n', 'required': False, '_id': '5fd7cac757aacdd85c2ecf33'}]","['1', '16']",21,"['confounds', 'desc-confound_regressors', 'eddyqc', 'fmriprep', 'preprocessed', 'qsiprep', 'rest']",2019-12-17T20:33:14.713Z,"[{'datatype_tag': 'eddyqc', 'desc': ""Datatype tag for regressors generated from FSL eddy's QC functions. Designed for DWI data"", '_id': '623372275d8ab5d5f03d733c'}, {'datatype_tag': 'fmriprep', 'desc': 'Datatype tag for regressors generated from FMRIPREP.', '_id': '623372275d8ab5d5f03d733d'}, {'datatype_tag': 'qsiprep', 'desc': 'Datatype tag for regressors generated from QSIPREP.', '_id': '623372275d8ab5d5f03d733e'}]",['6091b66c8fe49f631c1c1474'],"[{'docker': False, '_id': '5be75b31e15a02914a4be8f0', 'ui': 'raw', 'name': 'File Viewer', 'desc': ""Browse / download files via Brain-Life's File Browser"", 'avatar': 'https://brainlife.io/images/ui-logos/raw.png'}]",True,"It is possible to minimize confounding effects of non-neuronal signals by including them as nuisance regressors in the GLM design matrix or regressing them out from the fMRI data - a procedure known as denoising. There is currently no consensus on an optimal denoising strategy in the fMRI community. Rather, different strategies have been proposed, which achieve different compromises between how much of the non-neuronal fluctuations are effectively removed, and how much of neuronal fluctuations are damaged in the process. The fMRIPrep pipeline generates a large array of possible confounds. (from Please see https://fmriprep.org/en/stable/outputs.html#confounds for more detail)",,,,"{'derivatives': 'notspecific', 'maps': [{'src': 'regressors.tsv', 'dest': 'regressors.tsv', '_id': '5df93b8a32bff06312e23e07'}, {'src': '_meta_', 'dest': 'regressors.json', '_id': '5df93b8a32bff06e59e23e06'}], '_id': '5df93b2d32bff00e0ce23e02'}",
60f69321b991113f21b4fdf6,neuro/reho,(experimental) Regional homogeneity (ReHo) analyses result.,"[{'_id': '60f69321b99111412cb4fdf7', 'id': 'map', 'desc': '', 'required': True, 'filename': 'map.nii.gz'}]","['386', '1']",4,[],2021-07-20T09:10:57.949Z,[],[],"[{'docker': False, '_id': '5be75b31e15a02914a4be8f0', 'ui': 'raw', 'name': 'File Viewer', 'desc': ""Browse / download files via Brain-Life's File Browser"", 'avatar': 'https://brainlife.io/images/ui-logos/raw.png'}, {'_id': '5bf755f4e15a02914af8f22b', 'ui': 'fsleyes', 'name': 'FSLeyes', 'desc': 'A 2d/3d brain volume viewer.', 'avatar': 'https://brainlife.io/images/ui-logos/fsleyes.png', 'docker': True}, {'_id': '5bf7563de15a02914af8f4c5', 'ui': 'freeview-gpu', 'name': 'FreeView', 'desc': 'A freesurfer program used to view and work with structural, anatomical scans.', 'avatar': 'https://brainlife.io/images/ui-logos/freeview.png', 'docker': True}]",False,"This datatype allows single-volume Nifti files containing the result of Region Homogeneity analyses.

Zang, Y., Jiang, T., Lu, Y., He, Y., Tian, L., 2004. Regional homogeneity approach to fMRI data analysis. Neuroimage 22, 394-400.",,,,,
5be9ea0315a8683a39a1ebd9,neuro/rois,Regions of interests in multiple nifti files. Each nifti files should be a binary masks (values should be either 0 or 1),"[{'_id': '5e5d83ef82b37f71b98f3bcc', 'id': 'rois', 'dirname': 'rois', 'desc': 'A directory containing some number of .nii.gz files representing ROI s (binary mask)', 'required': True}, {'_id': '5fb687d87e8ecb741cab6434', 'id': 'label', 'desc': '(optional) json file containing list of object that describes each roi stored in rois directory. This information will be used by brainlife UI to present a user dropdown list of existing ROIs within a data object.', 'required': False, 'filename': 'label.json'}]",['1'],11,"['MNI Warp', 'aligned', 'anat', 'benson', 'eccentricity', 'hcp-mmp', 'merged', 'optic_radiation', 'resliced', 'tractEndpointDensity', 'visual_white_matter']",2020-03-02T22:08:47.612Z,[],['5e5d85a982b37f036e8f3c13'],"[{'docker': False, '_id': '5be75b31e15a02914a4be8f0', 'ui': 'raw', 'name': 'File Viewer', 'desc': ""Browse / download files via Brain-Life's File Browser"", 'avatar': 'https://brainlife.io/images/ui-logos/raw.png'}, {'_id': '5bf755f4e15a02914af8f22b', 'ui': 'fsleyes', 'name': 'FSLeyes', 'desc': 'A 2d/3d brain volume viewer.', 'avatar': 'https://brainlife.io/images/ui-logos/fsleyes.png', 'docker': True}]",False,"
label.json should look like this

```
[
    {
        ""filename"": ""ROI1001.nii.gz"", 
        ""name"": ""XYZ1 region of the MNI305 atlas"",
        ""id"": ""1001"",
        ""atlas"": ""MN305"", (optional)
        ""color"": ""#345"" (optional)
    },
    {
        ""filename"": ""ROI1002.nii.gz"", 
        ""name"": ""XYZ2 region of the MNI305 atlas"",
        ""id"": ""1002"",
        ""atlas"": ""MN305"",
        ""color"": ""#456""
    }
    ...
]
```",brainlife/validator-neuro-rois,,,,
60ca4e7e8b8b725ea44295bc,neuro/snr,(experimental) per-voxel SNR data,"[{'_id': '60ca4e7e8b8b7215ef4295bd', 'id': 'snr', 'desc': '', 'required': True, 'filename': 'snr.nii.gz'}]","['16', '1']",1,[],2021-06-16T19:18:22.375Z,[],[],"[{'docker': False, '_id': '5be75b31e15a02914a4be8f0', 'ui': 'raw', 'name': 'File Viewer', 'desc': ""Browse / download files via Brain-Life's File Browser"", 'avatar': 'https://brainlife.io/images/ui-logos/raw.png'}]",False,EDIT ME,,,,,
60ca4f058b8b7238324295d3,neuro/snr-stats,(exeprimental) SNR in CSV,"[{'id': 'snr', 'filename': 'snr.csv', 'desc': '', 'required': True, '_id': '60ca4f058b8b72cc574295d4'}]","['16', '1', '56']",7,"['AP', 'SENSE', 'image_24', 'image_30', 'normalized', 'preprocessed', 'session_1', 'single_shell', 't1_aligned']",2021-06-16T19:20:37.843Z,[],[],"[{'docker': False, '_id': '5be75b31e15a02914a4be8f0', 'ui': 'raw', 'name': 'File Viewer', 'desc': ""Browse / download files via Brain-Life's File Browser"", 'avatar': 'https://brainlife.io/images/ui-logos/raw.png'}]",True,EDIT ME,,,,,
6376c8aece8953d657da0fb9,neuro/spherical-mean,Spherical mean image for a certain b-value,"[{'id': 'sphmean', 'filename': 'sphmean.nii.gz', 'desc': 'Spherical mean image for a certain b-value', 'required': True, '_id': '6376c8aece8953d657da0fba'}]",['146'],0,[],2022-11-17T23:50:06.037Z,"[{'datatype_tag': 'normalized', 'desc': 'normalized by the b0 image', '_id': '6376c8aece8953d657da0fbb'}, {'datatype_tag': 'b1000', 'desc': '', '_id': '6376c8aece8953d657da0fbc'}, {'datatype_tag': 'b2000', 'desc': '', '_id': '6376c8aece8953d657da0fbd'}]",[],"[{'docker': False, '_id': '5be75b31e15a02914a4be8f0', 'ui': 'raw', 'name': 'File Viewer', 'desc': ""Browse / download files via Brain-Life's File Browser"", 'avatar': 'https://brainlife.io/images/ui-logos/raw.png'}, {'_id': '5bf755f4e15a02914af8f22b', 'ui': 'fsleyes', 'name': 'FSLeyes', 'desc': 'A 2d/3d brain volume viewer.', 'avatar': 'https://brainlife.io/images/ui-logos/fsleyes.png', 'docker': True}, {'_id': '5bf75608e15a02914af8f2e3', 'ui': 'mrview', 'name': 'mrView', 'desc': 'The MRtrix image viewer.', 'avatar': 'https://brainlife.io/images/ui-logos/mrview.png', 'docker': True}]",False,,,,,,
5afc7c555858d874a40c6dda,neuro/stimulus,stimulus movie,"[{'_id': '643852d4b32aa6e00a1684a5', 'id': 'stim', 'filename': 'stim.nii.gz', 'ext': '.gz', 'required': True}]",['1'],1,[],2020-09-08T15:43:02.951Z,[],[],"[{'docker': False, '_id': '5be75b31e15a02914a4be8f0', 'ui': 'raw', 'name': 'File Viewer', 'desc': ""Browse / download files via Brain-Life's File Browser"", 'avatar': 'https://brainlife.io/images/ui-logos/raw.png'}]",False,,,,,,
5dcecaffc4ae284155298383,neuro/streamline-weights,"A text file containing a list of streamline-weights in each line. This is intended to be used with algorithms like SIFT2, LiFE, and COMMIT that filter streamlines based on different anatomical and diffusion properties.","[{'id': 'weights', 'filename': 'weights.csv', 'dirname': '', 'desc': '', 'required': False, '_id': '5dcecaffc4ae286f6a298388'}]","['1', '16']",11,"['ctf', 'facerecognition', 'fif', 'noise', 'numbersletters', 'rest', 'rivalry']",2019-11-15T15:57:51.408Z,[],[],"[{'docker': False, '_id': '5be75b31e15a02914a4be8f0', 'ui': 'raw', 'name': 'File Viewer', 'desc': ""Browse / download files via Brain-Life's File Browser"", 'avatar': 'https://brainlife.io/images/ui-logos/raw.png'}]",False,"For example

weights.txt
```
0.13
0.45
0.67
0.89
...
0.99
```",,,,,
5f78b377268f76598c29b27a,neuro/surface/data,(experimental) surface data data.nii only contains measures at each vertices. The 3d coordinates for each vertices (the actual 3D mesh) can be stored using neuro/surface/vertices datatype,"[{'_id': '5f78b377268f765a4129b27b', 'id': 'left', 'desc': '', 'required': True, 'filename': 'left.gii'}, {'_id': '5fad4fd27e8ecbfc35aa0a46', 'id': 'right', 'desc': '', 'required': True, 'filename': 'right.gii'}, {'_id': '5fad52107e8ecb4c44aa0aeb', 'id': 'label', 'desc': 'optional json file describing vertices values (in case such as parcelation). \n\n[\n { ""name"": ""unknown"", \n   ""desc"": ""voxel value 0 indicates that this voxel doesn\'t belong to any segmentation"", \n   ""voxel_value"": 0 \n  }\n]', 'required': False, 'filename': 'label.json'}]","['16', '1']",12,"['benson14_retinotopy', 'func', 'parcellation', 'resampled', 'varea']",2020-10-03T17:23:03.244Z,"[{'_id': '6144bf637a38b0ffd0a0633c', 'datatype_tag': 'parc', 'desc': 'The data contains information that pertains to parcellation'}, {'_id': '6144bf637a38b00f13a0633d', 'datatype_tag': 'func', 'desc': 'The data contains information that pertains to functional data.'}]",[],"[{'docker': False, '_id': '5be75b31e15a02914a4be8f0', 'ui': 'raw', 'name': 'File Viewer', 'desc': ""Browse / download files via Brain-Life's File Browser"", 'avatar': 'https://brainlife.io/images/ui-logos/raw.png'}]",False,,,,,,
6174c1ba4fd85c74b153fddd,neuro/surface/gradient,(experimental) surface gradient data. The 3d coordinates for each vertices (the actual 3D mesh) can be stored using neuro/surface/vertices datatype,"[{'_id': '6174c1ba4fd85c28ff53fdde', 'id': 'left', 'desc': '', 'required': True, 'filename': 'left.gii'}, {'_id': '6174c1ba4fd85c742353fddf', 'id': 'right', 'desc': '', 'required': True, 'filename': 'right.gii'}, {'_id': '6174c1ba4fd85c6c8753fde0', 'id': 'label', 'desc': 'optional json file describing vertices values (in case such as parcelation). \n\n[\n { ""name"": ""unknown"", \n   ""desc"": ""voxel value 0 indicates that this voxel doesn\'t belong to any segmentation"", \n   ""voxel_value"": 0 \n  }\n]', 'required': False, 'filename': 'label.json'}]","['386', '1']",1,[],2021-10-24T02:15:22.236Z,[],[],"[{'docker': False, '_id': '5be75b31e15a02914a4be8f0', 'ui': 'raw', 'name': 'File Viewer', 'desc': ""Browse / download files via Brain-Life's File Browser"", 'avatar': 'https://brainlife.io/images/ui-logos/raw.png'}]",True,,,,,,
5f78b255268f764bdd29b254,neuro/surface/vertices,"Surface vertices (3D mesh) stored in <left/right>/<name>.gii. Where <name> is the name of the surface such as pial, white, inflated, etc. ","[{'_id': '5f78b255268f76dc0729b255', 'id': 'right', 'desc': '', 'required': True, 'dirname': 'right', 'filename': ''}, {'_id': '5fad508f7e8ecb0704aa0a7e', 'id': 'left', 'desc': '', 'required': True, 'dirname': 'left'}]","['16', '1']",8,"['benson14_retinotopy', 'parcellation', 'varea']",2020-10-03T17:18:13.668Z,[],[],"[{'docker': False, '_id': '5be75b31e15a02914a4be8f0', 'ui': 'raw', 'name': 'File Viewer', 'desc': ""Browse / download files via Brain-Life's File Browser"", 'avatar': 'https://brainlife.io/images/ui-logos/raw.png'}]",False,"```
left/
    pial.gii
    white.gii
    inflated.gii
    (etc..)
right/
    pial.gii
    white.gii
    inflated.gii
    (etc..)
```",,,,,
5dcf0047c4ae28d7f2298f48,neuro/tcks,collection of tck files with json file describing each tck file,"[{'_id': '5dcf0047c4ae2883db298f4a', 'id': 'tcks', 'desc': '', 'required': True, 'dirname': 'tcks'}, {'_id': '5dcf0047c4ae289e79298f49', 'id': 'tcks_json', 'desc': 'A json file containing a list of object for each tck files stored inside the tcks directory. ', 'required': True, 'filename': 'tcks.json'}]",['1'],7,"['classifyber', 'cleaned', 'optic_radiation', 'wmaSeg']",2019-11-15T19:45:11.697Z,[],['5e988bfeedd2a970bdcf886f'],"[{'docker': False, '_id': '5be75b31e15a02914a4be8f0', 'ui': 'raw', 'name': 'File Viewer', 'desc': ""Browse / download files via Brain-Life's File Browser"", 'avatar': 'https://brainlife.io/images/ui-logos/raw.png'}, {'_id': '5f724b403ad30ab2f0c0ce5e', 'ui': 'dsistudio', 'name': 'dsi-studio', 'desc': 'DSI Studio is a tractography software tool that maps brain connections and correlates findings with neuropsychological disorders.', 'avatar': 'https://raw.githubusercontent.com/brainlife/brainlife.hugo/master/static/images/ui-logos/dsi_studio.png', 'docker': True}]",False,"tcks.json sample

```
[
    {
        ""name"": ""forcepsMinor"",
        ""color"": [0.8147236864,0.2550951155,0.004634224134],
        ""filename"": ""forcepsMinor.json""
    },
    {
        ""name"": ""forcepsMajor"",
        ""color"": [0.9057919371,0.5059570517,0.7749104647],
        ""filename"": ""forcepsMajor.json""
    },
]
```",,,,,
5a79df48d071a1753f1d661b,neuro/tensor,Diffusion Tensor Image Scalars,"[{'_id': '5f2e1437beafe9d1b16347fc', 'id': 'fa', 'filename': 'fa.nii.gz', 'ext': '.gz', 'required': True, 'desc': 'Tensor measure / Fractional anisotropy (normalized fraction of anisotropic component)'}, {'_id': '5f2e1437beafe9162d6347fd', 'id': 'md', 'filename': 'md.nii.gz', 'ext': '.gz', 'required': True, 'desc': 'Tensor measure / Mean Diffusivity (microm^2/msec)'}, {'_id': '5f2e1437beafe9b8e16347fe', 'id': 'rd', 'filename': 'rd.nii.gz', 'ext': '.gz', 'required': True, 'desc': 'Tensor measure / Radial Diffusivity (microm^2/msec)'}, {'_id': '5f2e1437beafe91d736347ff', 'id': 'ad', 'filename': 'ad.nii.gz', 'ext': '.gz', 'required': True, 'desc': 'Tensor measure / Axial Diffusivity (microm^2/msec)'}, {'_id': '5f2e1437beafe90fba634800', 'id': 'cl', 'filename': 'cl.nii.gz', 'ext': '.gz', 'required': False, 'desc': '??'}, {'_id': '5f2e1437beafe90d49634801', 'id': 'cp', 'filename': 'cp.nii.gz', 'ext': '.gz', 'required': False, 'desc': '??'}, {'_id': '5f2e1437beafe9d579634802', 'id': 'cs', 'filename': 'cs.nii.gz', 'ext': '.gz', 'required': False, 'desc': '??'}, {'_id': '5f2e1437beafe91063634803', 'id': 'tensors', 'filename': 'tensors.nii.gz', 'ext': '.gz', 'required': False, 'desc': '??'}, {'_id': '5f2e1437beafe93421634804', 'id': 'kurtosis', 'filename': 'kurtosis.nii.gz', 'ext': '.gz', 'required': False, 'desc': '??'}, {'_id': '5f2e15febeafe90418634816', 'id': 'ga', 'desc': 'DKI measure / Geodesic Anisotropy (normalized fraction of geodesic component)', 'required': False, 'filename': 'ga.nii.gz'}, {'_id': '5f2e15febeafe93291634817', 'id': 'mk', 'desc': 'DKI measure / Mean kurtosis (microm^2/msec)', 'required': False, 'filename': 'mk.nii.gz'}, {'_id': '5f2e15febeafe91bd8634818', 'id': 'ak', 'desc': 'DKI measure / Axial kurtosis (microm^2/msec)', 'required': False, 'filename': 'ak.nii.gz'}, {'_id': '5f2e15febeafe97701634819', 'id': 'rk', 'desc': 'DKI measure / Radial kurtosis (microm^2/msec)', 'required': False, 'filename': 'rk.nii.gz'}, {'_id': '5f7356a49d2115566093f084', 'id': 'rgb', 'desc': 'RGB color value assigned for each voxel (colored FA)', 'required': False, 'filename': 'rgb.nii.gz'}]","['16', '1']",11,"['dipy_reconst_dti', 'dki', 'dti', 'epi_reg', 'fsl', 'mrtrix3', 'warped']",2020-08-08T02:55:51.058Z,[],['5d7c0635f59daf4ee88c3817'],"[{'docker': False, '_id': '5be75b31e15a02914a4be8f0', 'ui': 'raw', 'name': 'File Viewer', 'desc': ""Browse / download files via Brain-Life's File Browser"", 'avatar': 'https://brainlife.io/images/ui-logos/raw.png'}, {'_id': '5bf755f4e15a02914af8f22b', 'ui': 'fsleyes', 'name': 'FSLeyes', 'desc': 'A 2d/3d brain volume viewer.', 'avatar': 'https://brainlife.io/images/ui-logos/fsleyes.png', 'docker': True}]",False,,,,,"{'_id': '5f2e1427beafe9f9e26347fa', 'maps': [{'_id': '5f2e1437beafe9cce0634805', 'src': 'fa.nii.gz', 'dest': 'GFA.nii.gz'}, {'_id': '5f2e1437beafe96a89634806', 'src': 'md.nii.gz', 'dest': 'MD.nii.gz'}, {'_id': '5f2e1437beafe9d1dd634807', 'src': 'rd.nii.gz', 'dest': 'RD.nii.gz'}, {'_id': '5f2e1437beafe9c145634808', 'src': 'ad.nii.gz', 'dest': 'AD.nii.gz'}], 'derivatives': 'dwi'}",
5907d922436ee50ffde9c549,neuro/track/tck,MRtrix Track Data (.tck),"[{'_id': '5e4208ec301ffca3043407d6', 'id': 'track', 'filename': 'track.tck', 'required': True}]",['1'],22,"['ACT', 'TractSeg', 'aLIC', 'csd_det', 'dipy_long', 'dt_stream', 'dwi', 'ensemble', 'filtered', 'fit2prediction', 'intersected', 'merged', 'mni_space', 'optic_radiation', 'res', 'resampled', 'roi2roi', 'roi_mrtrix3_ifod2', 'roi_trekker', 'sd_prob', 'sd_stream', 't1', 'testing', 'tracking_eccentricity']",2020-02-11T01:52:44.772Z,[],['5d7c0635f59daff0888c380c'],"[{'docker': False, '_id': '5be75b31e15a02914a4be8f0', 'ui': 'raw', 'name': 'File Viewer', 'desc': ""Browse / download files via Brain-Life's File Browser"", 'avatar': 'https://brainlife.io/images/ui-logos/raw.png'}, {'_id': '5bf75608e15a02914af8f2e3', 'ui': 'mrview', 'name': 'mrView', 'desc': 'The MRtrix image viewer.', 'avatar': 'https://brainlife.io/images/ui-logos/mrview.png', 'docker': True}, {'_id': '5f724b403ad30ab2f0c0ce5e', 'ui': 'dsistudio', 'name': 'dsi-studio', 'desc': 'DSI Studio is a tractography software tool that maps brain connections and correlates findings with neuropsychological disorders.', 'avatar': 'https://raw.githubusercontent.com/brainlife/brainlife.hugo/master/static/images/ui-logos/dsi_studio.png', 'docker': True}]",False,,brainlife/validator-neuro-track,,,"{'_id': '5e4208e3301ffc588c3407d4', 'maps': [{'_id': '5e4208ec301ffc3efa3407d7', 'src': 'track.tck', 'dest': 'tractography.tck'}, {'_id': '5e4208ec301ffca8463407d8', 'src': '_meta_', 'dest': 'tractography.json'}], 'derivatives': 'dwi'}",
5b956f6cd7b3f1e24e9121ce,neuro/track/trk,"TrackVis (.trk). Track file is one single binary file, with the first 1000 bytes as the header and the rest as the body.","[{'_id': '5dcef986c4ae28a5e9298edf', 'id': 'track', 'filename': 'track.trk', 'required': True}]",['1'],10,"['ACT', 'afq', 'cleaned', 'csd_eudx', 'dipy_long', 'dt_stream', 'dwi', 'ensemble', 'full', 'multi-LAPanat', 'noACT', 'res', 'roi_mrtrix3_ifod2', 'sd_prob', 'sd_stream', 't1', 'wmaSeg', 'wmc']",2019-11-15T19:16:22.167Z,[],[],"[{'docker': False, '_id': '5be75b31e15a02914a4be8f0', 'ui': 'raw', 'name': 'File Viewer', 'desc': ""Browse / download files via Brain-Life's File Browser"", 'avatar': 'https://brainlife.io/images/ui-logos/raw.png'}, {'_id': '5bf75615e15a02914af8f351', 'ui': 'trackvis', 'name': 'trackvis', 'desc': 'A software tool that can visualize and analyze fiber track data from diffusion MR imaging (DTI/DSI/HARDI/Q-Ball) tractography', 'avatar': 'https://brainlife.io/images/ui-logos/trackvis.jpg', 'docker': True}, {'_id': '5bf7563de15a02914af8f4c5', 'ui': 'freeview-gpu', 'name': 'FreeView', 'desc': 'A freesurfer program used to view and work with structural, anatomical scans.', 'avatar': 'https://brainlife.io/images/ui-logos/freeview.png', 'docker': True}, {'_id': '5f724b403ad30ab2f0c0ce5e', 'ui': 'dsistudio', 'name': 'dsi-studio', 'desc': 'DSI Studio is a tractography software tool that maps brain connections and correlates findings with neuropsychological disorders.', 'avatar': 'https://raw.githubusercontent.com/brainlife/brainlife.hugo/master/static/images/ui-logos/dsi_studio.png', 'docker': True}]",False,,brainlife/validator-neuro-track,,,"{'_id': '5dcef982c4ae28ba65298edd', 'maps': [{'_id': '5dcef986c4ae282a14298ee1', 'src': 'track.trk', 'dest': 'tractography.trk'}, {'_id': '5dcef986c4ae28a54f298ee0', 'src': '_meta_', 'dest': 'tractography.json'}], 'derivatives': 'dwi'}",
61b1867f7577fd30683bcaf5,neuro/track/trx,TRX: A community-oriented tractography file format,"[{'id': 'track', 'filename': 'track.trx', 'dirname': '', 'desc': 'trx is a directory containing various sub-directories such as dpg / dpv / dps / groups / heaer.json  / etc', 'required': True, '_id': '61b1867f7577fd30683bcaf6'}]","['1', '386']",3,[],2021-12-09T04:30:55.813Z,[],[],"[{'docker': False, '_id': '5be75b31e15a02914a4be8f0', 'ui': 'raw', 'name': 'File Viewer', 'desc': ""Browse / download files via Brain-Life's File Browser"", 'avatar': 'https://brainlife.io/images/ui-logos/raw.png'}]",False,https://github.com/frheault/tractography_file_format/blob/master/trx_file_memmap/specifications.md,,,,,
592dded1436ee50ffd88f5d0,neuro/tractmasks,(might be deprecated by neuro/rois in the future) List of nifti volumes for each tract segments. Each nifti files should be binarized (contains either 0 or 1). This datatype is very similar to neuro/rois (neuro/rois a bit more generic). We recommend using neuro/rois instead to increase compatibilities with more apps. ,"[{'id': 'masks', 'dirname': 'masks', 'desc': 'A directory containing nifti files with binarized (0 or 1) tract masks.', 'required': True, '_id': '6115212da5a04c359ff9a373'}]",['1'],10,"['density', 'ending_segmentations', 'stem_segmentations', 'tract_segmentations']",2020-09-08T15:43:02.926Z,[],[],"[{'docker': False, '_id': '5be75b31e15a02914a4be8f0', 'ui': 'raw', 'name': 'File Viewer', 'desc': ""Browse / download files via Brain-Life's File Browser"", 'avatar': 'https://brainlife.io/images/ui-logos/raw.png'}]",False,,,,,,
599f305ad1f46fec1759f363,neuro/tractmeasures,A csv file listing various measures and statistics of classified tracts,"[{'id': 'csv', 'filename': 'tractmeasures.csv', 'desc': 'Used to be called output_FiberStats.csv', 'required': True, '_id': '5ffc7c0c2ba0fbc38fe8871f'}]","['16', '1', '146']",27,"['ROC', 'afq', 'categories', 'cleaned', 'eccentricity', 'intersected', 'macro', 'macro_micro', 'optic_radiation', 'profiles', 'quickbundles', 'roi_mrtrix3_ifod2', 'roi_trekker', 'test', 'tracking_eccentricity', 'tract_segmentations', 'tsv', 'wmaSeg']",2020-09-08T15:43:02.942Z,"[{'datatype_tag': 'profiles', 'desc': ""This tag is intended for profilometric data. Can be single-node (i.e. tract average) or multi-node (profiles). Each column represents a measure. REQUIRED: column named 'structureID' containing the tract names being described. "", '_id': '602551eadea2e2cc0e78cd3f'}, {'datatype_tag': 'macro', 'desc': ""This tag is intended for macrostatistics data of tracts. Generally single-value per tract. Measures include, but not limited to, length, volume, count, curvature. Each column represents a measure. REQUIRED: column named 'structureID' containing the tract names being described. "", '_id': '602551eadea2e2848b78cd41'}, {'datatype_tag': 'macro_micro', 'desc': ""This tag is intended for the combination of profilometric data (i.e. micro) and macrostructural statistics of segmented tractgrams. Measures include, but not limited to, length, volume, count, curvature. Each column represents a measure. REQUIRED: column named 'structureID' containing the tract names being described. "", '_id': '62c35e2ef3194eded6fbe928'}, {'datatype_tag': 'tractseg_tractometry', 'desc': 'This tag is intended for the Tractometry_peaks.csv file produced by TractSeg. The header corresponds to the list of the tracts for which tractometry is available (up to 50). On the rows, the single metric value at each node is reported (the number of rows is 98 since the first and last nodes are dropped).', '_id': '6356fc81fa262bbde2bf5edf'}]","['60a6765a8aef1aad16d2be3a', '60a6a6a78aef1a02a2d5a635']","[{'docker': False, '_id': '5be75b31e15a02914a4be8f0', 'ui': 'raw', 'name': 'File Viewer', 'desc': ""Browse / download files via Brain-Life's File Browser"", 'avatar': 'https://brainlife.io/images/ui-logos/raw.png'}]",True,"## profile data
Note that the tensor measures (ad, fa, md, rd) are the most common for tract profilometry, and thus are being defined here. However, it is possible to perform profilometry without the tensor model measures, and thus your columns may vary. The two most important columns here are 'structureID', which defines the tract name, and 'nodeID', which defines the node along the tract that the sample comes from.
```
structureID,nodeID,ad,fa,md,rd
9002,anterioFrontalCC,1,1.0019006889695898,0.24268335891982998,0.805430040663103,0.7071947157091801
9002,anterioFrontalCC,2,0.9950038146613741,0.254798299231487,0.789624928849494,0.686935485811522
9002,anterioFrontalCC,3,0.993601256629925,0.265887020991478,0.779734001108083,0.6728003741142728
9002,anterioFrontalCC,4,0.996656880870817,0.275811464734581,0.7745675249992672,0.663522849165054
9002,anterioFrontalCC,5,1.00283331746702,0.284366581530563,0.7728782779258171,0.6579007619941128
9002,anterioFrontalCC,6,1.0115783702678198,0.292515316388438,0.7733881760068231,0.65429308441503
9002,anterioFrontalCC,7,1.02225832698264,0.300337351987778,0.775467393528038,0.652071934108625
9002,anterioFrontalCC,8,1.0339884711985,0.30865612456029495,0.7782409165546359,0.65036714813835
...
```


## macro data
```
structureID,StreamlineCount,volume,averageStreamlineLength
wbfg,3000000,810751,65.2514924075696
forcepsMinor,14099,60410,105.731972723956
forcepsMajor,4081,62772,150.358790348804
parietalCC,9849,71726,134.825090667247
middleFrontalCC,26724,88239,107.105992469294
anterioFrontalCC,12943,81067,102.599889955666
...
```

## macro_micro data
This tag is intended for the combination of profilometric data (i.e. micro) and macrostructural statistics of segmented tractgrams. 


## tractseg_tractometry data
This tag is intended for the Tractometry_peaks.csv file produced by TractSeg. The header corresponds to the list of tracts for which tractometry is available (up to 50 tracts). On the rows, the single metric value at each node is reported (the number of rows is 98 since the first and last nodes are dropped).
```
AF_left		AF_right	ATR_left	ATR_right	CC_1 ...
0.303229543104303	0.38406270303966	0.327933922929156	0.366009730347503	0.272032753658072 ...
0.314547988510265	0.381685942522947	0.338081227248489	0.357288162926036	0.283212173047058 ...
0.335131049401065	0.390992535108405	0.353733501285894	0.368398958358031	0.298387214533339 ...
0.358696506161878	0.403191425976436	0.350793235502353	0.379496356078586	0.313209308367591 ...
0.374724823800164	0.42180236579076	0.362169293075503	0.371354171478226	0.325845129115041 ...
0.390861091163352	0.423967894431337	0.353761813965393	0.380103259370617	0.335139814450343 ...
0.43133852465121	0.416558198546214	0.336435631306328	0.386099828381267	0.344068721377194 ...
0.435267521263819	0.398952599799162	0.329597462231323	0.379060014078116	0.360103802902478 ...
0.417307986951566	0.381144758931852	0.337344700599544	0.381887989404343	0.377558340144154 ...
...
```",brainlife/validator-neuro-tractmeasures,"[{'id': 'subject', 'type': 'string', 'required': True}]",,,
5965467cb09297d8d81bdbcd,neuro/tractprofile-deprecated,A directory containing a bunch of csv files containing tractprofile measures. This datatype has been deprecated by neuro/tractmeasures<profile> datatype.,"[{'_id': '5dcf0d53c4ae2854352991f5', 'id': 'profiles', 'dirname': 'profiles', 'required': True}]","['16', '1']",14,[],2019-11-15T20:40:51.239Z,[],['60a676688aef1a57a8d2be66'],"[{'docker': False, '_id': '5be75b31e15a02914a4be8f0', 'ui': 'raw', 'name': 'File Viewer', 'desc': ""Browse / download files via Brain-Life's File Browser"", 'avatar': 'https://brainlife.io/images/ui-logos/raw.png'}]",True,"The first row of each csv should contain the measurement headers which are..

ad_mean
ad_sd
ad_inverse_mean
ad_inverse_sd
fa_mean
fa_sd
fa_inverse_mean
fa_inverse_sd
md_mean
md_sd
md_inverse_mean
md_inverse_sd
rd_mean
rd_sd
rd_inverse_mean
rd_inverse_sd
ga_mean
ga_sd
ga_inverse_mean
ga_inverse_sd
mk_mean
mk_sd
mk_inverse_mean
mk_inverse_sd
ak_mean
ak_sd
ak_inverse_mean
ak_inverse_sd
rk_mean
rk_sd
rk_inverse_mean
rk_inverse_sd
ndi_mean
ndi_sd
ndi_inverse_mean
ndi_inverse_sd
isovf_mean
isovf_sd
isovf_inverse_mean
isovf_inverse_sd
odi_mean
odi_sd
odi_inverse_mean
odi_inverse_sd
x_coords
y_coords
z_coords

",brainlife/validator-neuro-tractprofile,,,,
630d072219b13f0a0ee3cd15,neuro/tractseg,"Tractseg output directory containing bundle_segmentations, endings_segmentations, Tractometry_peaks.csv, etc..","[{'id': 'nodif_brain_mask', 'filename': 'nodif_brain_mask.nii.gz', 'dirname': '', 'desc': '', 'required': True, '_id': '630d072219b13f0a0ee3cd16'}, {'id': 'peaks', 'filename': 'peaks.nii.gz', 'desc': '', 'required': True, '_id': '630d098619b13f0a0ee3ce33'}, {'id': 'bundle_segmentations', 'dirname': 'bundle_segmentations', 'desc': '', 'required': True, '_id': '630d098619b13f0a0ee3ce34'}, {'id': 'endings_segmentations', 'filename': '', 'dirname': 'endings_segmentations', 'desc': '', 'required': True, '_id': '630d098619b13f0a0ee3ce35'}, {'id': 'TOM', 'dirname': 'TOM', 'desc': '(Collection of .nii.gz files)', 'required': True, '_id': '630d098619b13f0a0ee3ce36'}, {'id': 'TOM_trackings', 'dirname': 'TOM_trackings', 'desc': '(Collection of .tck files)', 'required': True, '_id': '630d098619b13f0a0ee3ce37'}, {'id': 'Tractometry_peaks', 'filename': 'Tractometry_peaks.csv', 'desc': 'Columns look like ""AF_left;AF_right;ATR_left;ATR_right;CC_1;CC_2""', 'required': False, '_id': '630d098619b13f0a0ee3ce38'}]","['1', '146']",1,[],2022-08-29T18:36:18.747Z,[],[],"[{'docker': False, '_id': '5be75b31e15a02914a4be8f0', 'ui': 'raw', 'name': 'File Viewer', 'desc': ""Browse / download files via Brain-Life's File Browser"", 'avatar': 'https://brainlife.io/images/ui-logos/raw.png'}]",False,"```
nodif_brain_mask.nii.gz
peaks.nii.gz 
bundle_segmentations (dir)
endings_segmentations (dir)
TOM  (dir)
TOM_trackings (dir)
Tractometry_peaks.csv 
```",,,,,
62618e2afdf0b815e4ba5372,neuro/transform/h5,"A transformation file encapsulates a mathematical operation on the coordinates of those objects susceptible of being spatially transformed (i.e. images, surfaces, or points).  Similar to neuro/transform/fsl but uses .h5 (.x5)","[{'id': 'warp', 'filename': 'warp.h5', 'desc': 'The native space to standard space warp', 'required': True, '_id': '62618e2afdf0b815e4ba5373'}, {'id': 'inverse-warp', 'filename': 'inverse-warp.h5', 'dirname': '', 'desc': 'The standard space to native space warp', 'required': True, '_id': '62644a09f3858674a29b19e4'}, {'id': 'affine', 'filename': 'affine.txt', 'desc': 'The linear transformation from native space to standard space', 'required': True, '_id': '62644a09f3858674a29b19e5'}]","['1', '16']",2,[],2022-04-21T17:02:34.651Z,"[{'datatype_tag': 'image', 'desc': 'Indicates how the from and to labels should be interpreted as a coordinates mapping internal to a resampling process (image).', '_id': '626190a9fdf0b815e4ba5790'}, {'datatype_tag': 'sphere', 'desc': 'Indicates how the from and to labels should be interpreted as a coordinates mapping internal to a resampling process (sphere).', '_id': '626190a9fdf0b815e4ba5791'}, {'datatype_tag': 'points', 'desc': 'Indicates how the from and to labels should be interpreted as pure coordinates mapping (points) ', '_id': '626190a9fdf0b815e4ba5792'}, {'datatype_tag': 'surface', 'desc': 'Indicates how the from and to labels should be interpreted as pure coordinates mapping (surface) ', '_id': '626190a9fdf0b815e4ba5793'}]",[],"[{'docker': False, '_id': '5be75b31e15a02914a4be8f0', 'ui': 'raw', 'name': 'File Viewer', 'desc': ""Browse / download files via Brain-Life's File Browser"", 'avatar': 'https://brainlife.io/images/ui-logos/raw.png'}]",False,Roughly based on https://docs.google.com/document/d/11gCzXOPUbYyuQx8fErtMO9tnOKC3kTWiL9axWkkILNE/edit,,,,,
5bbfb28071454db2a890fbce,neuro/transform/nifti,Linear & Non-Linear Image Warping in FSL format (warp.nii.gz / inverse-warp.nii.gz),"[{'id': 'warp', 'filename': 'warp.nii.gz', 'required': False, '_id': '5fa9555dafcdcc44d3c40495'}, {'id': 'inverse-warp', 'filename': 'inverse-warp.nii.gz', 'required': False, '_id': '5fa9555dafcdcc79a3c40496'}, {'id': 'affine', 'filename': 'affine.txt', 'desc': 'Both linear and non-linear transform should at least have affine.txt. We are currently setting this optional for older Apps that are yet to generate affine.txt. In the future, affine.txt will be the only required file.', 'required': False, '_id': '5fa9555dafcdcc5abcc40497'}]",['1'],28,"['ANTs', 'CHM', 'Control', 'MNI152', 'STGD', 'acpc_aligned', 'affine', 'anat', 'baseline', 'brain_extracted', 'crop_reorient', 'debiased', 'dwi-to-t1', 'fa_warping', 'image 3', 'image 4', 'image 5', 'image 6', 'image 7', 'image 8', 'image_10', 'image_11', 'image_22', 'image_28', 'image_28a', 'image_3', 'image_30', 'image_31', 'image_32', 'image_33', 'image_34', 'image_5', 'image_7', 'image_9', 'linear', 'preprocessed', 'second 1', 'session 1', 'session 2', 'session_1', 'session_2', 'standard', 't1_to_acpc', 't1_warping_mni152', 't2_to_acpc', 'warp']",2020-09-08T15:43:02.953Z,"[{'datatype_tag': 'linear', 'desc': 'By default, neuro/transform should have both linear (affine.txt) and non-linear (warp.nii.gz) components. For a simple linear transformation, you should set this tag to indicate that the this object only contains affine.txt. Some App can only work on linear transform, and some can only work on non-linear transform.', '_id': '60de0ea14cb70497f703f5f9'}, {'datatype_tag': 'image', 'desc': 'Indicates how the from and to labels should be interpreted as a coordinates mapping internal to a resampling process (image).', '_id': '6261913ffdf0b815e4ba5cfd'}, {'datatype_tag': 'sphere', 'desc': 'Indicates how the from and to labels should be interpreted as a coordinates mapping internal to a resampling process (sphere).', '_id': '6261913ffdf0b815e4ba5cfe'}, {'datatype_tag': 'points', 'desc': 'Indicates how the from and to labels should be interpreted as pure coordinates mapping (points)', '_id': '6261913ffdf0b815e4ba5cff'}, {'datatype_tag': 'surface', 'desc': 'Indicates how the from and to labels should be interpreted as pure coordinates mapping (surface)', '_id': '6261913ffdf0b815e4ba5d00'}]",[],"[{'docker': False, '_id': '5be75b31e15a02914a4be8f0', 'ui': 'raw', 'name': 'File Viewer', 'desc': ""Browse / download files via Brain-Life's File Browser"", 'avatar': 'https://brainlife.io/images/ui-logos/raw.png'}]",False,Roughly based on https://docs.google.com/document/d/11gCzXOPUbYyuQx8fErtMO9tnOKC3kTWiL9axWkkILNE/edit,,,,,
5cc1d64c44947d8aea6b2d8b,neuro/wmc,White Matter Classification (no FG),"[{'_id': '5e894192952fefe17c7ad860', 'id': 'classification', 'filename': 'classification.mat', 'required': True}, {'_id': '5e894192952fefe9d07ad861', 'id': 'tracts', 'dirname': 'tracts', 'required': False, 'desc': 'Used for VIS purpose only.'}, {'_id': '5e894192952fef15c67ad862', 'id': 'surfaces', 'dirname': 'surfaces', 'required': False, 'desc': 'If there is ROI / parcellation associated with this wmc, please convert them to .vtk surfaces and store them here to be used by VIS'}]","['56', '146', '1']",39,"['ACT', 'aLIC', 'afq', 'categories', 'classifyber', 'cleaned', 'customSeg', 'eccentricity', 'ensemble', 'intersected', 'life', 'multi-LAP', 'noACT', 'optic_radiation', 'quickbundles', 'res', 'roi2roi', 'roi_mrtrix3_ifod2', 'roi_trekker', 'sd_prob', 'surface_rois', 'tracking_eccentricity', 'tractseg', 'wmaSeg']",2020-04-05T02:25:22.098Z,[],['5d8a60279842201ded7ec330'],"[{'docker': False, '_id': '5be75b31e15a02914a4be8f0', 'ui': 'raw', 'name': 'File Viewer', 'desc': ""Browse / download files via Brain-Life's File Browser"", 'avatar': 'https://brainlife.io/images/ui-logos/raw.png'}, {'docker': False, '_id': '5bf7558be15a02914af8ee4e', 'ui': 'tractview', 'name': 'WMC Tract View', 'desc': 'Web-based visualization tools for white matter tracts.', 'avatar': 'https://brainlife.io/images/ui-logos/tractview.png'}]",False,"## What is a WMC (White Matter Classification) object _conceptually_?

A WMC is best thought of as the tractogram's equivalent of a parcellation for a nifti brain volume, in that it assigns (anatomical) identities to the constituent elements (in this case streamlines) of the larger object.  It is the result of the interaction of the following three entities

1. A tractogram:  a specific, omnibus, streamline-based, heterogeneous (in that it does not correspond to one indifferentiable ""thing"") model of white matter anatomy.
2.  A white matter ontology:  a finite set of white matter anatomical entities to which the constituent streamlines of the associated tractogram can be assigned membership.
3.  A segmentation:  a ruleset or algorithm which is used to assign the constituent elements of the tractogram (i.e. streamlines) membership or identity amongst the elements of the associated white matter ontology.  

In this way, a given WMC object is a-contextual (and thus relatively uninterpretable) _unless_ it can be clearly and easily associated with the _specific instances_ of the three entities listed above.

## What is a WMC (White Matter Classification) object _structurally_?

In essence, the WMC is composed of two parts:  **the index vector** and **the names vector** stored in HDF5 Matlab object with the filename of `classification.mat` which should be 1x1 struct with 2 fields

```
classification = 

  struct with fields:

    names: {1×61 cell} - cell array with a single row
    index: [1×675000 double] -  (675000 is the number of fibers for this example - from tck)
```

### .index
The index vector is a 1 by n vector of integers assigning categorical identity/membership to the streamlines of **the associated tck entity** (tractogram), where n is the number of streamlines in that object.  The integer values assigned to each streamline correspond to the index of a name in the name field, which itself corresponds to an element of the associated white matter ontological set.  **The index vector is not zero indexed** , meaning that an entry of zero **does not** correspond to the first entry on the names list.  Instead, a streamline with 0 in its .index entry indicates that no _specific_ identity was assigned to this streamline.  This is perfectly permissible and may result from one of several causes (with respect to the diagram above, a failure for one of the following scenarios to obtain:  ""No 'false positive' streamlines"", ""all WM entities enumerated"", or ""all streamlines mapped"".  Indeed, an ontology which intends to leave no component of the white matter uncategorized can be described as _complete_ (i.e. https://doi.org/10.25663/brainlife.app.249), while one which does not have this intent can be described as _incomplete_ (https://doi.org/10.25663/brainlife.app.188 or https://doi.org/10.25663/brainlife.app.207)

For example...


```
Columns 674929 through 674946

     0     0     0     0     0    26     0    15     0     0     0     0     0     0     0     0     0     0

  Columns 674947 through 674964

     0     0     0     0     0     0     0     0     4     0    24     0     0     0     0     0     0     0

  Columns 674965 through 674982

     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0

  Columns 674983 through 675000

     0     0     0     0    36     0     0     0     0     0     0     0     0     0     0     0     0     0

```

As it is currently implemented, The WMC, _as a data construct_ (and thus any given instance of a WMC), is both _exclusive_ and _non-hierarchical_.  This means that for any streamline, for a given WMC object, there can be _only one_ white matter anatomical entity/category (i.e. name) that it can be assigned to, and that (**generally speaking**) there is no higher order structuring of entities/categories _with respect to the structure of the WMC object itself_.  This stipulation warrants a couple of qualifications, though.  In practice, it is best to keep the right and left variants of an anatomical entity (should they exist) next to one another in the .names field (and thus also in .index numeration) for the sake of interpretability.  Furthermore, while there may be hierarchical structure within the associated white matter ontology _itself_, which could potentially be inferred from naming conventions in the .names field, there is nothing inherent to the WMC structure _itself_ which would or could indicate this.

### .names
The .names vector enumerates those anatomical structures (ontological set members of the associated white matter ontology superset) that the Application has attempted to segment.  For practical reasons (e.g. brevity) these entries may be abbreviations or shortened versions of longer category labels/names from the associated white matter ontology.  

For example...

```
1×61 cell array

  Columns 1 through 5

    {'forcepsMinor'}    {'forcepsMajor'}    {'parietalCC'}    {'middleFrontalCC'}    {'anterioFrontalCC'}

  Columns 6 through 10

    {'leftcingulum'}    {'rightcingulum'}    {'leftUncinate'}    {'rightUncinate'}    {'leftIFOF'}
```

## Quick rules

### .names

- No spaces in .names entries:  default replacement behavior should be to replace spaces with underscores
- Some but not all .name entries may correspond to the ""left"" or ""right"" right variant of a category/structure.  Such paired entries should be kept next to each other, and the associated .index values should be adjusted accordingly (see [here](https://github.com/DanNBullock/wma_tools/blob/master/ClassificationStruc_Tools/wma_resortClassificationStruc.m) for an example implementation).
- All .names entries should be unique, and non-empty.
- No entries in the .name list may be blank (a blank entry could not correspond to a category from the associated white matter ontology)

### .index

- The number of unique values in .index should be less than or equal to the number of entries in .names + 1 
- index numeral 0 is used to indicate that the corresponding streamline does not belong to *any* structure listed in .names array, and is thus (in a sense) ""unlabeled"".  As a corollary to this, it is likely ill advised to actually created an explicit category ""unlabeled"", as this would force there to be a numerical index for ""unlabeled"" other than 0.
- The integer values assigned to each streamline in the index vector should correspond to the index of a name in the .names field, *without conversion, transformation, or adjustment*.
- "".index"" will contain integer values from 0 to the number of entries in .names. In the case that no streamline is associated with a particular white matter structure (in .names), the corresponding index will not occur in .index.
- The number of entries in the .index vector should be **EXACTLY EQUAL** to the number of streamlines in the associated tractogram.
-  Because the identities assigned in the WMC object are locked to specific streamlines in the source tractogram, the sequencing of entries in the .index vector should be kept locked to the sequence of streamlines.  That is, if the sequential ordering of the streamlines in the associated tractogram (/.tck object) changes, the ordering of the corresponding WMC objects should change in exact correspondence with this shift.  Given that multiple WMC objects (from multiple ontologies/segmentations) could be associated with a single tractogram, **the sequencing of the source tractogram should take precedence over any particular WMC object**.
-   For the above reason, one should essentially *never* change the ordering of streamlines in a tractogram (e.g. .tck) object.

## Rationale 

### Why not store this as multiple track files in a directory?
Theoretically, it would be possible to store a separate track file for each track in a directory.  However, this is not efficient in terms of storage.  This is because, in cases where the tracts have been extracted from a source tractograms, those streamlines are doubly represented in storage, both in the source tractogram object, and in the extracted tract files.  An alternative way to illustrate this is to think about NiFTI-based anatomical parcellations and the data objects they are derived from.

As an analogy, one way of storing a parcellation would be to create N number of separate NiFTI files each containing all and only the data corresponding to each of the N labels, with all other entries (voxels) zeroed out.  Thus, any time a consumer algorithm wanted to extract the info specific to a label, it would just go to the relevant NiFTI file.  However, this isn't a very elegant or parsimonious method.  Instead, we typically use the parcellation to mask the voxels of interest in the relevant associated NiFTI and proceed accordingly.  Moreover, this dictionary-like operation is not a particularly computationally expensive operation for NiFTIs.  Similarly, it is not a particularly computationally expensive operation for WMC-type objects and their associated tractograms.

Additionally, null models which make use of unlabeled or shuffled streamlines would, at some point, need to amalgamate the component tract objects in order to compare across tract labelings/categories.

## Validator

A validator for this datatype (with examples of valid/invalid WMC structures) can be found [here](https://github.com/brainlife/validator-neuro-wmc).

## Future plans

Moving away from the .mat format is likely to occur in the future.  Potential alternatives include .csv, .tsv, and .json.  Of these, .json currently appears to be the most likely candidate.  This is because it maintains the pairing of the .names and .index fields, whereas separate files (As would be implemented in 1-d vector .csv or .tsv files) could lose their pairing / provenance.

Forcing the .index vector to various forms of uint can be used to save space, however the footprint reduction may be minimal.",brainlife/validator-neuro-wmc,,,,
58f10a90436ee50ffd9063c5,neuro/wmc-deprecated,White Matter Classification and FG structure,"[{'_id': '643852d4b32aa6e00a1684ec', 'id': 'output', 'filename': 'output.mat', 'required': True}, {'_id': '643852d4b32aa6e00a1684ed', 'id': 'fibercounts', 'filename': 'output_fibercounts.txt', 'required': False}, {'_id': '643852d4b32aa6e00a1684ee', 'id': 'tracts', 'dirname': 'tracts', 'required': False}, {'_id': '643852d4b32aa6e00a1684ef', 'id': 'surfaces', 'dirname': 'surfaces', 'required': False}]",['1'],1,"['afq', 'ants_fa_aligned', 'ants_t1_aligned', 'categories', 'cleaned', 'dt_stream', 'ensemble', 'life', 'multi-LAP', 'multi-LAPanat', 'pre_life', 'roi2roi', 'sd_prob', 'sd_stream', 'tractseg', 'wmaSeg']",2020-09-08T15:43:02.924Z,[],[],"[{'docker': False, '_id': '5be75b31e15a02914a4be8f0', 'ui': 'raw', 'name': 'File Viewer', 'desc': ""Browse / download files via Brain-Life's File Browser"", 'avatar': 'https://brainlife.io/images/ui-logos/raw.png'}, {'docker': False, '_id': '5bf7558be15a02914af8ee4e', 'ui': 'tractview', 'name': 'WMC Tract View', 'desc': 'Web-based visualization tools for white matter tracts.', 'avatar': 'https://brainlife.io/images/ui-logos/tractview.png'}]",False,,,,,,
5d7055105cee3829d5314c19,openscience/reprolit,"This is the data type for the paper: Open science and communal culture promote women's participation, diversity and discovery. You can visit this link for more information: https://github.com/contactaditya/BrainlifeCadreCollaboration/blob/master/Notes.txt","[{'_id': '643852d4b32aa6e00a1684f0', 'id': 'dictionary', 'filename': 'lancet_dictionary.csv', 'desc': 'Lancet Dictionary. This is a csv file which is a dictionary of words which are most commonly used in scientific papers and publications. This dictionary classifies the various words under different categories such as feminine, masculine, learning, competition, policing, innovation, pro social motives, collaboration, team, team focused, individual focused. ', 'required': True}, {'_id': '643852d4b32aa6e00a1684f1', 'id': 'open-old', 'filename': 'open-old.csv', 'desc': ""This is a csv file which is used to built a collaboration network from the 3157 unique author ID's in the Open Science literature. Apart from building the collaboration network we also performed connected component analysis of the network to measure the degree of isolation of individual sub-networks of authors within each literature."", 'required': True}, {'_id': '643852d4b32aa6e00a1684f2', 'id': 'journal', 'filename': 'open_science_journal.csv', 'desc': 'This is a csv file which contains data from Microsoft Academic Graph, consisting of 2,926 scientific articles and conference proceedings published between 2010 and 2017 that included Open Science or Reproducibility as a field of study. This sample consisted of 879 Open Science papers and 2,047 Reproducibility papers.', 'required': True}, {'_id': '643852d4b32aa6e00a1684f3', 'id': 'repro-old', 'filename': 'repro-old.csv', 'desc': ""This is a csv file which is used to built a collaboration network from the 8766 unique author ID's in the Reproducibility literature. Apart from building the collaboration network we also performed connected component analysis of the network to measure the degree of isolation of individual sub-networks of authors within each literature."", 'required': True}]",['1'],1,[],2020-09-08T15:43:02.965Z,[],[],[],False,,,,,,
5ebe0bbbb969982124072325,optometry/oct,"Raw data from compatible systems with the Orion® software (Voxeleron, LLC, Pleasanton, CA, USA), and an associated centroid indicator file","[{'_id': '5ebe0bbbb96998d8fc072326', 'id': 'os_raw', 'desc': 'The raw output from a Voxeleron OCT device for the left eye.  S in the name stem is an abbreviation for sinister, indicating left.', 'required': True, 'filename': 'OS_raw.csv'}, {'_id': '5ebe0bbbb969986069072327', 'id': 'os_centroid', 'desc': 'This file is the slice and position coordinate of the foveal centroid for the associated eye.', 'required': True, 'filename': 'OS_centroid.csv', 'dirname': ''}, {'_id': '5ebe0bbbb969987342072328', 'id': 'od_raw', 'desc': 'The raw output from a Voxeleron OCT device for the right eye.  D in the name stem is an abbreviation for dexter, indicating right.', 'required': True, 'filename': 'OD_raw.csv'}, {'_id': '5ebe0bbbb96998b864072329', 'id': 'od_centroid', 'desc': 'This file is the slice and position coordinate of the foveal centroid for the associated eye.', 'required': True, 'filename': 'OD_centroid.csv'}]","['56', '1']",7,[],2020-05-15T03:25:47.626Z,[],[],"[{'docker': False, '_id': '5be75b31e15a02914a4be8f0', 'ui': 'raw', 'name': 'File Viewer', 'desc': ""Browse / download files via Brain-Life's File Browser"", 'avatar': 'https://brainlife.io/images/ui-logos/raw.png'}]",False,"The [eyeIndicator]_raw.csv file corresponds to the direct ouput of the Voxeleron OCT device.  The [eyeIndicator]_centroid file is a two number csv file indicating the slice and position of the foveal centroid for the associated eye.  For a description of how to derive these values from Voxelron output, please see the Centroid CSV section here (https://github.com/DanNBullock/OCT_scripts/blob/brainlife_code/OCTcode/convertToSubject.md)

For a guide to converting from group directory structure to single subject directory structure, please see https://github.com/DanNBullock/OCT_scripts/blob/brainlife_code/OCTcode/convertToSubject.md",brainlife/validator-optometry-oct,,,,
59c3eae633fc1cf9ead71679,raw,Unstructured data not meant to be used as input to any other Apps. You can use this datatype for development purposes. Please register a new datatype once your App is ready to be used by other users.,"[{'_id': '5e56dc9a0f7fa6102d3cc5b2', 'id': 'output', 'dirname': '.', 'required': True}]",['1'],59,"['AP', 'DSC', 'DSC-SLRanat', 'SENSE', 'acpc_aligned', 'afq', 'alpha_peak', 'bedpostx', 'benson', 'benson14_visual_areas', 'biasfield', 'bold', 'broccoli', 'c-pac', 'categories', 'cleaned', 'conn_preprocessing', 'connmatrix', 'cortex_mapping_stats_derivatives', 'cortexmap_derivatives', 'crop_reorient', 'customSeg', 'defaced', 'derivatives', 'dp-optimal', 'dp_fit_results', 'dp_profile', 'dsc-slr', 'dsc-slr-mni', 'dsc-slr-mni-ex', 'dwi', 'dwiqc', 'eccentricity', 'eccentricity-binned', 'ecclog', 'eddy_correct', 'eddy_params', 'eddy_quad', 'eddyqc', 'ensemble', 'fmri', 'fmriprep', 'freesurfer-stats', 'gif', 'gray_matter_density', 'hcp-pipeline', 'hcp_freesurferpost', 'hrsc', 'html', 'image 5', 'image_23', 'image_24', 'image_29', 'image_30', 'image_31', 'image_33', 'image_4', 'image_9', 'inflated_roi_analysis', 'info-multi-LAPanat', 'info_output', 'intersected', 'mask', 'matlab', 'merged', 'microperimetryRings', 'mid', 'mriqc', 'mrtrix3', 'mrtrix3_connectome', 'myelin_mapping', 'nback', 'network', 'networkmatrices', 'noddi', 'normalized', 'optic_radiation', 'or_derivatives', 'orientation', 'preprocessed', 'prf', 'pros_lgn_roi_derivatives', 'psd_image', 'qa_image', 'raw', 'rest', 'roi_mrtrix3_ifod2', 'roi_trekker', 'rsHRF', 'sd_prob', 'session 1', 'session_1', 'session_2', 'snr-cc', 'solr-mlra', 'sst', 'subcort_stats_derivatives', 't1', 't1-t2-ratio', 't2', 'tSNR', 'tSNR_derivatives', 'tensor', 'tensor_metrics', 'test', 'test_gradient_flip', 'tract_endpoints', 'tract_measures', 'tract_profiles', 'tractography_quantification', 'tractseg', 'trks_res', 'visual_areas', 'visual_white_matter', 'visualization', 'volThickEcc', 'volume', 'warp', 'wm_tracts', 'wmaSeg', 'wmc']",2020-02-26T21:01:14.672Z,[],[],"[{'docker': False, '_id': '5be75b31e15a02914a4be8f0', 'ui': 'raw', 'name': 'File Viewer', 'desc': ""Browse / download files via Brain-Life's File Browser"", 'avatar': 'https://brainlife.io/images/ui-logos/raw.png'}]",False,,,"[{'id': 'subject', 'type': 'string', 'required': True}]",,"{'_id': '5e56dc970f7fa621da3cc5b0', 'maps': [{'_id': '5e56dc9a0f7fa6159a3cc5b3', 'src': '.', 'dest': 'output'}, {'_id': '5e56dc9a0f7fa6dd2a3cc5b4', 'src': '_meta_', 'dest': 'output.json'}], 'derivatives': 'dwi'}",
5e56dc330f7fa604cc3cc291,report/html,Unstructured HTML content. This is meant for reporting / HTML output - not as data to be re-used by downstream Apps.,"[{'_id': '5e56dc330f7fa683593cc292', 'id': 'index', 'desc': 'html to open. if index.html does not exist, it will pick the first .html file found within the data-object', 'required': False, 'filename': 'index.html'}, {'_id': '5e56dc330f7fa6c62f3cc293', 'id': 'html', 'desc': 'Any contents referenced by index.html', 'required': True, 'filename': '', 'dirname': 'html'}]",['1'],12,"['communities', 'fmriprep', 'maxwell', 'measurements', 'network-preprocess', 'qsiprep', 'rest', 'time series']",2020-02-26T20:59:31.665Z,[],[],"[{'docker': False, '_id': '5be75b31e15a02914a4be8f0', 'ui': 'raw', 'name': 'File Viewer', 'desc': ""Browse / download files via Brain-Life's File Browser"", 'avatar': 'https://brainlife.io/images/ui-logos/raw.png'}, {'_id': '5e56db217ba4a359997127ce', 'ui': 'html', 'name': 'HTML Viewer', 'desc': 'Show HTML contents', 'avatar': 'https://brainlife.io/images/ui-logos/html.png', 'docker': True}]",True,"This datatype is used to store output from nbconvert for jupyter notebook and must be stored in secondary storage. Therefore, it is configured to use secondary output",,,,,
5ed53b69da664506f88e6df9,report/pdf,Unstructured PDF file for reporting. This datatype is not meant to be used by downstream Apps.,"[{'_id': '5ed53b69da664514fe8e6dfa', 'id': 'pdf', 'desc': '', 'required': True, 'filename': 'report.pdf'}]",['1'],9,"['bold', 'communities', 'fmriprep', 'letter2backtask', 'measurements', 'network-preprocess', 'networkmatrices', 'preprocessed', 'rest', 'satellite', 'time series', 'visualization']",2020-06-01T17:31:21.248Z,[],[],"[{'docker': False, '_id': '5be75b31e15a02914a4be8f0', 'ui': 'raw', 'name': 'File Viewer', 'desc': ""Browse / download files via Brain-Life's File Browser"", 'avatar': 'https://brainlife.io/images/ui-logos/raw.png'}]",False,,,,,,
